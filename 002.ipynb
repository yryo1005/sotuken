{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 次の月の接続数を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 訓練用データ(train)テスト用データ(test)を分ける　train_test_split\n",
    "# k分割交差検証を行うKFoldをインストール\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'year': 2022.0,\n",
       "   'month': 11.0,\n",
       "   'date': 202211.0,\n",
       "   'good': 55857.0,\n",
       "   'bad': 6644.0,\n",
       "   'all_review_count': 62501.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 629325.0,\n",
       "   'gain': 12656.5,\n",
       "   'peak': 1129095.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 852068535.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 10.0,\n",
       "   'date': 202210.0,\n",
       "   'good': 55731.0,\n",
       "   'bad': 6675.0,\n",
       "   'all_review_count': 62406.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 621006.0,\n",
       "   'gain': -10426.5,\n",
       "   'peak': 1078860.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 849997689.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 9.0,\n",
       "   'date': 202209.0,\n",
       "   'good': 57430.0,\n",
       "   'bad': 7128.0,\n",
       "   'all_review_count': 64558.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 608349.5,\n",
       "   'gain': -22668.7,\n",
       "   'peak': 1100366.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 798181709.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 8.0,\n",
       "   'date': 202208.0,\n",
       "   'good': 71809.0,\n",
       "   'bad': 9490.0,\n",
       "   'all_review_count': 81299.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 618776.0,\n",
       "   'gain': 46991.7,\n",
       "   'peak': 1039889.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 804512345.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 7.0,\n",
       "   'date': 202207.0,\n",
       "   'good': 63481.0,\n",
       "   'bad': 8150.0,\n",
       "   'all_review_count': 71631.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 641444.8,\n",
       "   'gain': 22230.6,\n",
       "   'peak': 928329.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 806821513.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 6.0,\n",
       "   'date': 202206.0,\n",
       "   'good': 56873.0,\n",
       "   'bad': 7444.0,\n",
       "   'all_review_count': 64317.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 594453.1,\n",
       "   'gain': 7260.8,\n",
       "   'peak': 906670.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 796942903.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 5.0,\n",
       "   'date': 202205.0,\n",
       "   'good': 56049.0,\n",
       "   'bad': 7110.0,\n",
       "   'all_review_count': 63159.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 8.0,\n",
       "   'avg': 572222.5,\n",
       "   'gain': -4021.5,\n",
       "   'peak': 923996.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 814688015.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 4.0,\n",
       "   'date': 202204.0,\n",
       "   'good': 57366.0,\n",
       "   'bad': 7269.0,\n",
       "   'all_review_count': 64635.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 8.0,\n",
       "   'avg': 564961.7,\n",
       "   'gain': -12506.5,\n",
       "   'peak': 1013237.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 811476339.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 3.0,\n",
       "   'date': 202203.0,\n",
       "   'good': 68066.0,\n",
       "   'bad': 8200.0,\n",
       "   'all_review_count': 76266.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 568983.2,\n",
       "   'gain': -53148.7,\n",
       "   'peak': 987993.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 842232292.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 2.0,\n",
       "   'date': 202202.0,\n",
       "   'good': 71244.0,\n",
       "   'bad': 8735.0,\n",
       "   'all_review_count': 79979.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 581489.7,\n",
       "   'gain': 32262.1,\n",
       "   'peak': 995163.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 773919662.0},\n",
       "  {'year': 2022.0,\n",
       "   'month': 1.0,\n",
       "   'date': 202201.0,\n",
       "   'good': 78616.0,\n",
       "   'bad': 9862.0,\n",
       "   'all_review_count': 88478.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 634638.4,\n",
       "   'gain': 55762.1,\n",
       "   'peak': 991625.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 841556186.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 12.0,\n",
       "   'date': 202112.0,\n",
       "   'good': 68383.0,\n",
       "   'bad': 8724.0,\n",
       "   'all_review_count': 77107.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 602376.3,\n",
       "   'gain': -1547.5,\n",
       "   'peak': 950586.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 790841123.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 11.0,\n",
       "   'date': 202111.0,\n",
       "   'good': 69056.0,\n",
       "   'bad': 8610.0,\n",
       "   'all_review_count': 77666.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 546614.2,\n",
       "   'gain': 35725.8,\n",
       "   'peak': 935593.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 746857217.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 10.0,\n",
       "   'date': 202110.0,\n",
       "   'good': 70990.0,\n",
       "   'bad': 8999.0,\n",
       "   'all_review_count': 79989.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 548161.7,\n",
       "   'gain': 84.9,\n",
       "   'peak': 864966.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 761030927.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 9.0,\n",
       "   'date': 202109.0,\n",
       "   'good': 74696.0,\n",
       "   'bad': 9909.0,\n",
       "   'all_review_count': 84605.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 512435.8,\n",
       "   'gain': 269.0,\n",
       "   'peak': 942519.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 712688157.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 8.0,\n",
       "   'date': 202108.0,\n",
       "   'good': 78104.0,\n",
       "   'bad': 10531.0,\n",
       "   'all_review_count': 88635.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 512350.9,\n",
       "   'gain': 6014.6,\n",
       "   'peak': 802544.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 742779745.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 7.0,\n",
       "   'date': 202107.0,\n",
       "   'good': 77235.0,\n",
       "   'bad': 10570.0,\n",
       "   'all_review_count': 87805.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 512082.0,\n",
       "   'gain': -43279.7,\n",
       "   'peak': 763523.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 728164057.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 6.0,\n",
       "   'date': 202106.0,\n",
       "   'good': 86148.0,\n",
       "   'bad': 13458.0,\n",
       "   'all_review_count': 99606.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 506067.4,\n",
       "   'gain': -110541.8,\n",
       "   'peak': 929940.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 725029145.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 5.0,\n",
       "   'date': 202105.0,\n",
       "   'good': 76920.0,\n",
       "   'bad': 11079.0,\n",
       "   'all_review_count': 87999.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 549347.1,\n",
       "   'gain': -63457.6,\n",
       "   'peak': 1087197.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 763354617.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 4.0,\n",
       "   'date': 202104.0,\n",
       "   'good': 82430.0,\n",
       "   'bad': 11258.0,\n",
       "   'all_review_count': 93688.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 659888.9,\n",
       "   'gain': -17581.3,\n",
       "   'peak': 1148077.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 764329312.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 3.0,\n",
       "   'date': 202103.0,\n",
       "   'good': 93466.0,\n",
       "   'bad': 11791.0,\n",
       "   'all_review_count': 105257.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 723346.5,\n",
       "   'gain': -85.4,\n",
       "   'peak': 1198581.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 795249278.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 2.0,\n",
       "   'date': 202102.0,\n",
       "   'good': 86505.0,\n",
       "   'bad': 10704.0,\n",
       "   'all_review_count': 97209.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 740927.8,\n",
       "   'gain': -2196.42,\n",
       "   'peak': 1123485.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 710744828.0},\n",
       "  {'year': 2021.0,\n",
       "   'month': 1.0,\n",
       "   'date': 202101.0,\n",
       "   'good': 105384.0,\n",
       "   'bad': 12999.0,\n",
       "   'all_review_count': 118383.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 741013.24,\n",
       "   'gain': 25405.91,\n",
       "   'peak': 1124553.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 764912073.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 12.0,\n",
       "   'date': 202012.0,\n",
       "   'good': 124355.0,\n",
       "   'bad': 14052.0,\n",
       "   'all_review_count': 138407.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 743209.66,\n",
       "   'gain': 49049.17,\n",
       "   'peak': 1164396.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 742721118.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 11.0,\n",
       "   'date': 202011.0,\n",
       "   'good': 123339.0,\n",
       "   'bad': 13520.0,\n",
       "   'all_review_count': 136859.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 717803.75,\n",
       "   'gain': 55087.89,\n",
       "   'peak': 1037464.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 676323499.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 10.0,\n",
       "   'date': 202010.0,\n",
       "   'good': 82983.0,\n",
       "   'bad': 10688.0,\n",
       "   'all_review_count': 93671.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 668754.58,\n",
       "   'gain': 6816.37,\n",
       "   'peak': 943876.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 677821596.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 9.0,\n",
       "   'date': 202009.0,\n",
       "   'good': 78638.0,\n",
       "   'bad': 6989.0,\n",
       "   'all_review_count': 85627.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 613666.69,\n",
       "   'gain': -33107.34,\n",
       "   'peak': 977769.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 630276320.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 8.0,\n",
       "   'date': 202008.0,\n",
       "   'good': 91206.0,\n",
       "   'bad': 12033.0,\n",
       "   'all_review_count': 103239.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 606850.32,\n",
       "   'gain': 14056.85,\n",
       "   'peak': 925348.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 617654552.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 7.0,\n",
       "   'date': 202007.0,\n",
       "   'good': 95677.0,\n",
       "   'bad': 12356.0,\n",
       "   'all_review_count': 108033.0,\n",
       "   'recommend_count': 9.0,\n",
       "   'review_count': 10.0,\n",
       "   'avg': 639957.66,\n",
       "   'gain': -45746.65,\n",
       "   'peak': 857560.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 614835056.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 6.0,\n",
       "   'date': 202006.0,\n",
       "   'good': 105266.0,\n",
       "   'bad': 12827.0,\n",
       "   'all_review_count': 118093.0,\n",
       "   'recommend_count': 0.0,\n",
       "   'review_count': 0.0,\n",
       "   'avg': 625900.81,\n",
       "   'gain': -97147.79,\n",
       "   'peak': 1009467.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 617667675.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 5.0,\n",
       "   'date': 202005.0,\n",
       "   'good': 134154.0,\n",
       "   'bad': 16237.0,\n",
       "   'all_review_count': 150391.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 671647.46,\n",
       "   'gain': -88808.97,\n",
       "   'peak': 1193359.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 690919844.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 4.0,\n",
       "   'date': 202004.0,\n",
       "   'good': 154264.0,\n",
       "   'bad': 19462.0,\n",
       "   'all_review_count': 173726.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 768795.25,\n",
       "   'gain': 186570.94,\n",
       "   'peak': 1305714.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 707770424.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 3.0,\n",
       "   'date': 202003.0,\n",
       "   'good': 129384.0,\n",
       "   'bad': 15919.0,\n",
       "   'all_review_count': 145303.0,\n",
       "   'recommend_count': 8.0,\n",
       "   'review_count': 9.0,\n",
       "   'avg': 857604.22,\n",
       "   'gain': 127054.13,\n",
       "   'peak': 1145972.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 614637525.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 2.0,\n",
       "   'date': 202002.0,\n",
       "   'good': 98576.0,\n",
       "   'bad': 12199.0,\n",
       "   'all_review_count': 110775.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 671033.29,\n",
       "   'gain': 42783.15,\n",
       "   'peak': 916996.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 494362025.0},\n",
       "  {'year': 2020.0,\n",
       "   'month': 1.0,\n",
       "   'date': 202001.0,\n",
       "   'good': 106271.0,\n",
       "   'bad': 13640.0,\n",
       "   'all_review_count': 119911.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 543979.15,\n",
       "   'gain': 44494.44,\n",
       "   'peak': 817229.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 504227760.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201912.0,\n",
       "   'good': 123114.0,\n",
       "   'bad': 14973.0,\n",
       "   'all_review_count': 138087.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 501196.0,\n",
       "   'gain': 30620.76,\n",
       "   'peak': 767060.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 489960904.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201911.0,\n",
       "   'good': 200311.0,\n",
       "   'bad': 22686.0,\n",
       "   'all_review_count': 222997.0,\n",
       "   'recommend_count': 8.0,\n",
       "   'review_count': 9.0,\n",
       "   'avg': 456701.56,\n",
       "   'gain': 17085.5,\n",
       "   'peak': 758412.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 444037585.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201910.0,\n",
       "   'good': 52944.0,\n",
       "   'bad': 5789.0,\n",
       "   'all_review_count': 58733.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 426080.81,\n",
       "   'gain': -1930.29,\n",
       "   'peak': 747937.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 458972530.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201909.0,\n",
       "   'good': 27057.0,\n",
       "   'bad': 3568.0,\n",
       "   'all_review_count': 30625.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 408995.31,\n",
       "   'gain': -4171.7,\n",
       "   'peak': 720052.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 443916276.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201908.0,\n",
       "   'good': 28408.0,\n",
       "   'bad': 4152.0,\n",
       "   'all_review_count': 32560.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 410925.6,\n",
       "   'gain': 21314.48,\n",
       "   'peak': 647461.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 462667163.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201907.0,\n",
       "   'good': 90065.0,\n",
       "   'bad': 10184.0,\n",
       "   'all_review_count': 100249.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 415097.3,\n",
       "   'gain': 4406.1,\n",
       "   'peak': 578933.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 468667503.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201906.0,\n",
       "   'good': 72414.0,\n",
       "   'bad': 9413.0,\n",
       "   'all_review_count': 81827.0,\n",
       "   'recommend_count': 8.0,\n",
       "   'review_count': 9.0,\n",
       "   'avg': 393782.83,\n",
       "   'gain': 24959.42,\n",
       "   'peak': 587724.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 459967446.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201905.0,\n",
       "   'good': 28130.0,\n",
       "   'bad': 4467.0,\n",
       "   'all_review_count': 32597.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 389376.72,\n",
       "   'gain': 12427.39,\n",
       "   'peak': 588453.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 475503683.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201904.0,\n",
       "   'good': 29803.0,\n",
       "   'bad': 4616.0,\n",
       "   'all_review_count': 34419.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 364417.31,\n",
       "   'gain': -38250.24,\n",
       "   'peak': 621614.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 459882969.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201903.0,\n",
       "   'good': 35272.0,\n",
       "   'bad': 5236.0,\n",
       "   'all_review_count': 40508.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 351989.92,\n",
       "   'gain': 18881.2,\n",
       "   'peak': 680071.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 475948889.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201902.0,\n",
       "   'good': 34192.0,\n",
       "   'bad': 5963.0,\n",
       "   'all_review_count': 40155.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 390240.16,\n",
       "   'gain': -30007.91,\n",
       "   'peak': 654069.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 434108199.0},\n",
       "  {'year': 2019.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201901.0,\n",
       "   'good': 35082.0,\n",
       "   'bad': 8871.0,\n",
       "   'all_review_count': 43953.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 371358.96,\n",
       "   'gain': 5857.61,\n",
       "   'peak': 684511.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 487744486.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201812.0,\n",
       "   'good': 49885.0,\n",
       "   'bad': 35043.0,\n",
       "   'all_review_count': 84928.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 15.0,\n",
       "   'avg': 401366.87,\n",
       "   'gain': 85423.83,\n",
       "   'peak': 746548.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 479130101.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201811.0,\n",
       "   'good': 68588.0,\n",
       "   'bad': 8995.0,\n",
       "   'all_review_count': 77583.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 395509.26,\n",
       "   'gain': -15822.39,\n",
       "   'peak': 546031.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 435691109.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201810.0,\n",
       "   'good': 25296.0,\n",
       "   'bad': 4299.0,\n",
       "   'all_review_count': 29595.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 310085.43,\n",
       "   'gain': -7256.17,\n",
       "   'peak': 565968.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 450878274.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201809.0,\n",
       "   'good': 26312.0,\n",
       "   'bad': 4878.0,\n",
       "   'all_review_count': 31190.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 325907.82,\n",
       "   'gain': 49632.68,\n",
       "   'peak': 583029.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 444109147.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201808.0,\n",
       "   'good': 29830.0,\n",
       "   'bad': 6292.0,\n",
       "   'all_review_count': 36122.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 333163.99,\n",
       "   'gain': 10224.05,\n",
       "   'peak': 454370.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 452335748.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201807.0,\n",
       "   'good': 29220.0,\n",
       "   'bad': 6299.0,\n",
       "   'all_review_count': 35519.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 283531.31,\n",
       "   'gain': 6445.02,\n",
       "   'peak': 426008.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 461230198.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201806.0,\n",
       "   'good': 31037.0,\n",
       "   'bad': 6884.0,\n",
       "   'all_review_count': 37921.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 273307.26,\n",
       "   'gain': 4691.36,\n",
       "   'peak': 420261.0,\n",
       "   'price': 760.0,\n",
       "   'steam_online': 465287550.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201805.0,\n",
       "   'good': 25846.0,\n",
       "   'bad': 6321.0,\n",
       "   'all_review_count': 32167.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 266862.24,\n",
       "   'gain': -26905.82,\n",
       "   'peak': 454481.0,\n",
       "   'price': 760.0,\n",
       "   'steam_online': 474049371.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201804.0,\n",
       "   'good': 26395.0,\n",
       "   'bad': 7531.0,\n",
       "   'all_review_count': 33926.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 262170.88,\n",
       "   'gain': -65193.64,\n",
       "   'peak': 523262.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 474062020.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201803.0,\n",
       "   'good': 38423.0,\n",
       "   'bad': 8927.0,\n",
       "   'all_review_count': 47350.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 289076.7,\n",
       "   'gain': -28186.77,\n",
       "   'peak': 672502.0,\n",
       "   'price': 1520.0,\n",
       "   'steam_online': 510031006.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201802.0,\n",
       "   'good': 39603.0,\n",
       "   'bad': 7380.0,\n",
       "   'all_review_count': 46983.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 354270.33,\n",
       "   'gain': 426.57,\n",
       "   'peak': 686588.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 371090512.0},\n",
       "  {'year': 2018.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201801.0,\n",
       "   'good': 47300.0,\n",
       "   'bad': 8666.0,\n",
       "   'all_review_count': 55966.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 382457.1,\n",
       "   'gain': 41153.65,\n",
       "   'peak': 715850.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 522357795.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201712.0,\n",
       "   'good': 45971.0,\n",
       "   'bad': 7814.0,\n",
       "   'all_review_count': 53785.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 382030.53,\n",
       "   'gain': 19745.48,\n",
       "   'peak': 598405.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 503638824.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201711.0,\n",
       "   'good': 90715.0,\n",
       "   'bad': 13673.0,\n",
       "   'all_review_count': 104388.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 340876.88,\n",
       "   'gain': -20729.86,\n",
       "   'peak': 601881.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 456531797.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201710.0,\n",
       "   'good': 40456.0,\n",
       "   'bad': 8508.0,\n",
       "   'all_review_count': 48964.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 321131.4,\n",
       "   'gain': -12540.83,\n",
       "   'peak': 639968.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 461639493.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201709.0,\n",
       "   'good': 38971.0,\n",
       "   'bad': 7819.0,\n",
       "   'all_review_count': 46790.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 341861.26,\n",
       "   'gain': -20023.6,\n",
       "   'peak': 665371.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 413855215.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201708.0,\n",
       "   'good': 41377.0,\n",
       "   'bad': 8539.0,\n",
       "   'all_review_count': 49916.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 354402.09,\n",
       "   'gain': -3163.35,\n",
       "   'peak': 595781.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 402100933.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201707.0,\n",
       "   'good': 49776.0,\n",
       "   'bad': 7976.0,\n",
       "   'all_review_count': 57752.0,\n",
       "   'recommend_count': 0.0,\n",
       "   'review_count': 0.0,\n",
       "   'avg': 374425.69,\n",
       "   'gain': 3201.0,\n",
       "   'peak': 624785.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 397350674.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201706.0,\n",
       "   'good': 51702.0,\n",
       "   'bad': 7767.0,\n",
       "   'all_review_count': 59469.0,\n",
       "   'recommend_count': 8.0,\n",
       "   'review_count': 8.0,\n",
       "   'avg': 377589.04,\n",
       "   'gain': 2558.7,\n",
       "   'peak': 614621.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 384667873.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201705.0,\n",
       "   'good': 42320.0,\n",
       "   'bad': 5998.0,\n",
       "   'all_review_count': 48318.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 374388.04,\n",
       "   'gain': -20369.85,\n",
       "   'peak': 692966.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 384904645.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201704.0,\n",
       "   'good': 45248.0,\n",
       "   'bad': 6081.0,\n",
       "   'all_review_count': 51329.0,\n",
       "   'recommend_count': 0.0,\n",
       "   'review_count': 0.0,\n",
       "   'avg': 371829.34,\n",
       "   'gain': 5290.47,\n",
       "   'peak': 709841.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 372738458.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201703.0,\n",
       "   'good': 45310.0,\n",
       "   'bad': 6540.0,\n",
       "   'all_review_count': 51850.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 392199.19,\n",
       "   'gain': -15476.99,\n",
       "   'peak': 742356.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 355283156.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201702.0,\n",
       "   'good': 44226.0,\n",
       "   'bad': 7229.0,\n",
       "   'all_review_count': 51455.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 386908.72,\n",
       "   'gain': 9276.18,\n",
       "   'peak': 744468.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 355481565.0},\n",
       "  {'year': 2017.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201701.0,\n",
       "   'good': 49265.0,\n",
       "   'bad': 7500.0,\n",
       "   'all_review_count': 56765.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 402385.71,\n",
       "   'gain': 50913.83,\n",
       "   'peak': 814616.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 403770973.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201612.0,\n",
       "   'good': 48938.0,\n",
       "   'bad': 7279.0,\n",
       "   'all_review_count': 56217.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 393109.53,\n",
       "   'gain': 13150.44,\n",
       "   'peak': 662460.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 388609680.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201611.0,\n",
       "   'good': 119996.0,\n",
       "   'bad': 13183.0,\n",
       "   'all_review_count': 133179.0,\n",
       "   'recommend_count': 8.0,\n",
       "   'review_count': 11.0,\n",
       "   'avg': 342195.7,\n",
       "   'gain': -4031.2,\n",
       "   'peak': 627124.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 364127062.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201610.0,\n",
       "   'good': 31139.0,\n",
       "   'bad': 5365.0,\n",
       "   'all_review_count': 36504.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 329045.26,\n",
       "   'gain': 10550.57,\n",
       "   'peak': 661985.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 362204081.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201609.0,\n",
       "   'good': 30699.0,\n",
       "   'bad': 4943.0,\n",
       "   'all_review_count': 35642.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 333076.46,\n",
       "   'gain': -24703.36,\n",
       "   'peak': 638360.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 338136102.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201608.0,\n",
       "   'good': 36129.0,\n",
       "   'bad': 5453.0,\n",
       "   'all_review_count': 41582.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 322525.89,\n",
       "   'gain': -6548.31,\n",
       "   'peak': 599095.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 339754591.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201607.0,\n",
       "   'good': 43257.0,\n",
       "   'bad': 5598.0,\n",
       "   'all_review_count': 48855.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 347229.25,\n",
       "   'gain': 19466.5,\n",
       "   'peak': 636056.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 346363534.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201606.0,\n",
       "   'good': 46101.0,\n",
       "   'bad': 5721.0,\n",
       "   'all_review_count': 51822.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 353777.56,\n",
       "   'gain': -4427.34,\n",
       "   'peak': 579110.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 342460460.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201605.0,\n",
       "   'good': 42784.0,\n",
       "   'bad': 4596.0,\n",
       "   'all_review_count': 47380.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 334311.06,\n",
       "   'gain': -37057.47,\n",
       "   'peak': 668612.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 349085617.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201604.0,\n",
       "   'good': 47222.0,\n",
       "   'bad': 4728.0,\n",
       "   'all_review_count': 51950.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 338738.39,\n",
       "   'gain': -3631.08,\n",
       "   'peak': 850485.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 347096278.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201603.0,\n",
       "   'good': 51267.0,\n",
       "   'bad': 5181.0,\n",
       "   'all_review_count': 56448.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 375795.87,\n",
       "   'gain': 3141.92,\n",
       "   'peak': 737599.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 351943255.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201602.0,\n",
       "   'good': 55607.0,\n",
       "   'bad': 6095.0,\n",
       "   'all_review_count': 61702.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 379426.95,\n",
       "   'gain': 10913.93,\n",
       "   'peak': 738969.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 332474919.0},\n",
       "  {'year': 2016.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201601.0,\n",
       "   'good': 59292.0,\n",
       "   'bad': 7904.0,\n",
       "   'all_review_count': 67196.0,\n",
       "   'recommend_count': 0.0,\n",
       "   'review_count': 0.0,\n",
       "   'avg': 376285.02,\n",
       "   'gain': -12076.02,\n",
       "   'peak': 667432.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 354205980.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201512.0,\n",
       "   'good': 63369.0,\n",
       "   'bad': 8518.0,\n",
       "   'all_review_count': 71887.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 365371.09,\n",
       "   'gain': 16521.23,\n",
       "   'peak': 823694.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 319799868.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201511.0,\n",
       "   'good': 47536.0,\n",
       "   'bad': 4395.0,\n",
       "   'all_review_count': 51931.0,\n",
       "   'recommend_count': 0.0,\n",
       "   'review_count': 0.0,\n",
       "   'avg': 377447.11,\n",
       "   'gain': -1840.21,\n",
       "   'peak': 786707.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 312287411.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201510.0,\n",
       "   'good': 42958.0,\n",
       "   'bad': 3825.0,\n",
       "   'all_review_count': 46783.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 360925.88,\n",
       "   'gain': 6860.76,\n",
       "   'peak': 732093.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 306848246.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201509.0,\n",
       "   'good': 38546.0,\n",
       "   'bad': 3531.0,\n",
       "   'all_review_count': 42077.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 362766.09,\n",
       "   'gain': -1629.91,\n",
       "   'peak': 725939.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 285319406.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201508.0,\n",
       "   'good': 42101.0,\n",
       "   'bad': 3691.0,\n",
       "   'all_review_count': 45792.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 355905.33,\n",
       "   'gain': 28002.87,\n",
       "   'peak': 819902.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 280723676.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201507.0,\n",
       "   'good': 39299.0,\n",
       "   'bad': 3378.0,\n",
       "   'all_review_count': 42677.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 357535.24,\n",
       "   'gain': -14623.63,\n",
       "   'peak': 541181.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 274316327.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201506.0,\n",
       "   'good': 51772.0,\n",
       "   'bad': 4532.0,\n",
       "   'all_review_count': 56304.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 329532.38,\n",
       "   'gain': 26869.72,\n",
       "   'peak': 610401.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 275398132.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201505.0,\n",
       "   'good': 42027.0,\n",
       "   'bad': 3114.0,\n",
       "   'all_review_count': 45141.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 344156.01,\n",
       "   'gain': 25537.55,\n",
       "   'peak': 677701.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 268017435.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201504.0,\n",
       "   'good': 37328.0,\n",
       "   'bad': 2831.0,\n",
       "   'all_review_count': 40159.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 6.0,\n",
       "   'avg': 317286.29,\n",
       "   'gain': 23752.43,\n",
       "   'peak': 568556.0,\n",
       "   'price': 740.0,\n",
       "   'steam_online': 256307044.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201503.0,\n",
       "   'good': 36869.0,\n",
       "   'bad': 2666.0,\n",
       "   'all_review_count': 39535.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 291748.74,\n",
       "   'gain': 28061.68,\n",
       "   'peak': 595439.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 260193756.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201502.0,\n",
       "   'good': 28898.0,\n",
       "   'bad': 2084.0,\n",
       "   'all_review_count': 30982.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 267996.31,\n",
       "   'gain': 5863.96,\n",
       "   'peak': 455508.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 224509605.0},\n",
       "  {'year': 2015.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201501.0,\n",
       "   'good': 34941.0,\n",
       "   'bad': 2436.0,\n",
       "   'all_review_count': 37377.0,\n",
       "   'recommend_count': 9.0,\n",
       "   'review_count': 10.0,\n",
       "   'avg': 239934.64,\n",
       "   'gain': 50481.18,\n",
       "   'peak': 443188.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 248142190.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 12.0,\n",
       "   'date': 201412.0,\n",
       "   'good': 30837.0,\n",
       "   'bad': 2229.0,\n",
       "   'all_review_count': 33066.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 234070.68,\n",
       "   'gain': 36260.43,\n",
       "   'peak': 367634.0,\n",
       "   'price': 1480.0,\n",
       "   'steam_online': 229914135.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 11.0,\n",
       "   'date': 201411.0,\n",
       "   'good': 20940.0,\n",
       "   'bad': 1658.0,\n",
       "   'all_review_count': 22598.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 183589.5,\n",
       "   'gain': 13791.37,\n",
       "   'peak': 348018.0,\n",
       "   'price': 991.0,\n",
       "   'steam_online': 212894074.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 10.0,\n",
       "   'date': 201410.0,\n",
       "   'good': 16945.0,\n",
       "   'bad': 1214.0,\n",
       "   'all_review_count': 18159.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 147329.07,\n",
       "   'gain': 2503.02,\n",
       "   'peak': 260613.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 216669754.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 9.0,\n",
       "   'date': 201409.0,\n",
       "   'good': 18259.0,\n",
       "   'bad': 1224.0,\n",
       "   'all_review_count': 19483.0,\n",
       "   'recommend_count': 5.0,\n",
       "   'review_count': 5.0,\n",
       "   'avg': 133537.7,\n",
       "   'gain': -2151.11,\n",
       "   'peak': 242494.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 202281291.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 8.0,\n",
       "   'date': 201408.0,\n",
       "   'good': 21564.0,\n",
       "   'bad': 1252.0,\n",
       "   'all_review_count': 22816.0,\n",
       "   'recommend_count': 6.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 131034.68,\n",
       "   'gain': 27047.79,\n",
       "   'peak': 277192.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 202543340.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 7.0,\n",
       "   'date': 201407.0,\n",
       "   'good': 20171.0,\n",
       "   'bad': 1319.0,\n",
       "   'all_review_count': 21490.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 7.0,\n",
       "   'avg': 133185.79,\n",
       "   'gain': 21974.38,\n",
       "   'peak': 193613.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 209067723.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 6.0,\n",
       "   'date': 201406.0,\n",
       "   'good': 24742.0,\n",
       "   'bad': 1242.0,\n",
       "   'all_review_count': 25984.0,\n",
       "   'recommend_count': 7.0,\n",
       "   'review_count': 8.0,\n",
       "   'avg': 106138.0,\n",
       "   'gain': -761.4,\n",
       "   'peak': 164134.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 207131104.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 5.0,\n",
       "   'date': 201405.0,\n",
       "   'good': 12406.0,\n",
       "   'bad': 741.0,\n",
       "   'all_review_count': 13147.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 84163.62,\n",
       "   'gain': 6044.49,\n",
       "   'peak': 170137.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 200047568.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 4.0,\n",
       "   'date': 201404.0,\n",
       "   'good': 11987.0,\n",
       "   'bad': 650.0,\n",
       "   'all_review_count': 12637.0,\n",
       "   'recommend_count': 2.0,\n",
       "   'review_count': 2.0,\n",
       "   'avg': 84925.02,\n",
       "   'gain': 8737.2,\n",
       "   'peak': 142526.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 191717596.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 3.0,\n",
       "   'date': 201403.0,\n",
       "   'good': 13930.0,\n",
       "   'bad': 885.0,\n",
       "   'all_review_count': 14815.0,\n",
       "   'recommend_count': 4.0,\n",
       "   'review_count': 4.0,\n",
       "   'avg': 78880.53,\n",
       "   'gain': 10351.96,\n",
       "   'peak': 164495.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 203940245.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 2.0,\n",
       "   'date': 201402.0,\n",
       "   'good': 11181.0,\n",
       "   'bad': 628.0,\n",
       "   'all_review_count': 11809.0,\n",
       "   'recommend_count': 1.0,\n",
       "   'review_count': 1.0,\n",
       "   'avg': 70143.33,\n",
       "   'gain': 4164.01,\n",
       "   'peak': 119764.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 187047218.0},\n",
       "  {'year': 2014.0,\n",
       "   'month': 1.0,\n",
       "   'date': 201401.0,\n",
       "   'good': 15735.0,\n",
       "   'bad': 843.0,\n",
       "   'all_review_count': 16578.0,\n",
       "   'recommend_count': 3.0,\n",
       "   'review_count': 3.0,\n",
       "   'avg': 59791.37,\n",
       "   'gain': 8839.08,\n",
       "   'peak': 102084.0,\n",
       "   'price': 0.0,\n",
       "   'steam_online': 215374048.0}],\n",
       " 107)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "\n",
    "# データセットのパス\n",
    "file_path = \"dataset/csgo_graf2.csv\"\n",
    "# データを入れる配列変数\n",
    "datas = list()\n",
    "# ファイルの読み込み\n",
    "with open(file_path, \"r\") as f:\n",
    "    \n",
    "    r = csv.reader(f)  # rに読み込んだcsvを入れている\n",
    "\n",
    "    # 読み込んだデータセットをitemsに読み込んでいる\n",
    "    # next関数では１行目の要素名の読み込みをしない様にできる\n",
    "    # イテレータ(iter)は要素を一つずつ取り出せる\n",
    "\n",
    "    items = next(iter(r)) #itemsの0行目に要素名を入れている\n",
    "    items[0] = items[0][1:] \n",
    "\n",
    "    # rはデータ数　Rはデータ数分を繰り返す\n",
    "    # データを一月分ずらすことで、次の月を出している\n",
    "    for i, R in enumerate(r):\n",
    "        if i == 0: \n",
    "            tmp = float(R[8])\n",
    "            continue\n",
    "            \n",
    "        # datasに各要素の内容である数値を入れている\n",
    "        datas.append({\n",
    "            I:V for I, V in zip(items, map(float, R))\n",
    "        })\n",
    "        datas[-1][\"avg\"] = tmp\n",
    "        tmp = float(R[8])\n",
    "        \n",
    "\n",
    "datas, len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'year': 2017.96261682243,\n",
       "  'month': 6.4485981308411215,\n",
       "  'date': 201802.71028037384,\n",
       "  'good': 57033.53271028037,\n",
       "  'bad': 7636.1682242990655,\n",
       "  'all_review_count': 64669.700934579436,\n",
       "  'recommend_count': 3.9158878504672896,\n",
       "  'review_count': 4.411214953271028,\n",
       "  'avg': 418133.41570093454,\n",
       "  'gain': 5366.5222429906535,\n",
       "  'peak': 715313.0,\n",
       "  'price': 565.7663551401869,\n",
       "  'steam_online': 482132167.1214953},\n",
       " {'year': 2.564769336679463,\n",
       "  'month': 3.426760124468988,\n",
       "  'date': 256.4189041008779,\n",
       "  'good': 33251.4001875988,\n",
       "  'bad': 4951.444306398299,\n",
       "  'all_review_count': 37215.10212999656,\n",
       "  'recommend_count': 2.226104662573369,\n",
       "  'review_count': 2.590252291786169,\n",
       "  'avg': 173012.8872184669,\n",
       "  'gain': 37362.302464107546,\n",
       "  'peak': 265331.46595278557,\n",
       "  'price': 654.3025762580565,\n",
       "  'steam_online': 198253770.00640947},\n",
       " [{'year': 1.5741700900078421,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': 1.592276205445198,\n",
       "   'good': -0.035382952406291815,\n",
       "   'bad': -0.2003795585496089,\n",
       "   'all_review_count': -0.058274754345800754,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 1.2206696720365666,\n",
       "   'gain': 0.19511585946857887,\n",
       "   'peak': 1.5594908749858958,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.8659739376786872},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': 1.5883763369721364,\n",
       "   'good': -0.039172266519054866,\n",
       "   'bad': -0.19411875905723824,\n",
       "   'all_review_count': -0.060827481452880944,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 1.1725865486707594,\n",
       "   'gain': -0.4226993841764,\n",
       "   'peak': 1.3701616530648928,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.8555285070574534},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': 1.5844764684990749,\n",
       "   'good': 0.01192332616018655,\n",
       "   'bad': -0.10263030195904782,\n",
       "   'all_review_count': -0.003001494774601232,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 1.0994330385277933,\n",
       "   'gain': -0.7503612035131657,\n",
       "   'peak': 1.451214987326525,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.594166617201211},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': 1.5805766000260133,\n",
       "   'good': 0.444356243838122,\n",
       "   'bad': 0.374402227104806,\n",
       "   'all_review_count': 0.44684276311623555,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 1.1596973354112632,\n",
       "   'gain': 1.114095626119321,\n",
       "   'peak': 1.223284991225868,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.6260986001329623},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': 1.5766767315529517,\n",
       "   'good': 0.19390062533740243,\n",
       "   'bad': 0.10377412001523609,\n",
       "   'all_review_count': 0.18705575605043243,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 1.290721101122864,\n",
       "   'gain': 0.4513661269460035,\n",
       "   'peak': 0.8028297708116728,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.637746136519914},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': 1.5727768630798902,\n",
       "   'good': -0.004827848131948511,\n",
       "   'bad': -0.03881053939165671,\n",
       "   'all_review_count': -0.009477360383088877,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 1.0191130102142216,\n",
       "   'gain': 0.05070024147545786,\n",
       "   'peak': 0.7211997993259157,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.5879180298479418},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': 1.5688769946068288,\n",
       "   'good': -0.029608759472557648,\n",
       "   'bad': -0.10626560489010174,\n",
       "   'all_review_count': -0.040593760277813744,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 1.385496331036635,\n",
       "   'avg': 0.8906220038076934,\n",
       "   'gain': -0.25126990639855096,\n",
       "   'peak': 0.7864992538696263,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.6774250894081524},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': 1.5649771261337673,\n",
       "   'good': 0.009998595182275161,\n",
       "   'bad': -0.07415376233245875,\n",
       "   'all_review_count': -0.0009324422772836029,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 1.385496331036635,\n",
       "   'avg': 0.848655187828074,\n",
       "   'gain': -0.47837047141729405,\n",
       "   'peak': 1.122837048105761,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.6612252663233447},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': 1.5610772576607057,\n",
       "   'good': 0.3317895555518356,\n",
       "   'bad': 0.1138721837126081,\n",
       "   'all_review_count': 0.3116019680642923,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 0.8718991210671163,\n",
       "   'gain': -1.566156751158574,\n",
       "   'peak': 1.0276956749959014,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.8163595318609216},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': 1.5571773891876441,\n",
       "   'good': 0.427364478173748,\n",
       "   'bad': 0.2219214652744886,\n",
       "   'all_review_count': 0.4113732917336476,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 0.944185643771103,\n",
       "   'gain': 0.719858680627267,\n",
       "   'peak': 1.0547184782441066,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.4717878750506046},\n",
       "  {'year': 1.5741700900078421,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': 1.5532775207145826,\n",
       "   'good': 0.6490694276919161,\n",
       "   'bad': 0.44953182101325373,\n",
       "   'all_review_count': 0.6397483199765376,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': 1.251380679091727,\n",
       "   'gain': 1.3488349066662138,\n",
       "   'peak': 1.041384213545062,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.8129492259687403},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': 1.206189226612107,\n",
       "   'good': 0.34132298867680294,\n",
       "   'bad': 0.2196998912610668,\n",
       "   'all_review_count': 0.3342003206648654,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': 1.064908442724375,\n",
       "   'gain': -0.1850534305168338,\n",
       "   'peak': 0.8867135270034866,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.557140405796693},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': 1.2022893581390455,\n",
       "   'good': 0.36156273786640236,\n",
       "   'bad': 0.1966763060310586,\n",
       "   'all_review_count': 0.3492211043791583,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': 0.7426081742502229,\n",
       "   'gain': 0.8125644233562501,\n",
       "   'peak': 0.830206847909994,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.3352838126102027},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': 1.198389489665984,\n",
       "   'good': 0.4197257021051622,\n",
       "   'bad': 0.27523924159661284,\n",
       "   'all_review_count': 0.41164199985018235,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': 0.751552594662362,\n",
       "   'gain': -0.14136233301104756,\n",
       "   'peak': 0.5640228137383073,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.4067765766546987},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': 1.1944896211929226,\n",
       "   'good': 0.5311796552948436,\n",
       "   'bad': 0.4590240008887834,\n",
       "   'all_review_count': 0.5356776664426262,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 0.5450598843540938,\n",
       "   'gain': -0.13643490649131265,\n",
       "   'peak': 0.8563100466961961,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.162933697911777},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': 1.190589752719861,\n",
       "   'good': 0.633671579868625,\n",
       "   'bad': 0.5846439132840913,\n",
       "   'all_review_count': 0.6439670374061333,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 0.5445691694636317,\n",
       "   'gain': 0.017345766033341467,\n",
       "   'peak': 0.3287623640368471,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.3147168796340067},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': 1.1866898842467994,\n",
       "   'good': 0.607537342059172,\n",
       "   'bad': 0.5925204029680414,\n",
       "   'all_review_count': 0.6216642637337485,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 0.5430149499813541,\n",
       "   'gain': -1.3020135011680052,\n",
       "   'peak': 0.18169725866052666,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.2409947607581464},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': 1.1827900157737379,\n",
       "   'good': 0.8755862046548628,\n",
       "   'bad': 1.1757845621282488,\n",
       "   'all_review_count': 0.9387667120564153,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 0.5082510656447774,\n",
       "   'gain': -3.102279961314994,\n",
       "   'peak': 0.8089014215833407,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.225182138380783},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': 1.1788901473006763,\n",
       "   'good': 0.5980640567772644,\n",
       "   'bad': 0.6953186914072885,\n",
       "   'all_review_count': 0.6268772011945227,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 0.7584041073968047,\n",
       "   'gain': -1.8420739008016758,\n",
       "   'peak': 1.40158272847358,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.4184973625944812},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': 1.1749902788276148,\n",
       "   'good': 0.763771364406823,\n",
       "   'bad': 0.7314697594438803,\n",
       "   'all_review_count': 0.779745248691146,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 1.3973264546114181,\n",
       "   'gain': -0.6141972183067598,\n",
       "   'peak': 1.6310315794848405,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.4234137634274564},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': 1.1710904103545534,\n",
       "   'good': 1.0956671624104182,\n",
       "   'bad': 0.8391151184578659,\n",
       "   'all_review_count': 1.0906136687102064,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': 1.7641060686633516,\n",
       "   'gain': -0.14592040327889574,\n",
       "   'peak': 1.8213746276364944,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.5793753171421745},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': 1.1671905418814918,\n",
       "   'good': 0.8863225946410248,\n",
       "   'bad': 0.6195832136769984,\n",
       "   'all_review_count': 0.874357376523034,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 1.8657245104028954,\n",
       "   'gain': -0.20242173913816117,\n",
       "   'peak': 1.5383475101013169,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.1531314681739153},\n",
       "  {'year': 1.1842714797512672,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': 1.1632906734084303,\n",
       "   'good': 1.4540881592033548,\n",
       "   'bad': 1.0830843373863737,\n",
       "   'all_review_count': 1.4433199424737286,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': 1.8662183464481379,\n",
       "   'gain': 0.5363531269589281,\n",
       "   'peak': 1.5423726640579534,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.4263532333804423},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': 0.8162023793059546,\n",
       "   'good': 2.024620524546432,\n",
       "   'bad': 1.2957495588530283,\n",
       "   'all_review_count': 1.981381075022926,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 1.8789134701196282,\n",
       "   'gain': 1.1691636991315912,\n",
       "   'peak': 1.6925357811874153,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.3144211626849767},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': 0.8123025108328932,\n",
       "   'good': 1.994065420272089,\n",
       "   'bad': 1.1883061611129901,\n",
       "   'all_review_count': 1.9397850585833456,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 1.7320694378139914,\n",
       "   'gain': 1.3307897125658852,\n",
       "   'peak': 1.214145479667026,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.9795088984800974},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': 0.8084026423598316,\n",
       "   'good': 0.7804022430128386,\n",
       "   'bad': 0.6163518332938394,\n",
       "   'all_review_count': 0.779288444893037,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 1.4485693425981672,\n",
       "   'gain': 0.038805096618500866,\n",
       "   'peak': 0.8614244042984018,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.9870653600795493},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': 0.80450277388677,\n",
       "   'good': 0.6497310539655732,\n",
       "   'bad': -0.130702919037742,\n",
       "   'all_review_count': 0.5631396359524784,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': 1.1301659514655782,\n",
       "   'gain': -1.0297508372229185,\n",
       "   'peak': 0.989162740489674,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.7472450731893535},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': 0.8006029054137086,\n",
       "   'good': 1.0277000997529222,\n",
       "   'bad': 0.8879897467531465,\n",
       "   'all_review_count': 1.0363883707934924,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': 1.0907679036693303,\n",
       "   'gain': 0.2325961513040529,\n",
       "   'peak': 0.7915947671181024,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.6835803670927585},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': 0.796703036940647,\n",
       "   'good': 1.1621606029129508,\n",
       "   'bad': 0.9532232382381697,\n",
       "   'all_review_count': 1.165207041860255,\n",
       "   'recommend_count': 2.2838603390981156,\n",
       "   'review_count': 2.157621890520593,\n",
       "   'avg': 1.2821255564561702,\n",
       "   'gain': -1.3680412841819107,\n",
       "   'peak': 0.5361105569940663,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.6693587157218471},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': 0.7928031684675856,\n",
       "   'good': 1.4505394364628306,\n",
       "   'bad': 1.048346998267414,\n",
       "   'all_review_count': 1.4355274070942206,\n",
       "   'recommend_count': -1.7590762538274087,\n",
       "   'review_count': -1.7030059068991967,\n",
       "   'avg': 1.2008781405787037,\n",
       "   'gain': -2.7437900097691252,\n",
       "   'peak': 1.1086284053936644,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.6836465600332488},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': 0.788903299994524,\n",
       "   'good': 2.319314881617584,\n",
       "   'bad': 1.7370349424281855,\n",
       "   'all_review_count': 2.303400881878179,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 1.4652899467480018,\n",
       "   'gain': -2.5206019445258026,\n",
       "   'peak': 1.80169358460133,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.0531334504849752},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': 0.7850034315214625,\n",
       "   'good': 2.9241014435831785,\n",
       "   'bad': 2.38836005090868,\n",
       "   'all_review_count': 2.930431271812034,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 2.0267960377788365,\n",
       "   'gain': 4.849926417973975,\n",
       "   'peak': 2.225145057258527,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 1.1381284546125399},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': 0.781103563048401,\n",
       "   'good': 2.175862275920126,\n",
       "   'bad': 1.6728112573128993,\n",
       "   'all_review_count': 2.1666821921852946,\n",
       "   'recommend_count': 1.8346451621063908,\n",
       "   'review_count': 1.771559110778614,\n",
       "   'avg': 2.5401044475035937,\n",
       "   'gain': 3.2569622247962293,\n",
       "   'peak': 1.6230981065646908,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.6683623614028669},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': 0.7772036945753394,\n",
       "   'good': 1.2493449014280307,\n",
       "   'bad': 0.9215153182284216,\n",
       "   'all_review_count': 1.2388868074140853,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': 1.4617400955786817,\n",
       "   'gain': 1.0014540135194825,\n",
       "   'peak': 0.7601171586482265,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.06168789566074485},\n",
       "  {'year': 0.7943728694946923,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': 0.7733038261022779,\n",
       "   'good': 1.4807637276003454,\n",
       "   'bad': 1.2125415139866829,\n",
       "   'all_review_count': 1.4843785426802394,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': 0.727377805909669,\n",
       "   'gain': 1.0472565975985542,\n",
       "   'peak': 0.3841082309405981,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.11145106031421421},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': 0.42621553199980233,\n",
       "   'good': 1.9872987879278694,\n",
       "   'bad': 1.4817558921586207,\n",
       "   'all_review_count': 1.9727824152938138,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': 0.48009478157647667,\n",
       "   'gain': 0.6759283045061281,\n",
       "   'peak': 0.1950277544888254,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.03948846409453698},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': 0.42231566352674077,\n",
       "   'good': 4.308915308268893,\n",
       "   'bad': 3.0394831981152275,\n",
       "   'all_review_count': 4.254383032790436,\n",
       "   'recommend_count': 1.8346451621063908,\n",
       "   'review_count': 1.771559110778614,\n",
       "   'avg': 0.2229206443469421,\n",
       "   'gain': 0.3136578043675787,\n",
       "   'peak': 0.16243456027815886,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.19215060636810954},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': 0.41841579505367926,\n",
       "   'good': -0.1229882858227899,\n",
       "   'bad': -0.3730564477746703,\n",
       "   'all_review_count': -0.15952397265609722,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': 0.04593527353271739,\n",
       "   'gain': -0.1952987841153635,\n",
       "   'peak': 0.12295563921470694,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.11681814232711218},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': 0.41451592658061776,\n",
       "   'good': -0.901511892466417,\n",
       "   'bad': -0.821612437211935,\n",
       "   'all_review_count': -0.9148087466119923,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.0528174857251857,\n",
       "   'gain': -0.25529000125604245,\n",
       "   'peak': 0.017860678464887696,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.19276249384947283},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': 0.4106160581075562,\n",
       "   'good': -0.8608820244795687,\n",
       "   'bad': -0.7036670532266299,\n",
       "   'all_review_count': -0.8628137260625168,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.04166057116793331,\n",
       "   'gain': 0.4268462248098844,\n",
       "   'peak': -0.2557254178517746,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.09818226468463127},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': 0.4067161896344947,\n",
       "   'good': 0.9933857552873457,\n",
       "   'bad': 0.5145633512243295,\n",
       "   'all_review_count': 0.9560446439496001,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.017548494506659396,\n",
       "   'gain': -0.025705649268090262,\n",
       "   'peak': -0.5139985923277873,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.06791630807858029},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': 0.4028163211614332,\n",
       "   'good': 0.4625509663636906,\n",
       "   'bad': 0.3588512090108531,\n",
       "   'all_review_count': 0.4610305516692707,\n",
       "   'recommend_count': 1.8346451621063908,\n",
       "   'review_count': 1.771559110778614,\n",
       "   'avg': -0.14074434623003856,\n",
       "   'gain': 0.524402846313646,\n",
       "   'peak': -0.480866449600455,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.11179974595579559},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': 0.39891645268837167,\n",
       "   'good': -0.8692425746648714,\n",
       "   'bad': -0.6400492519331863,\n",
       "   'all_review_count': -0.8618195060313382,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.16621129306178734,\n",
       "   'gain': 0.18898374273888596,\n",
       "   'peak': -0.4781189428266835,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.033434340851530894},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': 0.3950165842153101,\n",
       "   'good': -0.8189289039454065,\n",
       "   'bad': -0.6099570221150177,\n",
       "   'all_review_count': -0.8128608871987055,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.31047459275739453,\n",
       "   'gain': -1.1674002769206075,\n",
       "   'peak': -0.35313942002142057,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.11222585134585839},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': 0.3911167157422486,\n",
       "   'good': -0.6544546270985723,\n",
       "   'bad': -0.48474103226760473,\n",
       "   'all_review_count': -0.6492445150406919,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.3823038662860635,\n",
       "   'gain': 0.3617196175206909,\n",
       "   'peak': -0.1328225428275105,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.031188703858168264},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': 0.3872168472691871,\n",
       "   'good': -0.686934462350827,\n",
       "   'bad': -0.3379151861078157,\n",
       "   'all_review_count': -0.6587299115543689,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.16122068216637053,\n",
       "   'gain': -0.9467947612964549,\n",
       "   'peak': -0.23082071996277317,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.24223482922893577},\n",
       "  {'year': 0.4044742592381175,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': 0.38331697879612553,\n",
       "   'good': -0.6601686721892467,\n",
       "   'bad': 0.24938819853134048,\n",
       "   'all_review_count': -0.5566745688944681,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -0.27035243705211076,\n",
       "   'gain': 0.013143937193943397,\n",
       "   'peak': -0.11608875671565115,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': 0.028308762442818866},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': 0.03622868469364995,\n",
       "   'good': -0.21498441178264835,\n",
       "   'bad': 5.5351186602837466,\n",
       "   'all_review_count': 0.5443569386066989,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 4.087935789230488,\n",
       "   'avg': -0.09690923011858117,\n",
       "   'gain': 2.142729502120946,\n",
       "   'peak': 0.11772067774863203,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -0.015142542416208533},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': 0.03232881622058842,\n",
       "   'good': 0.3474881425904253,\n",
       "   'bad': 0.2744313965008231,\n",
       "   'all_review_count': 0.3469908270119198,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.13076572540152193,\n",
       "   'gain': -0.5671200875092209,\n",
       "   'peak': -0.6380019776098583,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.23425056744188968},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': 0.028428947747526898,\n",
       "   'good': -0.9544720682805101,\n",
       "   'bad': -0.6739787459563562,\n",
       "   'all_review_count': -0.9424856826150723,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.6245083093983638,\n",
       "   'gain': -0.33784567359350415,\n",
       "   'peak': -0.5628620015485657,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.15764589556347341},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': 0.024529079274465373,\n",
       "   'good': -0.9239169640061667,\n",
       "   'bad': -0.5570431683407883,\n",
       "   'all_review_count': -0.8996267380277785,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.5330562201674571,\n",
       "   'gain': 1.1847813126488673,\n",
       "   'peak': -0.49856129775252245,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.1917896447581604},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': 0.020629210801403848,\n",
       "   'good': -0.8181169080641001,\n",
       "   'bad': -0.2714699269791078,\n",
       "   'all_review_count': -0.7670998949528364,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.4911161652001213,\n",
       "   'gain': 0.1300114670843901,\n",
       "   'peak': -0.9834604390511057,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.1502943380119934},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': 0.016729342328342327,\n",
       "   'good': -0.8364620001973181,\n",
       "   'bad': -0.27005619806147574,\n",
       "   'all_review_count': -0.7833029943798822,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.7779888993527385,\n",
       "   'gain': 0.028865933999796083,\n",
       "   'peak': -1.0903531511467262,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.1054303740141716},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': 0.012829473855280802,\n",
       "   'good': -0.7818176847775525,\n",
       "   'bad': -0.15190885280222324,\n",
       "   'all_review_count': -0.7187593047882336,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.8370830521893989,\n",
       "   'gain': -0.018070680832351135,\n",
       "   'peak': -1.1120128513234953,\n",
       "   'price': 0.2968559989028799,\n",
       "   'steam_online': -0.08496492712824945},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': 0.008929605382219279,\n",
       "   'good': -0.9379314114390841,\n",
       "   'bad': -0.2656130500346321,\n",
       "   'all_review_count': -0.8733739550423327,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.8743347280825465,\n",
       "   'gain': -0.863767490614193,\n",
       "   'peak': -0.9830420943983093,\n",
       "   'price': 0.2968559989028799,\n",
       "   'steam_online': -0.040769949147670646},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': 0.005029736909157754,\n",
       "   'good': -0.9214208285191879,\n",
       "   'bad': -0.02123990855822941,\n",
       "   'all_review_count': -0.826108197343869,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -0.901450396027421,\n",
       "   'gain': -1.8885389172890228,\n",
       "   'peak': -0.7238153956235802,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': -0.04070614708226936},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': 0.001129868436096231,\n",
       "   'good': -0.5596917003579662,\n",
       "   'bad': 0.26069802987239715,\n",
       "   'all_review_count': -0.46539442170761114,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.7459370095244522,\n",
       "   'gain': -0.8980520479224734,\n",
       "   'peak': -0.16134912550333555,\n",
       "   'price': 1.458398116536628,\n",
       "   'steam_online': 0.14072286684688384},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': -0.0027700000369652927,\n",
       "   'good': -0.524204472952725,\n",
       "   'bad': -0.051736060924292886,\n",
       "   'all_review_count': -0.47525600958443676,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -0.3691232874479073,\n",
       "   'gain': -0.13221755398335705,\n",
       "   'peak': -0.10826081217638722,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.5600985803089917},\n",
       "  {'year': 0.0145756489815426,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': -0.006669868510026817,\n",
       "   'good': -0.29272549893735056,\n",
       "   'bad': 0.20798613737211524,\n",
       "   'all_review_count': -0.23387550850126448,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.20620611721186613,\n",
       "   'gain': 0.957840534356484,\n",
       "   'peak': 0.00202388359055596,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': 0.20289968698806693},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': -0.3537581626125024,\n",
       "   'good': -0.33269374065054175,\n",
       "   'bad': 0.035915131968896175,\n",
       "   'all_review_count': -0.29248074871749496,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': -0.20867165609083593,\n",
       "   'gain': 0.38485202486711384,\n",
       "   'peak': -0.4406111411633447,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': 0.10848044341254844},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': -0.35765803108556393,\n",
       "   'good': 1.0129338042817584,\n",
       "   'bad': 1.2192062360269484,\n",
       "   'all_review_count': 1.067262933383336,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.44653630687858026,\n",
       "   'gain': -0.6984682560198315,\n",
       "   'peak': -0.42751054645054676,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.1291292978724574},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': -0.3615578995586255,\n",
       "   'good': -0.49855141788774976,\n",
       "   'bad': 0.17607625608841967,\n",
       "   'all_review_count': -0.4220249316989014,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.5606635277893958,\n",
       "   'gain': -0.4792893120062266,\n",
       "   'peak': -0.2839655663509102,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.10336587355101891},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': -0.365457768031687,\n",
       "   'good': -0.5432111913595999,\n",
       "   'bad': 0.036924938338633376,\n",
       "   'all_review_count': -0.48044207623355756,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.4408466729106955,\n",
       "   'gain': -0.6795652454069692,\n",
       "   'peak': -0.18822494279245017,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.3443916961543175},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': -0.3693576365047485,\n",
       "   'good': -0.47085333615874364,\n",
       "   'bad': 0.18233705558079033,\n",
       "   'all_review_count': -0.3964439190047925,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': -0.36836172568150755,\n",
       "   'gain': -0.22830156816981387,\n",
       "   'peak': -0.4505006580006238,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.40368076793146446},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': -0.37325750497781,\n",
       "   'good': -0.21826246922940368,\n",
       "   'bad': 0.0686328583483815,\n",
       "   'all_review_count': -0.18588423888815686,\n",
       "   'recommend_count': -1.7590762538274087,\n",
       "   'review_count': -1.7030059068991967,\n",
       "   'avg': -0.25262699446049874,\n",
       "   'gain': -0.05796008543828323,\n",
       "   'peak': -0.34118833088612643,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.4276412656301787},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': -0.3771573734508716,\n",
       "   'good': -0.1603400963628828,\n",
       "   'bad': 0.026422952093366484,\n",
       "   'all_review_count': -0.13974705527913908,\n",
       "   'recommend_count': 1.8346451621063908,\n",
       "   'review_count': 1.385496331036635,\n",
       "   'avg': -0.23434309635985873,\n",
       "   'gain': -0.07515121011848815,\n",
       "   'peak': -0.37949513314759903,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -0.49161382463669834},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': -0.3810572419239331,\n",
       "   'good': -0.4424936281560805,\n",
       "   'bad': -0.33084654151965526,\n",
       "   'all_review_count': -0.4393834760270467,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.25284460830768274,\n",
       "   'gain': -0.6888326078863728,\n",
       "   'peak': -0.08422295455894604,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -0.4904195371334022},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': -0.3849571103969946,\n",
       "   'good': -0.3544371859166345,\n",
       "   'bad': -0.31408375578201775,\n",
       "   'all_review_count': -0.35847546213843134,\n",
       "   'recommend_count': -1.7590762538274087,\n",
       "   'review_count': -1.7030059068991967,\n",
       "   'avg': -0.267633680041796,\n",
       "   'gain': -0.002035534160768425,\n",
       "   'peak': -0.02062326072164285,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -0.551786274318812},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': -0.38885697887005616,\n",
       "   'good': -0.3525726027817828,\n",
       "   'bad': -0.22138353104014266,\n",
       "   'all_review_count': -0.3444757692669705,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.14989765281580936,\n",
       "   'gain': -0.5578754752337379,\n",
       "   'peak': 0.10192157158175943,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -0.639831520567777},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': -0.39275684734311767,\n",
       "   'good': -0.385172733720157,\n",
       "   'bad': -0.08223221329035636,\n",
       "   'all_review_count': -0.3550897398700934,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.18047612639113123,\n",
       "   'gain': 0.1046417779194737,\n",
       "   'peak': 0.10988142659713036,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -0.6388307375814379},\n",
       "  {'year': -0.3753229612750323,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': -0.3966567158161792,\n",
       "   'good': -0.23363024313116493,\n",
       "   'bad': -0.027500708050600058,\n",
       "   'all_review_count': -0.2124057299901374,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.09102042023638139,\n",
       "   'gain': 1.2190712229463054,\n",
       "   'peak': 0.37426017168152415,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.3952570189155138},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': -0.7437450099186548,\n",
       "   'good': -0.2434644154714309,\n",
       "   'bad': -0.07213414959298435,\n",
       "   'all_review_count': -0.22713093477624208,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.1446359638478048,\n",
       "   'gain': 0.2083361367915439,\n",
       "   'peak': -0.19919612553380658,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.4717311913840113},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': -0.7476448783917163,\n",
       "   'good': 1.8935283005977488,\n",
       "   'bad': 1.1202452117927026,\n",
       "   'all_review_count': 1.840900471698555,\n",
       "   'recommend_count': 1.8346451621063908,\n",
       "   'review_count': 2.543684670262572,\n",
       "   'avg': -0.43891363771674663,\n",
       "   'gain': -0.25152952637270326,\n",
       "   'peak': -0.332372942211433,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.5952225025414661},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': -0.7515447468647778,\n",
       "   'good': -0.7787501447815062,\n",
       "   'bad': -0.4586880279283849,\n",
       "   'all_review_count': -0.7568352449012087,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.51492207969711,\n",
       "   'gain': 0.13875075718337893,\n",
       "   'peak': -0.20098633913811587,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.6049220961478718},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': -0.7554446153378394,\n",
       "   'good': -0.791982670254647,\n",
       "   'bad': -0.5439156855342047,\n",
       "   'all_review_count': -0.7799978845465046,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.491622081270347,\n",
       "   'gain': -0.8048187681119914,\n",
       "   'peak': -0.2900259105103403,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.7263219514909601},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': -0.7593444838109009,\n",
       "   'good': -0.6286812763474776,\n",
       "   'bad': -0.44091543582101017,\n",
       "   'all_review_count': -0.620385263324859,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.5526034923641784,\n",
       "   'gain': -0.31889983906737956,\n",
       "   'peak': -0.4380106203486639,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.7181582277950744},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': -0.7632443522839624,\n",
       "   'good': -0.4143143636825966,\n",
       "   'bad': -0.41163105109863135,\n",
       "   'all_review_count': -0.42495385016913023,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.4098201402269092,\n",
       "   'gain': 0.37738514029092896,\n",
       "   'peak': -0.29870938870892677,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.684822453147327},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': -0.7671442207570239,\n",
       "   'good': -0.32878413085165925,\n",
       "   'bad': -0.38678981440309623,\n",
       "   'all_review_count': -0.3452281519932678,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': -0.3719714567832805,\n",
       "   'gain': -0.26213219199751464,\n",
       "   'peak': -0.5133315022057604,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.7045097155881564},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': -0.7710440892300855,\n",
       "   'good': -0.42853932856622295,\n",
       "   'bad': -0.6139962475939664,\n",
       "   'all_review_count': -0.4645882973580069,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.4844861966559193,\n",
       "   'gain': -1.135475852531992,\n",
       "   'peak': -0.17601003270494203,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.6710921568714379},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': -0.774943957703147,\n",
       "   'good': -0.29507126481668006,\n",
       "   'bad': -0.5873373594329043,\n",
       "   'all_review_count': -0.3417886881016229,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.45889660000113636,\n",
       "   'gain': -0.240820336263652,\n",
       "   'peak': 0.5094457964667228,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.6811264629022169},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': -0.7788438261762085,\n",
       "   'good': -0.17342225222837426,\n",
       "   'bad': -0.49584890233471396,\n",
       "   'all_review_count': -0.2209237772842892,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.2447074687995586,\n",
       "   'gain': -0.05954135843549093,\n",
       "   'peak': 0.08399305344344528,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.6566781157164696},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': -0.7827436946492701,\n",
       "   'good': -0.04290143278875818,\n",
       "   'bad': -0.3112562979467536,\n",
       "   'all_review_count': -0.07974453285692784,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': -0.22372013046669223,\n",
       "   'gain': 0.1484760678852305,\n",
       "   'peak': 0.08915640636534782,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.7548771865304602},\n",
       "  {'year': -0.7652215715316071,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': -0.7866435631223315,\n",
       "   'good': 0.06792096804879603,\n",
       "   'bad': 0.054091646624165796,\n",
       "   'all_review_count': 0.06788370636726768,\n",
       "   'recommend_count': -1.7590762538274087,\n",
       "   'review_count': -1.7030059068991967,\n",
       "   'avg': -0.2418802227610461,\n",
       "   'gain': -0.4668486975540921,\n",
       "   'peak': -0.18045730018512085,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.6452648396918732},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': -1.1337318572248072,\n",
       "   'good': 0.19053234612605752,\n",
       "   'bad': 0.17809586882789408,\n",
       "   'all_review_count': 0.1939346838337222,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.3049618242270615,\n",
       "   'gain': 0.2985551484072809,\n",
       "   'peak': 0.4084739803129338,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -0.8188106542248713},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': -1.1376317256978687,\n",
       "   'good': -0.2856280534563023,\n",
       "   'bad': -0.6545904636574019,\n",
       "   'all_review_count': -0.3422992335230389,\n",
       "   'recommend_count': -1.7590762538274087,\n",
       "   'review_count': -1.7030059068991967,\n",
       "   'avg': -0.23516343987462116,\n",
       "   'gain': -0.19288779779870016,\n",
       "   'peak': 0.26907475803380293,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.8567037898749885},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': -1.1415315941709303,\n",
       "   'good': -0.4233064662200264,\n",
       "   'bad': -0.7697083898074428,\n",
       "   'all_review_count': -0.48063017191513185,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -0.33065476578457076,\n",
       "   'gain': 0.03999319256206976,\n",
       "   'peak': 0.06324165111644134,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.8841391571813663},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': -1.1454314626439916,\n",
       "   'good': -0.5559926080097928,\n",
       "   'bad': -0.8290850043479903,\n",
       "   'all_review_count': -0.6070842115563886,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -0.32001850608400667,\n",
       "   'gain': -0.1872591296992963,\n",
       "   'peak': 0.040048020546084966,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -0.9927314931520971},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': -1.1493313311170532,\n",
       "   'good': -0.4490798169711211,\n",
       "   'bad': -0.7967712005163998,\n",
       "   'all_review_count': -0.5072591462637263,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.35967312436302995,\n",
       "   'gain': 0.6058606205748474,\n",
       "   'peak': 0.3941824224444269,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.0159125403516103},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': -1.1532311995901148,\n",
       "   'good': -0.5333469450978041,\n",
       "   'bad': -0.8599850792619487,\n",
       "   'all_review_count': -0.5909617245643031,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.3502523810519155,\n",
       "   'gain': -0.5350353410953296,\n",
       "   'peak': -0.6562810007275426,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -1.0482314667447519},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': -1.1571310680631763,\n",
       "   'good': -0.15823492185579222,\n",
       "   'bad': -0.6269217691266027,\n",
       "   'all_review_count': -0.2247931741623897,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.5121065668886052,\n",
       "   'gain': 0.5755319222541652,\n",
       "   'peak': -0.39539976769535723,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.0427747987582363},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': -1.161030936536238,\n",
       "   'good': -0.4513052871643311,\n",
       "   'bad': -0.9133028555840729,\n",
       "   'all_review_count': -0.524752044650139,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -0.427583210073373,\n",
       "   'gain': 0.5398764644225778,\n",
       "   'peak': -0.14175476649532728,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -1.080003331662107},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': -1.1649308050092992,\n",
       "   'good': -0.5926226444331689,\n",
       "   'bad': -0.9704578961111985,\n",
       "   'all_review_count': -0.658622428307755,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.613370771552677,\n",
       "   'avg': -0.582887941599361,\n",
       "   'gain': 0.49209782439591204,\n",
       "   'peak': -0.5531081640581396,\n",
       "   'price': 0.2662891010704128,\n",
       "   'steam_online': -1.1390710154676729},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': -1.1688306734823608,\n",
       "   'good': -0.6064265744153772,\n",
       "   'bad': -1.0037815063125262,\n",
       "   'all_review_count': -0.6753898147795238,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -0.7304928420814458,\n",
       "   'gain': 0.607434667036692,\n",
       "   'peak': -0.45178961179572646,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.119466283613775},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': -1.1727305419554224,\n",
       "   'good': -0.8461458029299347,\n",
       "   'bad': -1.1213229677499363,\n",
       "   'all_review_count': -0.9052158668517015,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -0.8677798984497227,\n",
       "   'gain': 0.013313894599702867,\n",
       "   'peak': -0.9791714641422553,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.299458578332036},\n",
       "  {'year': -1.155120181788182,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': -1.176630410428484,\n",
       "   'good': -0.6644090951249577,\n",
       "   'bad': -1.0502325993204373,\n",
       "   'all_review_count': -0.7333770263277244,\n",
       "   'recommend_count': 2.2838603390981156,\n",
       "   'review_count': 2.157621890520593,\n",
       "   'avg': -1.029974001161655,\n",
       "   'gain': 1.2074913691507416,\n",
       "   'peak': -1.025603951731919,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.1802548678591611},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 1.6200147274735566,\n",
       "   'date': -1.5237187045309595,\n",
       "   'good': -0.7878324690835256,\n",
       "   'bad': -1.0920385830275574,\n",
       "   'all_review_count': -0.8492170953658581,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -1.063867198912846,\n",
       "   'gain': 0.826873766323365,\n",
       "   'peak': -1.3103572120687252,\n",
       "   'price': 1.397264320871694,\n",
       "   'steam_online': -1.272197911360481},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 1.3281938927266366,\n",
       "   'date': -1.527618573004021,\n",
       "   'good': -1.085474070464604,\n",
       "   'bad': -1.2073584704515459,\n",
       "   'all_review_count': -1.1305007517544419,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -1.3556441920119577,\n",
       "   'gain': 0.22549059349601802,\n",
       "   'peak': -1.3842873806205795,\n",
       "   'price': 0.6499036688678744,\n",
       "   'steam_online': -1.3580477844773946},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 1.0363730579797164,\n",
       "   'date': -1.5315184414770826,\n",
       "   'good': -1.2056193869764165,\n",
       "   'bad': -1.2970292760842093,\n",
       "   'all_review_count': -1.2497802846842205,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -1.5652264409586112,\n",
       "   'gain': -0.07664148230001361,\n",
       "   'peak': -1.7137055281672158,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.339003102502984},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 0.7445522232327962,\n",
       "   'date': -1.5354183099501442,\n",
       "   'good': -1.1661022540861734,\n",
       "   'bad': -1.295009663344735,\n",
       "   'all_review_count': -1.2142033300550186,\n",
       "   'recommend_count': 0.48699963113121586,\n",
       "   'review_count': 0.22730799181069805,\n",
       "   'avg': -1.644939404667409,\n",
       "   'gain': -0.2012090194444665,\n",
       "   'peak': -1.7819936972124362,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.4115790893280256},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 0.4527313884858761,\n",
       "   'date': -1.5393181784232055,\n",
       "   'good': -1.066707943429968,\n",
       "   'bad': -1.2893547476742067,\n",
       "   'all_review_count': -1.124642914813984,\n",
       "   'recommend_count': 0.9362148081229408,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': -1.6594066506641734,\n",
       "   'gain': 0.580297956150793,\n",
       "   'peak': -1.6512214200707032,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.4102573036187727},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': 0.16091055373895596,\n",
       "   'date': -1.543218046896267,\n",
       "   'good': -1.1086009161210706,\n",
       "   'bad': -1.275823342319728,\n",
       "   'all_review_count': -1.1602736110664928,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 0.9994335512946559,\n",
       "   'avg': -1.6469734149984179,\n",
       "   'gain': 0.4445084125359738,\n",
       "   'peak': -1.9662198681434713,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.3773480530164306},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -0.1309102810079642,\n",
       "   'date': -1.5471179153693286,\n",
       "   'good': -0.9711330208080555,\n",
       "   'bad': -1.291374360413681,\n",
       "   'all_review_count': -1.0395161834957731,\n",
       "   'recommend_count': 1.3854299851146656,\n",
       "   'review_count': 1.385496331036635,\n",
       "   'avg': -1.8033073762127994,\n",
       "   'gain': -0.16401350663218628,\n",
       "   'peak': -2.077322408862278,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.3871164372440667},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -0.4227311157548843,\n",
       "   'date': -1.5510177838423902,\n",
       "   'good': -1.3421249168004759,\n",
       "   'bad': -1.3925569586613484,\n",
       "   'all_review_count': -1.3844567926914406,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -1.9303174524752256,\n",
       "   'gain': 0.018145770262971414,\n",
       "   'peak': -2.054697877774555,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.4228460780966516},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -0.7145519505018045,\n",
       "   'date': -1.5549176523154518,\n",
       "   'good': -1.3547258899214896,\n",
       "   'bad': -1.4109354345905656,\n",
       "   'all_review_count': -1.3981609066347132,\n",
       "   'recommend_count': -0.8606458998439589,\n",
       "   'review_count': -0.9308803474152388,\n",
       "   'avg': -1.925916624234965,\n",
       "   'gain': 0.09021600743817705,\n",
       "   'peak': -2.1587601679399935,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.4648627923297817},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -1.0063727852487245,\n",
       "   'date': -1.5588175207885133,\n",
       "   'good': -1.2962922603889608,\n",
       "   'bad': -1.3634745352129172,\n",
       "   'all_review_count': -1.3396362788534433,\n",
       "   'recommend_count': 0.037784454139490935,\n",
       "   'review_count': -0.15875478793128092,\n",
       "   'avg': -1.9608532702685495,\n",
       "   'gain': 0.1334349713002472,\n",
       "   'peak': -2.0759618465230028,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.403211258542531},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -1.2981936199956448,\n",
       "   'date': -1.5627173892615747,\n",
       "   'good': -1.378965470674561,\n",
       "   'bad': -1.4153785826174092,\n",
       "   'all_review_count': -1.4204099386837912,\n",
       "   'recommend_count': -1.3098610768356838,\n",
       "   'review_count': -1.3169431271572178,\n",
       "   'avg': -2.011353554614231,\n",
       "   'gain': -0.03218517499412297,\n",
       "   'peak': -2.244547203858494,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.4884203670475236},\n",
       "  {'year': -1.545018792044757,\n",
       "   'month': -1.590014454742565,\n",
       "   'date': -1.5666172577346362,\n",
       "   'good': -1.2420088320275537,\n",
       "   'bad': -1.3719569087187096,\n",
       "   'all_review_count': -1.2922630379083655,\n",
       "   'recommend_count': -0.411430722852234,\n",
       "   'review_count': -0.5448175676732598,\n",
       "   'avg': -2.071187016539691,\n",
       "   'gain': 0.09294282011514929,\n",
       "   'peak': -2.311180838646258,\n",
       "   'price': -0.8646861187308683,\n",
       "   'steam_online': -1.3455386957477333}])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの標準化\n",
    "\n",
    "# データの平均\n",
    "mean_items = {\n",
    "    I: np.average([D[I] for D in datas])  for I in items\n",
    "}\n",
    "# データの標準偏差\n",
    "std_items = {\n",
    "    I: np.std([D[I] for D in datas])  for I in items\n",
    "}\n",
    "# データの標準化\n",
    "standardization_datas = [\n",
    "    {I:(D[I] - mean_items[I]) / std_items[I] for I in items} for D in datas\n",
    "]\n",
    "\n",
    "mean_items, std_items, standardization_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[[ 0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00 -2.8562805e-01 -6.5459049e-01 -3.4229922e-01\n",
      "  -1.7590762e+00 -1.7030059e+00 -1.9288780e-01  2.6907477e-01\n",
      "   2.6628911e-01 -8.5670382e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  6.4906943e-01  4.4953182e-01  6.3974833e-01\n",
      "  -1.3098611e+00 -1.3169432e+00  1.3488349e+00  1.0413842e+00\n",
      "  -8.6468613e-01  1.8129492e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00 -6.2868130e-01 -4.4091544e-01 -6.2038529e-01\n",
      "   3.7784453e-02 -1.5875478e-01 -3.1889984e-01 -4.3801063e-01\n",
      "   1.3972644e+00 -7.1815825e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.1923326e-02 -1.0263030e-01 -3.0014948e-03\n",
      "   3.7784453e-02 -1.5875478e-01 -7.5036120e-01  1.4512150e+00\n",
      "  -8.6468613e-01  1.5941666e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  1.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00  1.9940654e+00  1.1883062e+00  1.9397850e+00\n",
      "   4.8699963e-01  6.1337078e-01  1.3307897e+00  1.2141454e+00\n",
      "  -8.6468613e-01  9.7950888e-01]\n",
      " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00 -1.0667080e+00 -1.2893548e+00 -1.1246430e+00\n",
      "   9.3621480e-01  9.9943358e-01  5.8029795e-01 -1.6512214e+00\n",
      "  -8.6468613e-01 -1.4102573e+00]\n",
      " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00 -1.2420088e+00 -1.3719569e+00 -1.2922630e+00\n",
      "  -4.1143072e-01 -5.4481757e-01  9.2942819e-02 -2.3111808e+00\n",
      "  -8.6468613e-01 -1.3455387e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  9.9985953e-03 -7.4153766e-02 -9.3244226e-04\n",
      "   1.3854300e+00  1.3854964e+00 -4.7837046e-01  1.1228371e+00\n",
      "  -8.6468613e-01  1.6612253e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  6.0753733e-01  5.9252042e-01  6.2166429e-01\n",
      "   3.7784453e-02 -1.5875478e-01 -1.3020135e+00  1.8169726e-01\n",
      "  -8.6468613e-01  1.2409948e+00]\n",
      " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00 -5.5599260e-01 -8.2908499e-01 -6.0708421e-01\n",
      "  -1.3098611e+00 -9.3088037e-01 -1.8725912e-01  4.0048022e-02\n",
      "   2.6628911e-01 -9.9273151e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00 -3.5257259e-01 -2.2138353e-01 -3.4447578e-01\n",
      "  -8.6064589e-01 -9.3088037e-01 -5.5787545e-01  1.0192157e-01\n",
      "   6.4990366e-01 -6.3983154e-01]]\n"
     ]
    }
   ],
   "source": [
    "# データ作成\n",
    "max_year, min_year = int(max([D[\"year\"] for D in datas])), int(min([D[\"year\"] for D in datas]))\n",
    "\n",
    "# 目的変数と説明変数\n",
    "x = list()\n",
    "y = list()\n",
    "\n",
    "# DはデータDSは標準化したデータ\n",
    "for D, SD in zip(datas, standardization_datas):\n",
    "    tmp = list()\n",
    "    \n",
    "    # Iには要素名\n",
    "    for I in items:\n",
    "        # yearの要素をone-hot表現にしている\n",
    "        if I == \"year\":\n",
    "            # 年の数だけ0を入力\n",
    "            a = [0] * (max_year - min_year + 1)\n",
    "            # \n",
    "            a[int(D[\"year\"]) - min_year] = 1\n",
    "            tmp += a\n",
    "        # 月ごとのone-hot表現\n",
    "        elif I == \"month\":\n",
    "            a = [0] * 12  #分割する数をかけてあげる\n",
    "            a[int(D[\"month\"]) - 1] = 1 #分割の時の一番低い数を引いてあげる\n",
    "            tmp += a\n",
    "        # dateは省く様にしている\n",
    "        elif I == \"date\":\n",
    "            continue\n",
    "\n",
    "        # 教師信号なのでyに入れる\n",
    "        elif I == \"avg\":\n",
    "            y.append(SD[I])\n",
    "\n",
    "        else:\n",
    "            tmp.append(SD[I])\n",
    "        \n",
    "    x.append(tmp)\n",
    "\n",
    "# print(x)\n",
    "x = np.array(x, np.float32)\n",
    "y = np.array(y, np.float32)\n",
    "print(len(x[0]))\n",
    "\n",
    "# 学習データ/テストデータ分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# for xtr, xte, ytr, yte in zip(x_train, x_test, y_train, y_test):\n",
    "#     print(f\"xtr{xtr} xte{xte} ytr{ytr} yte{yte}\")\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               15872     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,417\n",
      "Trainable params: 188,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 10:36:26.260791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 645ms/step - loss: 0.8936 - val_loss: 1.0503\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8676 - val_loss: 1.0195\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8421 - val_loss: 0.9893\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8171 - val_loss: 0.9597\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7926 - val_loss: 0.9307\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7687 - val_loss: 0.9022\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7452 - val_loss: 0.8743\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7223 - val_loss: 0.8471\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6999 - val_loss: 0.8204\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6781 - val_loss: 0.7944\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6568 - val_loss: 0.7689\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6360 - val_loss: 0.7441\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6158 - val_loss: 0.7199\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5962 - val_loss: 0.6963\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5770 - val_loss: 0.6733\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5585 - val_loss: 0.6509\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.6291\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5230 - val_loss: 0.6079\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5060 - val_loss: 0.5873\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4896 - val_loss: 0.5674\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4737 - val_loss: 0.5480\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4583 - val_loss: 0.5292\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4434 - val_loss: 0.5109\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4291 - val_loss: 0.4932\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4152 - val_loss: 0.4761\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4018 - val_loss: 0.4596\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3889 - val_loss: 0.4435\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3765 - val_loss: 0.4280\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3646 - val_loss: 0.4131\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3531 - val_loss: 0.3986\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3420 - val_loss: 0.3846\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3313 - val_loss: 0.3711\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3211 - val_loss: 0.3581\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3113 - val_loss: 0.3456\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3019 - val_loss: 0.3335\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2928 - val_loss: 0.3218\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2842 - val_loss: 0.3106\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2759 - val_loss: 0.2998\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2679 - val_loss: 0.2894\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2603 - val_loss: 0.2794\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2530 - val_loss: 0.2697\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2460 - val_loss: 0.2605\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2393 - val_loss: 0.2516\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2329 - val_loss: 0.2430\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2268 - val_loss: 0.2348\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2210 - val_loss: 0.2269\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2154 - val_loss: 0.2193\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2101 - val_loss: 0.2120\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2050 - val_loss: 0.2050\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2001 - val_loss: 0.1983\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1954 - val_loss: 0.1918\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1910 - val_loss: 0.1856\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1867 - val_loss: 0.1797\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1826 - val_loss: 0.1740\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1787 - val_loss: 0.1686\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1750 - val_loss: 0.1633\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1715 - val_loss: 0.1583\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1681 - val_loss: 0.1535\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1648 - val_loss: 0.1489\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1617 - val_loss: 0.1444\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1587 - val_loss: 0.1402\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1559 - val_loss: 0.1361\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1531 - val_loss: 0.1322\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1505 - val_loss: 0.1285\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1480 - val_loss: 0.1249\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1456 - val_loss: 0.1214\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1432 - val_loss: 0.1181\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1410 - val_loss: 0.1150\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1389 - val_loss: 0.1120\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1368 - val_loss: 0.1091\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1349 - val_loss: 0.1063\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1330 - val_loss: 0.1036\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1311 - val_loss: 0.1011\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1294 - val_loss: 0.0986\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1276 - val_loss: 0.0963\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1260 - val_loss: 0.0940\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1244 - val_loss: 0.0918\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1229 - val_loss: 0.0898\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1214 - val_loss: 0.0878\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1199 - val_loss: 0.0859\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1185 - val_loss: 0.0841\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1172 - val_loss: 0.0823\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1159 - val_loss: 0.0806\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1146 - val_loss: 0.0790\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1134 - val_loss: 0.0775\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1122 - val_loss: 0.0760\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1110 - val_loss: 0.0746\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1099 - val_loss: 0.0732\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1087 - val_loss: 0.0719\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1077 - val_loss: 0.0706\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1066 - val_loss: 0.0694\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1056 - val_loss: 0.0682\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1046 - val_loss: 0.0671\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1036 - val_loss: 0.0660\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1026 - val_loss: 0.0650\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1017 - val_loss: 0.0640\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1008 - val_loss: 0.0630\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0998 - val_loss: 0.0621\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0990 - val_loss: 0.0612\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0981 - val_loss: 0.0604\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0973 - val_loss: 0.0595\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0964 - val_loss: 0.0588\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0956 - val_loss: 0.0580\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0948 - val_loss: 0.0573\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0940 - val_loss: 0.0565\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0932 - val_loss: 0.0559\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0925 - val_loss: 0.0552\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0917 - val_loss: 0.0546\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0910 - val_loss: 0.0539\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0903 - val_loss: 0.0533\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0896 - val_loss: 0.0528\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0889 - val_loss: 0.0522\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0882 - val_loss: 0.0517\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0875 - val_loss: 0.0511\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0869 - val_loss: 0.0506\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0862 - val_loss: 0.0502\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0856 - val_loss: 0.0497\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0849 - val_loss: 0.0492\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0843 - val_loss: 0.0488\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0837 - val_loss: 0.0483\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0831 - val_loss: 0.0479\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0825 - val_loss: 0.0475\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0819 - val_loss: 0.0471\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0813 - val_loss: 0.0467\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0808 - val_loss: 0.0463\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0802 - val_loss: 0.0460\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0797 - val_loss: 0.0456\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0791 - val_loss: 0.0453\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0786 - val_loss: 0.0449\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0781 - val_loss: 0.0446\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0775 - val_loss: 0.0443\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0770 - val_loss: 0.0440\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0765 - val_loss: 0.0436\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0760 - val_loss: 0.0433\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0755 - val_loss: 0.0430\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0751 - val_loss: 0.0428\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0746 - val_loss: 0.0425\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0741 - val_loss: 0.0422\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0737 - val_loss: 0.0419\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0732 - val_loss: 0.0416\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0728 - val_loss: 0.0414\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0723 - val_loss: 0.0411\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0719 - val_loss: 0.0409\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0715 - val_loss: 0.0406\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0710 - val_loss: 0.0404\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0706 - val_loss: 0.0401\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0702 - val_loss: 0.0399\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0698 - val_loss: 0.0397\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0694 - val_loss: 0.0394\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0690 - val_loss: 0.0392\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0686 - val_loss: 0.0390\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0682 - val_loss: 0.0387\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0679 - val_loss: 0.0385\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0675 - val_loss: 0.0383\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0671 - val_loss: 0.0381\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0668 - val_loss: 0.0379\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0664 - val_loss: 0.0377\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0660 - val_loss: 0.0375\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0657 - val_loss: 0.0373\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0654 - val_loss: 0.0371\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0650 - val_loss: 0.0369\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0647 - val_loss: 0.0367\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0644 - val_loss: 0.0365\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0640 - val_loss: 0.0363\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0637 - val_loss: 0.0361\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0634 - val_loss: 0.0359\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0631 - val_loss: 0.0357\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0628 - val_loss: 0.0355\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0625 - val_loss: 0.0354\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0622 - val_loss: 0.0352\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0619 - val_loss: 0.0350\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0616 - val_loss: 0.0348\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0613 - val_loss: 0.0346\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0610 - val_loss: 0.0345\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0607 - val_loss: 0.0343\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0605 - val_loss: 0.0341\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0602 - val_loss: 0.0340\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0599 - val_loss: 0.0338\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0596 - val_loss: 0.0336\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0594 - val_loss: 0.0335\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0591 - val_loss: 0.0333\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0589 - val_loss: 0.0332\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0586 - val_loss: 0.0330\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0584 - val_loss: 0.0328\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0581 - val_loss: 0.0327\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0579 - val_loss: 0.0325\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0576 - val_loss: 0.0324\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0574 - val_loss: 0.0322\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0572 - val_loss: 0.0321\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0569 - val_loss: 0.0319\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0567 - val_loss: 0.0318\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0565 - val_loss: 0.0316\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0562 - val_loss: 0.0315\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0560 - val_loss: 0.0314\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0558 - val_loss: 0.0312\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0556 - val_loss: 0.0311\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0554 - val_loss: 0.0309\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0552 - val_loss: 0.0308\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0550 - val_loss: 0.0307\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0547 - val_loss: 0.0305\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0545 - val_loss: 0.0304\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0543 - val_loss: 0.0303\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0541 - val_loss: 0.0301\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0539 - val_loss: 0.0300\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0538 - val_loss: 0.0299\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0536 - val_loss: 0.0298\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0534 - val_loss: 0.0296\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0532 - val_loss: 0.0295\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0530 - val_loss: 0.0294\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0528 - val_loss: 0.0293\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0526 - val_loss: 0.0291\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0525 - val_loss: 0.0290\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0523 - val_loss: 0.0289\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0521 - val_loss: 0.0288\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0519 - val_loss: 0.0287\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0518 - val_loss: 0.0286\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0516 - val_loss: 0.0284\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0514 - val_loss: 0.0283\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0513 - val_loss: 0.0282\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0511 - val_loss: 0.0281\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0509 - val_loss: 0.0280\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0508 - val_loss: 0.0279\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0506 - val_loss: 0.0278\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0504 - val_loss: 0.0277\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0503 - val_loss: 0.0276\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0501 - val_loss: 0.0274\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0500 - val_loss: 0.0273\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0498 - val_loss: 0.0272\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0497 - val_loss: 0.0271\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0495 - val_loss: 0.0270\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0494 - val_loss: 0.0269\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0492 - val_loss: 0.0268\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0491 - val_loss: 0.0267\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0490 - val_loss: 0.0266\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0488 - val_loss: 0.0265\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0487 - val_loss: 0.0264\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0485 - val_loss: 0.0263\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0484 - val_loss: 0.0262\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0483 - val_loss: 0.0261\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0481 - val_loss: 0.0261\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0480 - val_loss: 0.0260\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0479 - val_loss: 0.0259\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0477 - val_loss: 0.0258\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0476 - val_loss: 0.0257\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0475 - val_loss: 0.0256\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0474 - val_loss: 0.0255\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0472 - val_loss: 0.0254\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0471 - val_loss: 0.0253\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0470 - val_loss: 0.0252\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0469 - val_loss: 0.0252\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0468 - val_loss: 0.0251\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0466 - val_loss: 0.0250\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0465 - val_loss: 0.0249\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0464 - val_loss: 0.0248\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0463 - val_loss: 0.0247\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0462 - val_loss: 0.0246\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0461 - val_loss: 0.0246\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - val_loss: 0.0245\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0458 - val_loss: 0.0244\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0457 - val_loss: 0.0243\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0456 - val_loss: 0.0242\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0455 - val_loss: 0.0242\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0454 - val_loss: 0.0241\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0453 - val_loss: 0.0240\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0452 - val_loss: 0.0239\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0451 - val_loss: 0.0239\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0450 - val_loss: 0.0238\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0449 - val_loss: 0.0237\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0448 - val_loss: 0.0236\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0447 - val_loss: 0.0236\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0446 - val_loss: 0.0235\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0445 - val_loss: 0.0234\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0444 - val_loss: 0.0233\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0443 - val_loss: 0.0233\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0442 - val_loss: 0.0232\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0441 - val_loss: 0.0231\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0440 - val_loss: 0.0231\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0439 - val_loss: 0.0230\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0438 - val_loss: 0.0229\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0437 - val_loss: 0.0229\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0436 - val_loss: 0.0228\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0435 - val_loss: 0.0227\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0435 - val_loss: 0.0227\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0434 - val_loss: 0.0226\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0433 - val_loss: 0.0225\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0432 - val_loss: 0.0225\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0431 - val_loss: 0.0224\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0430 - val_loss: 0.0223\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0429 - val_loss: 0.0223\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0428 - val_loss: 0.0222\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0428 - val_loss: 0.0222\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0427 - val_loss: 0.0221\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0426 - val_loss: 0.0220\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0425 - val_loss: 0.0220\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0424 - val_loss: 0.0219\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0423 - val_loss: 0.0219\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0423 - val_loss: 0.0218\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0422 - val_loss: 0.0217\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0421 - val_loss: 0.0217\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0420 - val_loss: 0.0216\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0420 - val_loss: 0.0216\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0419 - val_loss: 0.0215\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0418 - val_loss: 0.0215\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0417 - val_loss: 0.0214\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0417 - val_loss: 0.0214\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0416 - val_loss: 0.0213\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0415 - val_loss: 0.0212\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0414 - val_loss: 0.0212\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0414 - val_loss: 0.0211\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0413 - val_loss: 0.0211\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0412 - val_loss: 0.0210\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0411 - val_loss: 0.0210\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0411 - val_loss: 0.0209\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.0209\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0409 - val_loss: 0.0208\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0409 - val_loss: 0.0208\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0408 - val_loss: 0.0207\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0407 - val_loss: 0.0207\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0407 - val_loss: 0.0206\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0406 - val_loss: 0.0206\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0405 - val_loss: 0.0205\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0405 - val_loss: 0.0205\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0404 - val_loss: 0.0204\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0403 - val_loss: 0.0204\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0403 - val_loss: 0.0204\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0402 - val_loss: 0.0203\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0401 - val_loss: 0.0203\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0401 - val_loss: 0.0202\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0400 - val_loss: 0.0202\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0399 - val_loss: 0.0201\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0399 - val_loss: 0.0201\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0398 - val_loss: 0.0200\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0398 - val_loss: 0.0200\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0397 - val_loss: 0.0200\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0396 - val_loss: 0.0199\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0396 - val_loss: 0.0199\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0395 - val_loss: 0.0198\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0395 - val_loss: 0.0198\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0394 - val_loss: 0.0197\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0393 - val_loss: 0.0197\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0393 - val_loss: 0.0197\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0392 - val_loss: 0.0196\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0392 - val_loss: 0.0196\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0391 - val_loss: 0.0195\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0391 - val_loss: 0.0195\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0390 - val_loss: 0.0195\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0389 - val_loss: 0.0194\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0389 - val_loss: 0.0194\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0388 - val_loss: 0.0194\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0388 - val_loss: 0.0193\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0387 - val_loss: 0.0193\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0387 - val_loss: 0.0192\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0386 - val_loss: 0.0192\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0386 - val_loss: 0.0192\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0385 - val_loss: 0.0191\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0385 - val_loss: 0.0191\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0384 - val_loss: 0.0191\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0384 - val_loss: 0.0190\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0383 - val_loss: 0.0190\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0383 - val_loss: 0.0190\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0382 - val_loss: 0.0189\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0382 - val_loss: 0.0189\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0381 - val_loss: 0.0189\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0381 - val_loss: 0.0188\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0380 - val_loss: 0.0188\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0380 - val_loss: 0.0188\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0379 - val_loss: 0.0187\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0379 - val_loss: 0.0187\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0378 - val_loss: 0.0187\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0378 - val_loss: 0.0186\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0377 - val_loss: 0.0186\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0377 - val_loss: 0.0186\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0376 - val_loss: 0.0186\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0376 - val_loss: 0.0185\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0375 - val_loss: 0.0185\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0375 - val_loss: 0.0185\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0374 - val_loss: 0.0184\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0374 - val_loss: 0.0184\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0373 - val_loss: 0.0184\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0373 - val_loss: 0.0184\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0372 - val_loss: 0.0183\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0372 - val_loss: 0.0183\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0372 - val_loss: 0.0183\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0371 - val_loss: 0.0182\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0371 - val_loss: 0.0182\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0370 - val_loss: 0.0182\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0370 - val_loss: 0.0182\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0369 - val_loss: 0.0181\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0369 - val_loss: 0.0181\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0368 - val_loss: 0.0181\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0368 - val_loss: 0.0181\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0368 - val_loss: 0.0180\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0367 - val_loss: 0.0180\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0367 - val_loss: 0.0180\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0366 - val_loss: 0.0180\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0366 - val_loss: 0.0179\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0366 - val_loss: 0.0179\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0365 - val_loss: 0.0179\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0365 - val_loss: 0.0179\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0364 - val_loss: 0.0178\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0364 - val_loss: 0.0178\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0364 - val_loss: 0.0178\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0363 - val_loss: 0.0178\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0363 - val_loss: 0.0177\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0362 - val_loss: 0.0177\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0362 - val_loss: 0.0177\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0362 - val_loss: 0.0177\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0361 - val_loss: 0.0177\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0361 - val_loss: 0.0176\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0360 - val_loss: 0.0176\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0360 - val_loss: 0.0176\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0360 - val_loss: 0.0176\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0359 - val_loss: 0.0176\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0359 - val_loss: 0.0175\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0358 - val_loss: 0.0175\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0358 - val_loss: 0.0175\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0358 - val_loss: 0.0175\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0357 - val_loss: 0.0175\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0357 - val_loss: 0.0174\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0357 - val_loss: 0.0174\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0356 - val_loss: 0.0174\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0356 - val_loss: 0.0174\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0355 - val_loss: 0.0174\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0355 - val_loss: 0.0173\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0355 - val_loss: 0.0173\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0354 - val_loss: 0.0173\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0354 - val_loss: 0.0173\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0354 - val_loss: 0.0173\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0353 - val_loss: 0.0172\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0353 - val_loss: 0.0172\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0353 - val_loss: 0.0172\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0352 - val_loss: 0.0172\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0352 - val_loss: 0.0172\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0352 - val_loss: 0.0172\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0351 - val_loss: 0.0171\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0351 - val_loss: 0.0171\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0351 - val_loss: 0.0171\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0350 - val_loss: 0.0171\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0350 - val_loss: 0.0171\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0350 - val_loss: 0.0171\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0349 - val_loss: 0.0171\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0349 - val_loss: 0.0170\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0349 - val_loss: 0.0170\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0348 - val_loss: 0.0170\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0348 - val_loss: 0.0170\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0348 - val_loss: 0.0170\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0347 - val_loss: 0.0170\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0347 - val_loss: 0.0169\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0347 - val_loss: 0.0169\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.0169\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.0169\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0346 - val_loss: 0.0169\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0345 - val_loss: 0.0169\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0345 - val_loss: 0.0169\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0345 - val_loss: 0.0168\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0344 - val_loss: 0.0168\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0344 - val_loss: 0.0168\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0344 - val_loss: 0.0168\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0343 - val_loss: 0.0168\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0343 - val_loss: 0.0168\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0343 - val_loss: 0.0168\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0342 - val_loss: 0.0168\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0342 - val_loss: 0.0167\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0342 - val_loss: 0.0167\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0341 - val_loss: 0.0167\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0341 - val_loss: 0.0167\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0341 - val_loss: 0.0167\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0341 - val_loss: 0.0167\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0340 - val_loss: 0.0167\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0340 - val_loss: 0.0167\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0340 - val_loss: 0.0167\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0339 - val_loss: 0.0166\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0339 - val_loss: 0.0166\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0339 - val_loss: 0.0166\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0338 - val_loss: 0.0166\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0338 - val_loss: 0.0166\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0338 - val_loss: 0.0166\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0338 - val_loss: 0.0166\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0166\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0337 - val_loss: 0.0166\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0165\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0336 - val_loss: 0.0165\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0336 - val_loss: 0.0165\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0336 - val_loss: 0.0165\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0165\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0335 - val_loss: 0.0165\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0335 - val_loss: 0.0165\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0335 - val_loss: 0.0165\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0334 - val_loss: 0.0165\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0334 - val_loss: 0.0165\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0334 - val_loss: 0.0165\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0334 - val_loss: 0.0164\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0333 - val_loss: 0.0164\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0333 - val_loss: 0.0164\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0333 - val_loss: 0.0164\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0332 - val_loss: 0.0164\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0164\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0332 - val_loss: 0.0164\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0332 - val_loss: 0.0164\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0331 - val_loss: 0.0164\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0164\n",
      "0.01638212986290455\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0164\n",
      "0.01638212986290455\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "# input_dimには入力の値を入れる\n",
    "\n",
    "activation = \"tanh\"\n",
    "\n",
    "\"\"\"\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=x_train.shape[1:]))\n",
    "model.add(layers.Dense(512, activation= activation))\n",
    "# model.add(layers.LayerNormalization())\n",
    "model.add(layers.Dense(256, input_dim=5, activation= activation))\n",
    "model.add(layers.Dense(128, input_dim=5, activation= activation))\n",
    "model.add(layers.Dense(64, input_dim=5, activation= activation))\n",
    "# model.add(layers.Dense(32, input_dim=5, activation= activation))\n",
    "model.add(layers.Dense(16, activation= activation))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\"\"\"\n",
    "\n",
    "# nnの構成をする関数\n",
    "def build_model(x):\n",
    "    # 活性化関数\n",
    "    activation = \"tanh\"\n",
    "    activation2 = \"relu\"\n",
    "\n",
    "    # 入力層\n",
    "    # inputするのは、12の要素\n",
    "    input = layers.Input(shape = x.shape[1:])\n",
    "    \n",
    "    # 中間層\n",
    "    # Denseは全結合で,(ニューロン数, 活性化関数)(入力やその後に出た計算xを再度入力)\n",
    "    x = layers.Dense(units = 512, activation = activation)(input)\n",
    "    x = layers.Dense(units = 256, activation = activation)(x)\n",
    "    x = layers.Dense(units = 128, activation = activation)(x)\n",
    "    x = layers.Dense(units = 64, activation = activation)(x)\n",
    "    # x = layers.Dense(units = 32, activation = activation)(x)\n",
    "    # x = layers.Dense(units = 16, activation = activation)(x)\n",
    "    # x = layers.Dense(units = 8, activation = activation)(x)\n",
    "\n",
    "    # 出力層\n",
    "    output = layers.Dense(units = 1, activation = \"linear\")(x)\n",
    "\n",
    "    return models.Model(input, output)\n",
    "\n",
    "model = build_model(x)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=losses.MeanSquaredError(), \n",
    "              optimizer=optimizers.Adam(learning_rate = 0.00001))\n",
    "\n",
    "mc = callbacks.ModelCheckpoint(\n",
    "    filepath = \"model.h5\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    mode = \"min\"\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size = len(x_train), epochs = 500, verbose = 1, \n",
    "                    validation_data=(x_test, y_test), callbacks =[mc])\n",
    "\n",
    "\n",
    "print(model.evaluate(x_test, y_test))\n",
    "model = models.load_model(\"model.h5\")\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "11\n",
      "y =  [-0.31788006]\n",
      "y =  [1.106058]\n",
      "y =  [-0.67295647]\n",
      "y =  [1.117575]\n",
      "y =  [1.6567612]\n",
      "y =  [-1.4657086]\n",
      "y =  [-1.9775177]\n",
      "y =  [1.0192918]\n",
      "y =  [0.56892484]\n",
      "y =  [-0.46963412]\n",
      "y =  [-0.33235723]\n",
      "\n",
      "誤差\n",
      "[-0.08271663]\n",
      "誤差\n",
      "[-0.14532268]\n",
      "誤差\n",
      "[-0.12035298]\n",
      "誤差\n",
      "[0.01814198]\n",
      "誤差\n",
      "[-0.07530832]\n",
      "誤差\n",
      "[0.19369805]\n",
      "誤差\n",
      "[0.0936693]\n",
      "誤差\n",
      "[0.1706366]\n",
      "誤差\n",
      "[0.0259099]\n",
      "誤差\n",
      "[-0.14961562]\n",
      "誤差\n",
      "[-0.18245958]\n"
     ]
    }
   ],
   "source": [
    "# 学習モデルの動き testを分割しているので11コのavg予測が出ている　また12月のリストを見てあっているのかを誤差を出して確認している\n",
    "predict = model.predict(x_test)\n",
    "print(len(x_test))\n",
    "for X, Y in zip(predict, y_test):\n",
    "    print(\"y = \", X)\n",
    "\n",
    "print(\"\")\n",
    "for X, Y in zip(predict, y_test):\n",
    "    print(\"誤差\")\n",
    "    print(X - Y)\n",
    "\n",
    "\n",
    "# print(predict-y_test)\n",
    "# print(\"y_test=\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "# 学習曲線\n",
    "# ax.plot(history.history[\"loss\"], label = \"train\")\n",
    "# 活性化関数tanhで学習した後のtanh_test\n",
    "# ax.plot(history.history[\"val_loss\"], label = \"tanh_test\")\n",
    "# ax.plot(relu_history.history[\"val_loss\"], label = \"relu_test\")\n",
    "# ax.plot(sigmoid_history.history[\"val_loss\"], label = \"sigmoid_test\")\n",
    "\n",
    "ax.plot(history.history[\"val_loss\"], label = \"SGD_test\")\n",
    "ax.plot(adam_history.history[\"val_loss\"], label = \"adam_test\")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"loss(log)\")\n",
    "ax.set_xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history.json\", \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "with open(\"history.json\", \"r\") as f:\n",
    "    history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8657496571540833,\n",
       "  0.8494500517845154,\n",
       "  0.8333494663238525,\n",
       "  0.8174554109573364,\n",
       "  0.8017687201499939,\n",
       "  0.7862935066223145,\n",
       "  0.7710320353507996,\n",
       "  0.7559871673583984,\n",
       "  0.7411612868309021,\n",
       "  0.7265568971633911,\n",
       "  0.712175726890564,\n",
       "  0.6980196237564087,\n",
       "  0.6840898990631104,\n",
       "  0.6703881621360779,\n",
       "  0.6569151282310486,\n",
       "  0.6436717510223389,\n",
       "  0.6306585073471069,\n",
       "  0.6178755164146423,\n",
       "  0.605323076248169,\n",
       "  0.593001127243042,\n",
       "  0.5809087753295898,\n",
       "  0.5690460801124573,\n",
       "  0.5574116706848145,\n",
       "  0.5460047125816345,\n",
       "  0.5348240733146667,\n",
       "  0.5238682627677917,\n",
       "  0.513135552406311,\n",
       "  0.5026243329048157,\n",
       "  0.49233278632164,\n",
       "  0.4822584390640259,\n",
       "  0.47239944338798523,\n",
       "  0.46275320649147034,\n",
       "  0.45331746339797974,\n",
       "  0.4440895617008209,\n",
       "  0.435066819190979,\n",
       "  0.42624640464782715,\n",
       "  0.4176255762577057,\n",
       "  0.40920132398605347,\n",
       "  0.40097057819366455,\n",
       "  0.3929305672645569,\n",
       "  0.38507798314094543,\n",
       "  0.37740975618362427,\n",
       "  0.36992284655570984,\n",
       "  0.36261382699012756,\n",
       "  0.35547956824302673,\n",
       "  0.3485170006752014,\n",
       "  0.34172266721725464,\n",
       "  0.33509361743927,\n",
       "  0.32862618565559387,\n",
       "  0.32231754064559937,\n",
       "  0.3161642849445343,\n",
       "  0.3101632595062256,\n",
       "  0.3043113052845001,\n",
       "  0.2986052632331848,\n",
       "  0.29304182529449463,\n",
       "  0.28761807084083557,\n",
       "  0.28233078122138977,\n",
       "  0.27717703580856323,\n",
       "  0.2721536457538605,\n",
       "  0.26725783944129944,\n",
       "  0.2624865174293518,\n",
       "  0.25783684849739075,\n",
       "  0.2533058822154999,\n",
       "  0.24889086186885834,\n",
       "  0.24458898603916168,\n",
       "  0.24039749801158905,\n",
       "  0.23631377518177032,\n",
       "  0.23233500123023987,\n",
       "  0.2284587323665619,\n",
       "  0.22468236088752747,\n",
       "  0.22100333869457245,\n",
       "  0.21741922199726105,\n",
       "  0.21392759680747986,\n",
       "  0.21052606403827667,\n",
       "  0.20721231400966644,\n",
       "  0.2039840668439865,\n",
       "  0.2008390873670578,\n",
       "  0.1977752149105072,\n",
       "  0.19479027390480042,\n",
       "  0.1918821483850479,\n",
       "  0.18904878199100494,\n",
       "  0.1862882822751999,\n",
       "  0.18359850347042084,\n",
       "  0.18097762763500214,\n",
       "  0.17842383682727814,\n",
       "  0.17593519389629364,\n",
       "  0.17350998520851135,\n",
       "  0.1711464375257492,\n",
       "  0.16884282231330872,\n",
       "  0.16659750044345856,\n",
       "  0.1644088625907898,\n",
       "  0.1622753143310547,\n",
       "  0.16019532084465027,\n",
       "  0.15816736221313477,\n",
       "  0.15618997812271118,\n",
       "  0.1542617380619049,\n",
       "  0.15238124132156372,\n",
       "  0.15054714679718018,\n",
       "  0.14875812828540802,\n",
       "  0.1470128893852234,\n",
       "  0.1453101634979248,\n",
       "  0.14364878833293915,\n",
       "  0.14202754199504852,\n",
       "  0.1404453068971634,\n",
       "  0.13890086114406586,\n",
       "  0.13739314675331116,\n",
       "  0.13592121005058289,\n",
       "  0.13448390364646912,\n",
       "  0.13308028876781464,\n",
       "  0.1317092776298523,\n",
       "  0.13037006556987762,\n",
       "  0.1290617138147354,\n",
       "  0.12778322398662567,\n",
       "  0.12653373181819916,\n",
       "  0.12531252205371857,\n",
       "  0.12411867082118988,\n",
       "  0.12295141071081161,\n",
       "  0.1218099370598793,\n",
       "  0.12069356441497803,\n",
       "  0.11960149556398392,\n",
       "  0.11853304505348206,\n",
       "  0.11748754233121872,\n",
       "  0.11646430939435959,\n",
       "  0.11546267569065094,\n",
       "  0.11448207497596741,\n",
       "  0.11352185904979706,\n",
       "  0.11258143186569214,\n",
       "  0.11166022717952728,\n",
       "  0.1107577383518219,\n",
       "  0.10987333208322525,\n",
       "  0.10900658369064331,\n",
       "  0.10815694183111191,\n",
       "  0.10732392221689224,\n",
       "  0.10650698840618134,\n",
       "  0.1057058572769165,\n",
       "  0.1049199178814888,\n",
       "  0.10414876788854599,\n",
       "  0.10339204221963882,\n",
       "  0.1026492491364479,\n",
       "  0.10192009806632996,\n",
       "  0.10120416432619095,\n",
       "  0.10050106793642044,\n",
       "  0.09981046617031097,\n",
       "  0.0991320088505745,\n",
       "  0.09846536815166473,\n",
       "  0.09781018644571304,\n",
       "  0.09716618061065674,\n",
       "  0.09653310477733612,\n",
       "  0.09591054171323776,\n",
       "  0.09529831260442734,\n",
       "  0.09469609707593918,\n",
       "  0.09410359710454941,\n",
       "  0.09352058917284012,\n",
       "  0.09294681251049042,\n",
       "  0.09238206595182419,\n",
       "  0.09182607382535934,\n",
       "  0.09127860516309738,\n",
       "  0.09073943644762039,\n",
       "  0.09020841866731644,\n",
       "  0.08968526124954224,\n",
       "  0.08916978538036346,\n",
       "  0.08866187185049057,\n",
       "  0.08816119283437729,\n",
       "  0.08766770362854004,\n",
       "  0.08718109130859375,\n",
       "  0.08670132607221603,\n",
       "  0.08622816205024719,\n",
       "  0.08576145023107529,\n",
       "  0.08530108630657196,\n",
       "  0.08484680950641632,\n",
       "  0.08439858257770538,\n",
       "  0.08395621925592422,\n",
       "  0.08351951092481613,\n",
       "  0.0830884799361229,\n",
       "  0.0826629176735878,\n",
       "  0.08224263787269592,\n",
       "  0.08182761818170547,\n",
       "  0.08141768723726273,\n",
       "  0.08101274073123932,\n",
       "  0.0806126743555069,\n",
       "  0.08021736145019531,\n",
       "  0.07982674986124039,\n",
       "  0.0794406607747078,\n",
       "  0.07905908674001694,\n",
       "  0.07868184894323349,\n",
       "  0.07830889523029327,\n",
       "  0.07794012129306793,\n",
       "  0.07757540047168732,\n",
       "  0.0772147849202156,\n",
       "  0.0768580362200737,\n",
       "  0.0765051618218422,\n",
       "  0.07615605741739273,\n",
       "  0.07581064105033875,\n",
       "  0.07546889036893845,\n",
       "  0.07513066381216049,\n",
       "  0.07479589432477951,\n",
       "  0.07446455210447311,\n",
       "  0.07413658499717712,\n",
       "  0.07381188869476318,\n",
       "  0.07349041104316711,\n",
       "  0.07317208498716354,\n",
       "  0.07285689562559128,\n",
       "  0.07254473865032196,\n",
       "  0.07223555445671082,\n",
       "  0.07192927598953247,\n",
       "  0.07162594050168991,\n",
       "  0.07132538408041,\n",
       "  0.07102760672569275,\n",
       "  0.07073260098695755,\n",
       "  0.07044025510549545,\n",
       "  0.07015051692724228,\n",
       "  0.06986343860626221,\n",
       "  0.06957880407571793,\n",
       "  0.06929675489664078,\n",
       "  0.06901713460683823,\n",
       "  0.06873992830514908,\n",
       "  0.06846509873867035,\n",
       "  0.06819263845682144,\n",
       "  0.06792241334915161,\n",
       "  0.06765448302030563,\n",
       "  0.06738879531621933,\n",
       "  0.06712528318166733,\n",
       "  0.06686393916606903,\n",
       "  0.06660471856594086,\n",
       "  0.06634755432605743,\n",
       "  0.06609245389699936,\n",
       "  0.06583938002586365,\n",
       "  0.06558831036090851,\n",
       "  0.06533922255039215,\n",
       "  0.06509203463792801,\n",
       "  0.06484677642583847,\n",
       "  0.06460336595773697,\n",
       "  0.06436184048652649,\n",
       "  0.06412211805582047,\n",
       "  0.0638841763138771,\n",
       "  0.0636480301618576,\n",
       "  0.06341364234685898,\n",
       "  0.06318094581365585,\n",
       "  0.06294996291399002,\n",
       "  0.0627206414937973,\n",
       "  0.0624929741024971,\n",
       "  0.06226694583892822,\n",
       "  0.06204250827431679,\n",
       "  0.061819687485694885,\n",
       "  0.06159837543964386,\n",
       "  0.06137867644429207,\n",
       "  0.06116044521331787,\n",
       "  0.06094374507665634,\n",
       "  0.06072850525379181,\n",
       "  0.06051475554704666,\n",
       "  0.060302428901195526,\n",
       "  0.06009155139327049,\n",
       "  0.05988207086920738,\n",
       "  0.059673987329006195,\n",
       "  0.05946731194853783,\n",
       "  0.05926194787025452,\n",
       "  0.05905795842409134,\n",
       "  0.058855269104242325,\n",
       "  0.058653924614191055,\n",
       "  0.058453865349292755,\n",
       "  0.058255087584257126,\n",
       "  0.05805756524205208,\n",
       "  0.057861313223838806,\n",
       "  0.05766628310084343,\n",
       "  0.057472486048936844,\n",
       "  0.05727989226579666,\n",
       "  0.05708850920200348,\n",
       "  0.05689830705523491,\n",
       "  0.05670928955078125,\n",
       "  0.05652143433690071,\n",
       "  0.05633469298481941,\n",
       "  0.05614909902215004,\n",
       "  0.055964648723602295,\n",
       "  0.0557812824845314,\n",
       "  0.05559903383255005,\n",
       "  0.05541785806417465,\n",
       "  0.0552377812564373,\n",
       "  0.05505877360701561,\n",
       "  0.05488082394003868,\n",
       "  0.054703909903764725,\n",
       "  0.05452801659703255,\n",
       "  0.05435316264629364,\n",
       "  0.0541793629527092,\n",
       "  0.05400651693344116,\n",
       "  0.0538347102701664,\n",
       "  0.05366385728120804,\n",
       "  0.05349400267004967,\n",
       "  0.05332513153553009,\n",
       "  0.05315720662474632,\n",
       "  0.05299018695950508,\n",
       "  0.05282417684793472,\n",
       "  0.052659083157777786,\n",
       "  0.05249492824077606,\n",
       "  0.05233168229460716,\n",
       "  0.052169349044561386,\n",
       "  0.052007924765348434,\n",
       "  0.05184737592935562,\n",
       "  0.05168774351477623,\n",
       "  0.05152898654341698,\n",
       "  0.051371101289987564,\n",
       "  0.051214076578617096,\n",
       "  0.05105791240930557,\n",
       "  0.0509025938808918,\n",
       "  0.050748150795698166,\n",
       "  0.050594527274370193,\n",
       "  0.05044173076748848,\n",
       "  0.050289757549762726,\n",
       "  0.050138622522354126,\n",
       "  0.0499882809817791,\n",
       "  0.04983876273036003,\n",
       "  0.04969004914164543,\n",
       "  0.0495421327650547,\n",
       "  0.04939497634768486,\n",
       "  0.049248628318309784,\n",
       "  0.049103062599897385,\n",
       "  0.04895826056599617,\n",
       "  0.04881422966718674,\n",
       "  0.048670947551727295,\n",
       "  0.04852840676903725,\n",
       "  0.04838666319847107,\n",
       "  0.048245616257190704,\n",
       "  0.048105333000421524,\n",
       "  0.04796578735113144,\n",
       "  0.047826945781707764,\n",
       "  0.04768887162208557,\n",
       "  0.0475514680147171,\n",
       "  0.04741482809185982,\n",
       "  0.04727887734770775,\n",
       "  0.04714363068342209,\n",
       "  0.047009073197841644,\n",
       "  0.04687520116567612,\n",
       "  0.046742040663957596,\n",
       "  0.046609584242105484,\n",
       "  0.04647776484489441,\n",
       "  0.04634663462638855,\n",
       "  0.04621618986129761,\n",
       "  0.04608640447258949,\n",
       "  0.045957304537296295,\n",
       "  0.04582884535193443,\n",
       "  0.0457010418176651,\n",
       "  0.045573893934488297,\n",
       "  0.04544739052653313,\n",
       "  0.045321546494960785,\n",
       "  0.04519632086157799,\n",
       "  0.045071739703416824,\n",
       "  0.04494775831699371,\n",
       "  0.04482445865869522,\n",
       "  0.04470175877213478,\n",
       "  0.044579677283763885,\n",
       "  0.04445821791887283,\n",
       "  0.04433738440275192,\n",
       "  0.04421713948249817,\n",
       "  0.04409750550985336,\n",
       "  0.0439784862101078,\n",
       "  0.043860048055648804,\n",
       "  0.043742213398218155,\n",
       "  0.043624959886074066,\n",
       "  0.04350830987095833,\n",
       "  0.04339222609996796,\n",
       "  0.04327673092484474,\n",
       "  0.043161824345588684,\n",
       "  0.043047476559877396,\n",
       "  0.04293372109532356,\n",
       "  0.0428205206990242,\n",
       "  0.042707864195108414,\n",
       "  0.04259583353996277,\n",
       "  0.042484283447265625,\n",
       "  0.04237333685159683,\n",
       "  0.04226292669773102,\n",
       "  0.04215307906270027,\n",
       "  0.04204374924302101,\n",
       "  0.04193498194217682,\n",
       "  0.04182674363255501,\n",
       "  0.04171907901763916,\n",
       "  0.0416119284927845,\n",
       "  0.041505277156829834,\n",
       "  0.04139917343854904,\n",
       "  0.04129361733794212,\n",
       "  0.041188549250364304,\n",
       "  0.04108402505517006,\n",
       "  0.040980011224746704,\n",
       "  0.04087652266025543,\n",
       "  0.040773503482341766,\n",
       "  0.04067104309797287,\n",
       "  0.04056907072663307,\n",
       "  0.040467582643032074,\n",
       "  0.040366608649492264,\n",
       "  0.04026613384485245,\n",
       "  0.04016614332795143,\n",
       "  0.0400666780769825,\n",
       "  0.03996765613555908,\n",
       "  0.039869144558906555,\n",
       "  0.03977112099528313,\n",
       "  0.039673563092947006,\n",
       "  0.039576511830091476,\n",
       "  0.03947991505265236,\n",
       "  0.039383791387081146,\n",
       "  0.03928813710808754,\n",
       "  0.03919296711683273,\n",
       "  0.03909826651215553,\n",
       "  0.03900401294231415,\n",
       "  0.03891023248434067,\n",
       "  0.038816895335912704,\n",
       "  0.03872403874993324,\n",
       "  0.03863160312175751,\n",
       "  0.03853965923190117,\n",
       "  0.03844812139868736,\n",
       "  0.03835708647966385,\n",
       "  0.03826644644141197,\n",
       "  0.0381762832403183,\n",
       "  0.038086533546447754,\n",
       "  0.03799721971154213,\n",
       "  0.037908390164375305,\n",
       "  0.037819936871528625,\n",
       "  0.037731967866420746,\n",
       "  0.037644367665052414,\n",
       "  0.03755722567439079,\n",
       "  0.03747052326798439,\n",
       "  0.037384212017059326,\n",
       "  0.03729834780097008,\n",
       "  0.03721289709210396,\n",
       "  0.03712784871459007,\n",
       "  0.03704323247075081,\n",
       "  0.036958999931812286,\n",
       "  0.03687519207596779,\n",
       "  0.03679180145263672,\n",
       "  0.03670879080891609,\n",
       "  0.03662621229887009,\n",
       "  0.03654402866959572,\n",
       "  0.03646222501993179,\n",
       "  0.036380838602781296,\n",
       "  0.03629982843995094,\n",
       "  0.03621922433376312,\n",
       "  0.03613901138305664,\n",
       "  0.0360591821372509,\n",
       "  0.035979729145765305,\n",
       "  0.035900671035051346,\n",
       "  0.03582201898097992,\n",
       "  0.03574370965361595,\n",
       "  0.035665784031152725,\n",
       "  0.03558824583888054,\n",
       "  0.03551110625267029,\n",
       "  0.0354342982172966,\n",
       "  0.035357873886823654,\n",
       "  0.035281822085380554,\n",
       "  0.035206153988838196,\n",
       "  0.035130828619003296,\n",
       "  0.035055868327617645,\n",
       "  0.034981269389390945,\n",
       "  0.03490704670548439,\n",
       "  0.034833166748285294,\n",
       "  0.03475964069366455,\n",
       "  0.03468647599220276,\n",
       "  0.034613657742738724,\n",
       "  0.034541185945272446,\n",
       "  0.03446907177567482,\n",
       "  0.034397318959236145,\n",
       "  0.03432587906718254,\n",
       "  0.034254804253578186,\n",
       "  0.0341840460896492,\n",
       "  0.03411364555358887,\n",
       "  0.034043580293655396,\n",
       "  0.03397385776042938,\n",
       "  0.03390445560216904,\n",
       "  0.03383539989590645,\n",
       "  0.03376665711402893,\n",
       "  0.03369826823472977,\n",
       "  0.033630188554525375,\n",
       "  0.033562421798706055,\n",
       "  0.03349502384662628,\n",
       "  0.0334278866648674,\n",
       "  0.033361129462718964,\n",
       "  0.03329465538263321,\n",
       "  0.033228494226932526,\n",
       "  0.033162686973810196,\n",
       "  0.033097147941589355,\n",
       "  0.03303194418549538,\n",
       "  0.03296704217791557,\n",
       "  0.032902467995882034,\n",
       "  0.03283818066120148,\n",
       "  0.032774198800325394,\n",
       "  0.03271053358912468,\n",
       "  0.03264716640114784,\n",
       "  0.03258410096168518,\n",
       "  0.0325213223695755,\n",
       "  0.032458867877721786,\n",
       "  0.032396674156188965,\n",
       "  0.032334815710783005,\n",
       "  0.03227321058511734,\n",
       "  0.03221191093325615,\n",
       "  0.03215089067816734,\n",
       "  0.0320901945233345,\n",
       "  0.03202974051237106,\n",
       "  0.0319695845246315,\n",
       "  0.031909745186567307,\n",
       "  0.03185015544295311,\n",
       "  0.03179087117314339,\n",
       "  0.03173181787133217,\n",
       "  0.03167308121919632,\n",
       "  0.03161461278796196],\n",
       " [1.0429978370666504,\n",
       "  1.0227532386779785,\n",
       "  1.0027432441711426,\n",
       "  0.9829700589179993,\n",
       "  0.9634389877319336,\n",
       "  0.9441532492637634,\n",
       "  0.9251177310943604,\n",
       "  0.9063351154327393,\n",
       "  0.8878093957901001,\n",
       "  0.8695433139801025,\n",
       "  0.8515398502349854,\n",
       "  0.8338014483451843,\n",
       "  0.8163300156593323,\n",
       "  0.7991279363632202,\n",
       "  0.782196044921875,\n",
       "  0.765536367893219,\n",
       "  0.7491500973701477,\n",
       "  0.7330373525619507,\n",
       "  0.7171991467475891,\n",
       "  0.7016357183456421,\n",
       "  0.6863470673561096,\n",
       "  0.6713328957557678,\n",
       "  0.6565924286842346,\n",
       "  0.6421253085136414,\n",
       "  0.6279305815696716,\n",
       "  0.6140064597129822,\n",
       "  0.6003518104553223,\n",
       "  0.5869651436805725,\n",
       "  0.5738444924354553,\n",
       "  0.5609878897666931,\n",
       "  0.5483927726745605,\n",
       "  0.5360569953918457,\n",
       "  0.523978054523468,\n",
       "  0.512153148651123,\n",
       "  0.5005796551704407,\n",
       "  0.48925450444221497,\n",
       "  0.4781746566295624,\n",
       "  0.4673369228839874,\n",
       "  0.45673808455467224,\n",
       "  0.4463750123977661,\n",
       "  0.43624427914619446,\n",
       "  0.4263421297073364,\n",
       "  0.41666528582572937,\n",
       "  0.40720996260643005,\n",
       "  0.3979731798171997,\n",
       "  0.3889507055282593,\n",
       "  0.3801390826702118,\n",
       "  0.3715347349643707,\n",
       "  0.36313390731811523,\n",
       "  0.3549327850341797,\n",
       "  0.34692779183387756,\n",
       "  0.339115172624588,\n",
       "  0.3314913809299469,\n",
       "  0.324052631855011,\n",
       "  0.31679511070251465,\n",
       "  0.30971553921699524,\n",
       "  0.3028101325035095,\n",
       "  0.2960750460624695,\n",
       "  0.2895070016384125,\n",
       "  0.2831023931503296,\n",
       "  0.27685773372650146,\n",
       "  0.2707693576812744,\n",
       "  0.26483428478240967,\n",
       "  0.2590487599372864,\n",
       "  0.25340962409973145,\n",
       "  0.24791330099105835,\n",
       "  0.24255676567554474,\n",
       "  0.23733669519424438,\n",
       "  0.23225031793117523,\n",
       "  0.22729383409023285,\n",
       "  0.22246462106704712,\n",
       "  0.21775951981544495,\n",
       "  0.2131757140159607,\n",
       "  0.20871014893054962,\n",
       "  0.20436006784439087,\n",
       "  0.2001224011182785,\n",
       "  0.19599461555480957,\n",
       "  0.19197402894496918,\n",
       "  0.18805772066116333,\n",
       "  0.18424342572689056,\n",
       "  0.18052828311920166,\n",
       "  0.17691005766391754,\n",
       "  0.17338591814041138,\n",
       "  0.16995356976985931,\n",
       "  0.166610985994339,\n",
       "  0.16335554420948029,\n",
       "  0.1601850837469101,\n",
       "  0.15709726512432098,\n",
       "  0.1540900617837906,\n",
       "  0.15116137266159058,\n",
       "  0.14830906689167023,\n",
       "  0.14553119242191315,\n",
       "  0.14282569289207458,\n",
       "  0.14019058644771576,\n",
       "  0.1376240849494934,\n",
       "  0.13512443006038666,\n",
       "  0.1326894760131836,\n",
       "  0.130317822098732,\n",
       "  0.1280076801776886,\n",
       "  0.12575732171535492,\n",
       "  0.12356516718864441,\n",
       "  0.12142962962388992,\n",
       "  0.11934909969568253,\n",
       "  0.11732210963964462,\n",
       "  0.11534705013036728,\n",
       "  0.11342275887727737,\n",
       "  0.11154768615961075,\n",
       "  0.1097203716635704,\n",
       "  0.1079396978020668,\n",
       "  0.10620417445898056,\n",
       "  0.10451262444257736,\n",
       "  0.10286395251750946,\n",
       "  0.10125678032636642,\n",
       "  0.09968998283147812,\n",
       "  0.0981624647974968,\n",
       "  0.09667313098907471,\n",
       "  0.09522102028131485,\n",
       "  0.09380483627319336,\n",
       "  0.09242365509271622,\n",
       "  0.09107668697834015,\n",
       "  0.0897628590464592,\n",
       "  0.0884811282157898,\n",
       "  0.08723068237304688,\n",
       "  0.08601061999797821,\n",
       "  0.08482015877962112,\n",
       "  0.08365843445062637,\n",
       "  0.08252464979887009,\n",
       "  0.08141791075468063,\n",
       "  0.08033764362335205,\n",
       "  0.07928292453289032,\n",
       "  0.07825318723917007,\n",
       "  0.07724767178297043,\n",
       "  0.07626569271087646,\n",
       "  0.07530656456947327,\n",
       "  0.07436967641115189,\n",
       "  0.07345438748598099,\n",
       "  0.07256024330854416,\n",
       "  0.07168646901845932,\n",
       "  0.07083261013031006,\n",
       "  0.06999810039997101,\n",
       "  0.06918230652809143,\n",
       "  0.06838489323854446,\n",
       "  0.0676051452755928,\n",
       "  0.06684275716543198,\n",
       "  0.06609711050987244,\n",
       "  0.06536787003278732,\n",
       "  0.06465454399585724,\n",
       "  0.06395666301250458,\n",
       "  0.0632738545536995,\n",
       "  0.06260569393634796,\n",
       "  0.06195181608200073,\n",
       "  0.06131180748343468,\n",
       "  0.06068522110581398,\n",
       "  0.060071710497140884,\n",
       "  0.05947107449173927,\n",
       "  0.05888288840651512,\n",
       "  0.058306798338890076,\n",
       "  0.057742465287446976,\n",
       "  0.057189714163541794,\n",
       "  0.05664801225066185,\n",
       "  0.056117307394742966,\n",
       "  0.05559711530804634,\n",
       "  0.055087290704250336,\n",
       "  0.054587505757808685,\n",
       "  0.054097484797239304,\n",
       "  0.053617075085639954,\n",
       "  0.05314596742391586,\n",
       "  0.052683912217617035,\n",
       "  0.052230581641197205,\n",
       "  0.05178594961762428,\n",
       "  0.0513496957719326,\n",
       "  0.05092160403728485,\n",
       "  0.05050145462155342,\n",
       "  0.05008908361196518,\n",
       "  0.049684345722198486,\n",
       "  0.04928687959909439,\n",
       "  0.04889671504497528,\n",
       "  0.04851354658603668,\n",
       "  0.04813716188073158,\n",
       "  0.04776754602789879,\n",
       "  0.04740443453192711,\n",
       "  0.04704763740301132,\n",
       "  0.046697091311216354,\n",
       "  0.04635253921151161,\n",
       "  0.046013880521059036,\n",
       "  0.04568104445934296,\n",
       "  0.045353833585977554,\n",
       "  0.04503209888935089,\n",
       "  0.04471566900610924,\n",
       "  0.044404536485672,\n",
       "  0.044098515063524246,\n",
       "  0.04379742220044136,\n",
       "  0.043501272797584534,\n",
       "  0.04320981726050377,\n",
       "  0.04292304441332817,\n",
       "  0.04264077916741371,\n",
       "  0.042362965643405914,\n",
       "  0.04208947345614433,\n",
       "  0.04182017967104912,\n",
       "  0.04155504330992699,\n",
       "  0.0412939228117466,\n",
       "  0.041036784648895264,\n",
       "  0.04078347608447075,\n",
       "  0.04053396359086037,\n",
       "  0.04028812795877457,\n",
       "  0.040045883506536484,\n",
       "  0.039807144552469254,\n",
       "  0.0395718477666378,\n",
       "  0.03933992236852646,\n",
       "  0.03911127150058746,\n",
       "  0.03888585418462753,\n",
       "  0.03866352140903473,\n",
       "  0.03844437375664711,\n",
       "  0.03822817653417587,\n",
       "  0.03801492229104042,\n",
       "  0.03780456632375717,\n",
       "  0.03759700059890747,\n",
       "  0.037392184138298035,\n",
       "  0.037190064787864685,\n",
       "  0.03699062764644623,\n",
       "  0.03679370507597923,\n",
       "  0.036599379032850266,\n",
       "  0.03640749678015709,\n",
       "  0.03621801361441612,\n",
       "  0.03603092208504677,\n",
       "  0.03584614768624306,\n",
       "  0.0356636606156826,\n",
       "  0.03548339381814003,\n",
       "  0.03530529513955116,\n",
       "  0.03512934595346451,\n",
       "  0.034955501556396484,\n",
       "  0.034783706068992615,\n",
       "  0.03461388126015663,\n",
       "  0.03444603830575943,\n",
       "  0.03428010642528534,\n",
       "  0.03411613404750824,\n",
       "  0.0339539609849453,\n",
       "  0.0337936133146286,\n",
       "  0.03363504633307457,\n",
       "  0.03347824141383171,\n",
       "  0.03332313522696495,\n",
       "  0.0331696942448616,\n",
       "  0.03301787003874779,\n",
       "  0.03286774083971977,\n",
       "  0.03271913528442383,\n",
       "  0.032572127878665924,\n",
       "  0.03242659196257591,\n",
       "  0.03228255733847618,\n",
       "  0.03214005008339882,\n",
       "  0.03199892118573189,\n",
       "  0.031859226524829865,\n",
       "  0.031720902770757675,\n",
       "  0.031584013253450394,\n",
       "  0.03144838660955429,\n",
       "  0.03131408989429474,\n",
       "  0.031181074678897858,\n",
       "  0.031049376353621483,\n",
       "  0.030918888747692108,\n",
       "  0.03078964538872242,\n",
       "  0.030661555007100105,\n",
       "  0.03053474985063076,\n",
       "  0.030409039929509163,\n",
       "  0.03028443455696106,\n",
       "  0.030160993337631226,\n",
       "  0.030038682743906975,\n",
       "  0.029917391017079353,\n",
       "  0.029797233641147614,\n",
       "  0.02967810072004795,\n",
       "  0.02955998107790947,\n",
       "  0.029442887753248215,\n",
       "  0.029326824471354485,\n",
       "  0.029211711138486862,\n",
       "  0.02909758873283863,\n",
       "  0.028984425589442253,\n",
       "  0.028872186318039894,\n",
       "  0.02876092679798603,\n",
       "  0.028650479391217232,\n",
       "  0.028540993109345436,\n",
       "  0.028432385995984077,\n",
       "  0.02832465060055256,\n",
       "  0.028217725455760956,\n",
       "  0.02811170183122158,\n",
       "  0.028006481006741524,\n",
       "  0.02790210396051407,\n",
       "  0.027798503637313843,\n",
       "  0.027695726603269577,\n",
       "  0.027593737468123436,\n",
       "  0.027492504566907883,\n",
       "  0.027392065152525902,\n",
       "  0.027292359620332718,\n",
       "  0.027193404734134674,\n",
       "  0.027095196768641472,\n",
       "  0.026997709646821022,\n",
       "  0.026900924742221832,\n",
       "  0.026804866269230843,\n",
       "  0.026709474623203278,\n",
       "  0.02661479264497757,\n",
       "  0.02652077004313469,\n",
       "  0.026427406817674637,\n",
       "  0.02633475698530674,\n",
       "  0.026242733001708984,\n",
       "  0.026151375845074654,\n",
       "  0.026060618460178375,\n",
       "  0.02597053162753582,\n",
       "  0.025881046429276466,\n",
       "  0.025792188942432404,\n",
       "  0.025703953579068184,\n",
       "  0.02561633102595806,\n",
       "  0.02552923746407032,\n",
       "  0.02544281631708145,\n",
       "  0.025356929749250412,\n",
       "  0.025271626189351082,\n",
       "  0.025186896324157715,\n",
       "  0.025102699175477028,\n",
       "  0.0250190868973732,\n",
       "  0.024936020374298096,\n",
       "  0.024853540584445,\n",
       "  0.024771587923169136,\n",
       "  0.024690134450793266,\n",
       "  0.024609221145510674,\n",
       "  0.02452882006764412,\n",
       "  0.024448974058032036,\n",
       "  0.024369575083255768,\n",
       "  0.024290751665830612,\n",
       "  0.024212442338466644,\n",
       "  0.02413460798561573,\n",
       "  0.02405722811818123,\n",
       "  0.0239803958684206,\n",
       "  0.02390400692820549,\n",
       "  0.02382814697921276,\n",
       "  0.02375272661447525,\n",
       "  0.02367781475186348,\n",
       "  0.023603318259119987,\n",
       "  0.023529328405857086,\n",
       "  0.023455791175365448,\n",
       "  0.023382695391774178,\n",
       "  0.023310042917728424,\n",
       "  0.02323787845671177,\n",
       "  0.023166131228208542,\n",
       "  0.02309480495750904,\n",
       "  0.02302394062280655,\n",
       "  0.02295350842177868,\n",
       "  0.022883540019392967,\n",
       "  0.022813934832811356,\n",
       "  0.022744793444871902,\n",
       "  0.02267606183886528,\n",
       "  0.022607728838920593,\n",
       "  0.022539863362908363,\n",
       "  0.022472349926829338,\n",
       "  0.022405290976166725,\n",
       "  0.022338615730404854,\n",
       "  0.022272318601608276,\n",
       "  0.022206414490938187,\n",
       "  0.022140933200716972,\n",
       "  0.02207585796713829,\n",
       "  0.022011157125234604,\n",
       "  0.02194683998823166,\n",
       "  0.021882910281419754,\n",
       "  0.02181936241686344,\n",
       "  0.02175617404282093,\n",
       "  0.02169337496161461,\n",
       "  0.02163095958530903,\n",
       "  0.021568913012742996,\n",
       "  0.021507205441594124,\n",
       "  0.02144588902592659,\n",
       "  0.021384941413998604,\n",
       "  0.021324338391423225,\n",
       "  0.02126411721110344,\n",
       "  0.02120419591665268,\n",
       "  0.021144691854715347,\n",
       "  0.02108556404709816,\n",
       "  0.021026717498898506,\n",
       "  0.020968260243535042,\n",
       "  0.020910101011395454,\n",
       "  0.020852284505963326,\n",
       "  0.020794861018657684,\n",
       "  0.020737774670124054,\n",
       "  0.020681001245975494,\n",
       "  0.020624570548534393,\n",
       "  0.020568490028381348,\n",
       "  0.02051270566880703,\n",
       "  0.020457245409488678,\n",
       "  0.020402126014232635,\n",
       "  0.020347310230135918,\n",
       "  0.020292840898036957,\n",
       "  0.020238708704710007,\n",
       "  0.020184876397252083,\n",
       "  0.020131364464759827,\n",
       "  0.020078144967556,\n",
       "  0.020025284960865974,\n",
       "  0.019972719252109528,\n",
       "  0.019920436665415764,\n",
       "  0.019868463277816772,\n",
       "  0.019816819578409195,\n",
       "  0.01976548321545124,\n",
       "  0.019714420661330223,\n",
       "  0.019663695245981216,\n",
       "  0.019613252952694893,\n",
       "  0.019563110545277596,\n",
       "  0.01951325498521328,\n",
       "  0.01946370117366314,\n",
       "  0.01941443793475628,\n",
       "  0.019365454092621803,\n",
       "  0.019316794350743294,\n",
       "  0.01926838606595993,\n",
       "  0.01922030560672283,\n",
       "  0.01917247101664543,\n",
       "  0.019124923273921013,\n",
       "  0.019077660515904427,\n",
       "  0.019030684605240822,\n",
       "  0.018984002992510796,\n",
       "  0.01893758587539196,\n",
       "  0.01889141835272312,\n",
       "  0.018845554441213608,\n",
       "  0.018799973651766777,\n",
       "  0.018754620105028152,\n",
       "  0.01870957762002945,\n",
       "  0.018664775416254997,\n",
       "  0.01862025074660778,\n",
       "  0.018576014786958694,\n",
       "  0.01853199489414692,\n",
       "  0.018488282337784767,\n",
       "  0.01844480074942112,\n",
       "  0.01840158924460411,\n",
       "  0.018358660861849785,\n",
       "  0.01831596903502941,\n",
       "  0.01827351376414299,\n",
       "  0.018231326714158058,\n",
       "  0.01818942464888096,\n",
       "  0.01814773492515087,\n",
       "  0.018106339499354362,\n",
       "  0.018065176904201508,\n",
       "  0.01802421733736992,\n",
       "  0.01798352785408497,\n",
       "  0.017943125218153,\n",
       "  0.0179029181599617,\n",
       "  0.01786298304796219,\n",
       "  0.017823277041316032,\n",
       "  0.01778382621705532,\n",
       "  0.017744580283761024,\n",
       "  0.017705613747239113,\n",
       "  0.01766684092581272,\n",
       "  0.017628364264965057,\n",
       "  0.017590103670954704,\n",
       "  0.017552059143781662,\n",
       "  0.01751420646905899,\n",
       "  0.0174766406416893,\n",
       "  0.017439275979995728,\n",
       "  0.01740216091275215,\n",
       "  0.01736525632441044,\n",
       "  0.017328601330518723,\n",
       "  0.017292149364948273,\n",
       "  0.017255930230021477,\n",
       "  0.01721993274986744,\n",
       "  0.017184142023324966,\n",
       "  0.017148584127426147,\n",
       "  0.01711326651275158,\n",
       "  0.01707811839878559,\n",
       "  0.017043238505721092,\n",
       "  0.017008565366268158,\n",
       "  0.016974089667201042,\n",
       "  0.016939805820584297,\n",
       "  0.0169057734310627,\n",
       "  0.016871921718120575,\n",
       "  0.016838310286402702,\n",
       "  0.016804922372102737,\n",
       "  0.016771705821156502,\n",
       "  0.016738705337047577,\n",
       "  0.016705917194485664,\n",
       "  0.01667335443198681,\n",
       "  0.016640949994325638,\n",
       "  0.016608774662017822,\n",
       "  0.016576804220676422,\n",
       "  0.01654500514268875,\n",
       "  0.016513438895344734,\n",
       "  0.016482077538967133,\n",
       "  0.016450906172394753,\n",
       "  0.016419924795627594,\n",
       "  0.016389112919569016,\n",
       "  0.016358530148863792,\n",
       "  0.016328146681189537,\n",
       "  0.016297953203320503,\n",
       "  0.016267908737063408,\n",
       "  0.016238093376159668,\n",
       "  0.016208471730351448,\n",
       "  0.016179025173187256,\n",
       "  0.016149789094924927,\n",
       "  0.01612071692943573,\n",
       "  0.016091831028461456,\n",
       "  0.016063142567873,\n",
       "  0.016034619882702827,\n",
       "  0.01600630208849907,\n",
       "  0.015978172421455383,\n",
       "  0.015950195491313934,\n",
       "  0.01592242158949375,\n",
       "  0.015894806012511253,\n",
       "  0.01586737670004368,\n",
       "  0.015840141102671623,\n",
       "  0.015813050791621208,\n",
       "  0.015786172822117805])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[\"loss\"], history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 1.5150 - val_loss: 1.5806\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4782 - val_loss: 1.5449\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4419 - val_loss: 1.5098\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4061 - val_loss: 1.4751\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3709 - val_loss: 1.4410\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3362 - val_loss: 1.4073\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3021 - val_loss: 1.3742\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2685 - val_loss: 1.3415\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2355 - val_loss: 1.3094\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2030 - val_loss: 1.2778\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1711 - val_loss: 1.2468\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1398 - val_loss: 1.2163\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1091 - val_loss: 1.1863\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0790 - val_loss: 1.1568\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0495 - val_loss: 1.1279\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0205 - val_loss: 1.0996\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9922 - val_loss: 1.0718\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9644 - val_loss: 1.0445\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9372 - val_loss: 1.0178\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9107 - val_loss: 0.9917\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8847 - val_loss: 0.9661\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8593 - val_loss: 0.9410\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8345 - val_loss: 0.9165\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8103 - val_loss: 0.8925\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7866 - val_loss: 0.8691\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7636 - val_loss: 0.8462\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7411 - val_loss: 0.8238\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7192 - val_loss: 0.8020\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6979 - val_loss: 0.7806\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6771 - val_loss: 0.7598\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6569 - val_loss: 0.7395\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6372 - val_loss: 0.7197\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6180 - val_loss: 0.7004\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5994 - val_loss: 0.6816\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5813 - val_loss: 0.6633\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5638 - val_loss: 0.6455\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5467 - val_loss: 0.6282\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5302 - val_loss: 0.6113\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5141 - val_loss: 0.5949\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4986 - val_loss: 0.5789\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4835 - val_loss: 0.5634\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4688 - val_loss: 0.5483\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4547 - val_loss: 0.5336\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4410 - val_loss: 0.5194\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4277 - val_loss: 0.5056\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4149 - val_loss: 0.4922\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4024 - val_loss: 0.4792\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3904 - val_loss: 0.4666\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3788 - val_loss: 0.4544\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3676 - val_loss: 0.4425\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3568 - val_loss: 0.4310\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3464 - val_loss: 0.4199\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3363 - val_loss: 0.4091\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3266 - val_loss: 0.3987\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3172 - val_loss: 0.3886\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3082 - val_loss: 0.3788\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2995 - val_loss: 0.3694\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2911 - val_loss: 0.3603\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2830 - val_loss: 0.3514\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2752 - val_loss: 0.3429\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2677 - val_loss: 0.3346\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2605 - val_loss: 0.3267\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2536 - val_loss: 0.3190\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2469 - val_loss: 0.3115\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2405 - val_loss: 0.3043\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2343 - val_loss: 0.2974\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2284 - val_loss: 0.2907\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2227 - val_loss: 0.2843\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2173 - val_loss: 0.2780\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2120 - val_loss: 0.2720\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2070 - val_loss: 0.2662\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2022 - val_loss: 0.2606\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1975 - val_loss: 0.2553\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1931 - val_loss: 0.2501\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1888 - val_loss: 0.2451\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1847 - val_loss: 0.2402\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1807 - val_loss: 0.2356\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1769 - val_loss: 0.2311\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1733 - val_loss: 0.2267\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1698 - val_loss: 0.2226\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1665 - val_loss: 0.2186\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1633 - val_loss: 0.2147\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1602 - val_loss: 0.2109\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1573 - val_loss: 0.2073\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1544 - val_loss: 0.2039\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1517 - val_loss: 0.2005\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1491 - val_loss: 0.1973\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1466 - val_loss: 0.1942\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1442 - val_loss: 0.1912\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1419 - val_loss: 0.1883\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1396 - val_loss: 0.1855\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1375 - val_loss: 0.1828\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1354 - val_loss: 0.1802\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1335 - val_loss: 0.1777\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1316 - val_loss: 0.1752\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1297 - val_loss: 0.1729\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1280 - val_loss: 0.1706\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1263 - val_loss: 0.1684\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1246 - val_loss: 0.1663\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1231 - val_loss: 0.1643\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1215 - val_loss: 0.1623\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1201 - val_loss: 0.1604\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1187 - val_loss: 0.1585\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1173 - val_loss: 0.1567\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1160 - val_loss: 0.1550\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1147 - val_loss: 0.1533\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1135 - val_loss: 0.1516\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1123 - val_loss: 0.1501\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1111 - val_loss: 0.1485\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1100 - val_loss: 0.1470\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1089 - val_loss: 0.1456\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1078 - val_loss: 0.1442\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1068 - val_loss: 0.1428\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1058 - val_loss: 0.1414\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1048 - val_loss: 0.1401\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1039 - val_loss: 0.1389\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1030 - val_loss: 0.1376\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1021 - val_loss: 0.1364\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1012 - val_loss: 0.1353\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1004 - val_loss: 0.1341\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0996 - val_loss: 0.1330\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0988 - val_loss: 0.1319\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0980 - val_loss: 0.1309\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0972 - val_loss: 0.1298\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0965 - val_loss: 0.1288\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0957 - val_loss: 0.1278\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0950 - val_loss: 0.1269\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0943 - val_loss: 0.1259\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0936 - val_loss: 0.1250\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0930 - val_loss: 0.1241\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0923 - val_loss: 0.1232\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0917 - val_loss: 0.1223\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0910 - val_loss: 0.1215\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0904 - val_loss: 0.1206\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0898 - val_loss: 0.1198\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0892 - val_loss: 0.1190\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0886 - val_loss: 0.1182\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0881 - val_loss: 0.1174\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0875 - val_loss: 0.1167\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0870 - val_loss: 0.1159\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0864 - val_loss: 0.1152\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0859 - val_loss: 0.1145\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0854 - val_loss: 0.1138\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0848 - val_loss: 0.1131\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0843 - val_loss: 0.1124\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0838 - val_loss: 0.1117\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0833 - val_loss: 0.1110\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0829 - val_loss: 0.1104\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0824 - val_loss: 0.1097\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0819 - val_loss: 0.1091\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0815 - val_loss: 0.1085\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0810 - val_loss: 0.1079\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0806 - val_loss: 0.1072\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0801 - val_loss: 0.1066\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0797 - val_loss: 0.1061\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0792 - val_loss: 0.1055\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0788 - val_loss: 0.1049\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0784 - val_loss: 0.1043\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0780 - val_loss: 0.1038\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0776 - val_loss: 0.1032\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0772 - val_loss: 0.1027\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0768 - val_loss: 0.1022\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0764 - val_loss: 0.1016\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0760 - val_loss: 0.1011\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0756 - val_loss: 0.1006\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0753 - val_loss: 0.1001\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0749 - val_loss: 0.0996\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0745 - val_loss: 0.0991\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0742 - val_loss: 0.0986\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0738 - val_loss: 0.0982\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0735 - val_loss: 0.0977\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0731 - val_loss: 0.0972\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0728 - val_loss: 0.0968\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0724 - val_loss: 0.0963\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0721 - val_loss: 0.0959\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0718 - val_loss: 0.0954\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0714 - val_loss: 0.0950\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0711 - val_loss: 0.0945\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0708 - val_loss: 0.0941\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0705 - val_loss: 0.0937\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0701 - val_loss: 0.0933\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0698 - val_loss: 0.0929\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0695 - val_loss: 0.0925\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0692 - val_loss: 0.0920\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0689 - val_loss: 0.0917\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0683 - val_loss: 0.0909\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0680 - val_loss: 0.0905\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0677 - val_loss: 0.0901\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0675 - val_loss: 0.0897\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0672 - val_loss: 0.0894\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0669 - val_loss: 0.0890\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0666 - val_loss: 0.0886\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0663 - val_loss: 0.0883\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0661 - val_loss: 0.0879\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0658 - val_loss: 0.0876\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0655 - val_loss: 0.0872\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0653 - val_loss: 0.0869\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0650 - val_loss: 0.0866\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0648 - val_loss: 0.0862\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0645 - val_loss: 0.0859\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0642 - val_loss: 0.0856\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0640 - val_loss: 0.0852\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0637 - val_loss: 0.0849\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0635 - val_loss: 0.0846\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0632 - val_loss: 0.0843\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0630 - val_loss: 0.0840\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0628 - val_loss: 0.0837\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0625 - val_loss: 0.0834\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0623 - val_loss: 0.0831\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0620 - val_loss: 0.0828\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0618 - val_loss: 0.0825\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0616 - val_loss: 0.0822\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0614 - val_loss: 0.0819\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0611 - val_loss: 0.0816\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0609 - val_loss: 0.0813\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0607 - val_loss: 0.0811\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0605 - val_loss: 0.0808\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0602 - val_loss: 0.0805\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0600 - val_loss: 0.0803\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0598 - val_loss: 0.0800\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0596 - val_loss: 0.0797\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0594 - val_loss: 0.0795\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0592 - val_loss: 0.0792\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0590 - val_loss: 0.0790\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0587 - val_loss: 0.0787\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0585 - val_loss: 0.0785\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0583 - val_loss: 0.0782\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0581 - val_loss: 0.0780\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0579 - val_loss: 0.0777\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0577 - val_loss: 0.0775\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0575 - val_loss: 0.0772\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0573 - val_loss: 0.0770\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0571 - val_loss: 0.0768\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0570 - val_loss: 0.0765\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0568 - val_loss: 0.0763\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0566 - val_loss: 0.0761\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0564 - val_loss: 0.0759\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0562 - val_loss: 0.0757\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0560 - val_loss: 0.0754\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0558 - val_loss: 0.0752\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0556 - val_loss: 0.0750\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0555 - val_loss: 0.0748\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0553 - val_loss: 0.0746\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0551 - val_loss: 0.0744\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0549 - val_loss: 0.0742\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0547 - val_loss: 0.0740\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0546 - val_loss: 0.0738\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0544 - val_loss: 0.0736\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0542 - val_loss: 0.0734\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0540 - val_loss: 0.0732\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0539 - val_loss: 0.0730\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0537 - val_loss: 0.0728\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0535 - val_loss: 0.0726\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0534 - val_loss: 0.0724\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0532 - val_loss: 0.0722\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0530 - val_loss: 0.0720\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0529 - val_loss: 0.0719\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0527 - val_loss: 0.0717\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0525 - val_loss: 0.0715\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0524 - val_loss: 0.0713\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0522 - val_loss: 0.0711\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0521 - val_loss: 0.0710\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0519 - val_loss: 0.0708\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0517 - val_loss: 0.0706\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0516 - val_loss: 0.0705\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0514 - val_loss: 0.0703\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0513 - val_loss: 0.0701\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0511 - val_loss: 0.0700\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0510 - val_loss: 0.0698\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0508 - val_loss: 0.0696\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0507 - val_loss: 0.0695\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0505 - val_loss: 0.0693\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0504 - val_loss: 0.0692\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0502 - val_loss: 0.0690\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0501 - val_loss: 0.0689\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0499 - val_loss: 0.0687\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0498 - val_loss: 0.0686\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0496 - val_loss: 0.0684\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0495 - val_loss: 0.0683\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0494 - val_loss: 0.0681\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0492 - val_loss: 0.0680\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0491 - val_loss: 0.0678\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0489 - val_loss: 0.0677\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0488 - val_loss: 0.0676\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0487 - val_loss: 0.0674\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0485 - val_loss: 0.0673\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0484 - val_loss: 0.0672\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0483 - val_loss: 0.0670\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0481 - val_loss: 0.0669\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0480 - val_loss: 0.0668\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0479 - val_loss: 0.0666\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0477 - val_loss: 0.0665\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0476 - val_loss: 0.0664\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0475 - val_loss: 0.0662\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0473 - val_loss: 0.0661\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0472 - val_loss: 0.0660\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0471 - val_loss: 0.0659\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0470 - val_loss: 0.0658\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0468 - val_loss: 0.0656\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0467 - val_loss: 0.0655\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0466 - val_loss: 0.0654\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0465 - val_loss: 0.0653\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0463 - val_loss: 0.0652\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0462 - val_loss: 0.0651\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0461 - val_loss: 0.0649\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0460 - val_loss: 0.0648\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0459 - val_loss: 0.0647\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0457 - val_loss: 0.0646\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0456 - val_loss: 0.0645\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0455 - val_loss: 0.0644\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0454 - val_loss: 0.0643\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0453 - val_loss: 0.0642\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0452 - val_loss: 0.0641\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0450 - val_loss: 0.0640\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0449 - val_loss: 0.0639\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0448 - val_loss: 0.0638\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0447 - val_loss: 0.0637\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0446 - val_loss: 0.0636\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0445 - val_loss: 0.0635\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0444 - val_loss: 0.0634\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0443 - val_loss: 0.0633\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0442 - val_loss: 0.0632\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0440 - val_loss: 0.0631\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0439 - val_loss: 0.0630\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0438 - val_loss: 0.0629\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0437 - val_loss: 0.0628\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0436 - val_loss: 0.0628\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0435 - val_loss: 0.0627\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0434 - val_loss: 0.0626\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0433 - val_loss: 0.0625\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0432 - val_loss: 0.0624\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0431 - val_loss: 0.0623\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0430 - val_loss: 0.0622\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0429 - val_loss: 0.0622\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0428 - val_loss: 0.0621\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0427 - val_loss: 0.0620\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0426 - val_loss: 0.0619\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0425 - val_loss: 0.0618\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0424 - val_loss: 0.0618\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0423 - val_loss: 0.0617\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0422 - val_loss: 0.0616\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0421 - val_loss: 0.0615\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0420 - val_loss: 0.0615\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0419 - val_loss: 0.0614\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0418 - val_loss: 0.0613\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0417 - val_loss: 0.0613\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0416 - val_loss: 0.0612\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0415 - val_loss: 0.0611\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0414 - val_loss: 0.0611\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0413 - val_loss: 0.0610\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0412 - val_loss: 0.0609\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0412 - val_loss: 0.0609\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0411 - val_loss: 0.0608\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.0607\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0409 - val_loss: 0.0607\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0408 - val_loss: 0.0606\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0407 - val_loss: 0.0605\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0406 - val_loss: 0.0605\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0405 - val_loss: 0.0604\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0404 - val_loss: 0.0604\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0403 - val_loss: 0.0603\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0403 - val_loss: 0.0602\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0402 - val_loss: 0.0602\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0401 - val_loss: 0.0601\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0400 - val_loss: 0.0601\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0399 - val_loss: 0.0600\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0398 - val_loss: 0.0600\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0397 - val_loss: 0.0599\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0397 - val_loss: 0.0599\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0396 - val_loss: 0.0598\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0395 - val_loss: 0.0598\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0394 - val_loss: 0.0597\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0393 - val_loss: 0.0597\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0393 - val_loss: 0.0596\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0392 - val_loss: 0.0596\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0391 - val_loss: 0.0595\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0390 - val_loss: 0.0595\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0389 - val_loss: 0.0594\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0389 - val_loss: 0.0594\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0388 - val_loss: 0.0593\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0387 - val_loss: 0.0593\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0386 - val_loss: 0.0592\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0385 - val_loss: 0.0592\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0385 - val_loss: 0.0592\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0384 - val_loss: 0.0591\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0383 - val_loss: 0.0591\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0382 - val_loss: 0.0590\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0382 - val_loss: 0.0590\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0381 - val_loss: 0.0590\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - val_loss: 0.0589\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0379 - val_loss: 0.0589\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0379 - val_loss: 0.0588\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0378 - val_loss: 0.0588\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0377 - val_loss: 0.0588\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0376 - val_loss: 0.0587\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0376 - val_loss: 0.0587\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0375 - val_loss: 0.0587\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0374 - val_loss: 0.0586\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0374 - val_loss: 0.0586\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0373 - val_loss: 0.0586\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0372 - val_loss: 0.0585\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0372 - val_loss: 0.0585\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0371 - val_loss: 0.0585\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0370 - val_loss: 0.0584\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0369 - val_loss: 0.0584\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0369 - val_loss: 0.0584\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0368 - val_loss: 0.0584\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0367 - val_loss: 0.0583\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - val_loss: 0.0583\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0366 - val_loss: 0.0583\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0365 - val_loss: 0.0582\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0365 - val_loss: 0.0582\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0364 - val_loss: 0.0582\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0363 - val_loss: 0.0582\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0363 - val_loss: 0.0581\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0362 - val_loss: 0.0581\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0361 - val_loss: 0.0581\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0361 - val_loss: 0.0581\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.0580\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0360 - val_loss: 0.0580\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0359 - val_loss: 0.0580\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0358 - val_loss: 0.0580\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0358 - val_loss: 0.0580\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - val_loss: 0.0579\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0356 - val_loss: 0.0579\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0356 - val_loss: 0.0579\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0355 - val_loss: 0.0579\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0355 - val_loss: 0.0579\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0354 - val_loss: 0.0578\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0353 - val_loss: 0.0578\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0353 - val_loss: 0.0578\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0352 - val_loss: 0.0578\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0352 - val_loss: 0.0578\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0351 - val_loss: 0.0578\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0350 - val_loss: 0.0577\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.0577\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0349 - val_loss: 0.0577\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0349 - val_loss: 0.0577\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0348 - val_loss: 0.0577\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0348 - val_loss: 0.0577\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0347 - val_loss: 0.0577\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.0577\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0346 - val_loss: 0.0576\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0345 - val_loss: 0.0576\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0345 - val_loss: 0.0576\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0344 - val_loss: 0.0576\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0344 - val_loss: 0.0576\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0343 - val_loss: 0.0576\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0343 - val_loss: 0.0576\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0342 - val_loss: 0.0576\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0341 - val_loss: 0.0576\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0341 - val_loss: 0.0575\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0340 - val_loss: 0.0575\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0340 - val_loss: 0.0575\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0339 - val_loss: 0.0575\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0339 - val_loss: 0.0575\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0338 - val_loss: 0.0575\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0338 - val_loss: 0.0575\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0575\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0575\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0336 - val_loss: 0.0575\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0336 - val_loss: 0.0575\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0335 - val_loss: 0.0575\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0335 - val_loss: 0.0575\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0334 - val_loss: 0.0575\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0334 - val_loss: 0.0575\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0333 - val_loss: 0.0575\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0333 - val_loss: 0.0574\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0332 - val_loss: 0.0574\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0332 - val_loss: 0.0574\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0331 - val_loss: 0.0574\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0331 - val_loss: 0.0574\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0574\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0330 - val_loss: 0.0574\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0329 - val_loss: 0.0574\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0329 - val_loss: 0.0574\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0328 - val_loss: 0.0574\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0328 - val_loss: 0.0574\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0327 - val_loss: 0.0574\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0327 - val_loss: 0.0574\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0326 - val_loss: 0.0574\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0326 - val_loss: 0.0574\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0326 - val_loss: 0.0574\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0325 - val_loss: 0.0574\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0325 - val_loss: 0.0574\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0324 - val_loss: 0.0574\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0324 - val_loss: 0.0574\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0323 - val_loss: 0.0574\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - val_loss: 0.0574\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0322 - val_loss: 0.0574\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0322 - val_loss: 0.0574\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0321 - val_loss: 0.0574\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0321 - val_loss: 0.0574\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0321 - val_loss: 0.0574\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0320 - val_loss: 0.0574\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0320 - val_loss: 0.0575\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0319 - val_loss: 0.0575\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0319 - val_loss: 0.0575\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0318 - val_loss: 0.0575\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0318 - val_loss: 0.0575\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0318 - val_loss: 0.0575\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0317 - val_loss: 0.0575\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0317 - val_loss: 0.0575\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0316 - val_loss: 0.0575\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0316 - val_loss: 0.0575\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0315 - val_loss: 0.0575\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0315 - val_loss: 0.0575\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0315 - val_loss: 0.0575\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0314 - val_loss: 0.0575\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0314 - val_loss: 0.0575\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0313 - val_loss: 0.0575\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0313 - val_loss: 0.0575\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0313 - val_loss: 0.0575\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0312 - val_loss: 0.0575\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0312 - val_loss: 0.0576\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0311 - val_loss: 0.0576\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0311 - val_loss: 0.0576\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0311 - val_loss: 0.0576\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0310 - val_loss: 0.0576\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0310 - val_loss: 0.0576\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0309 - val_loss: 0.0576\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0309 - val_loss: 0.0576\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0309 - val_loss: 0.0576\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0308 - val_loss: 0.0576\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0308 - val_loss: 0.0576\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0308 - val_loss: 0.0576\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0307 - val_loss: 0.0576\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0307 - val_loss: 0.0577\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0306 - val_loss: 0.0577\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0306 - val_loss: 0.0577\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0306 - val_loss: 0.0577\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0305 - val_loss: 0.0577\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0577\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0305 - val_loss: 0.0577\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0304 - val_loss: 0.0577\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0304 - val_loss: 0.0577\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0304 - val_loss: 0.0577\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - val_loss: 0.0578\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - val_loss: 0.0578\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0302 - val_loss: 0.0578\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0302 - val_loss: 0.0578\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0302 - val_loss: 0.0578\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - val_loss: 0.0578\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0301 - val_loss: 0.0578\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - val_loss: 0.0578\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0300 - val_loss: 0.0578\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0300 - val_loss: 0.0579\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0300 - val_loss: 0.0579\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0299 - val_loss: 0.0579\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0299 - val_loss: 0.0579\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0299 - val_loss: 0.0579\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0298 - val_loss: 0.0579\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0298 - val_loss: 0.0579\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0298 - val_loss: 0.0579\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0297 - val_loss: 0.0579\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0297 - val_loss: 0.0580\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0297 - val_loss: 0.0580\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0296 - val_loss: 0.0580\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0296 - val_loss: 0.0580\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0296 - val_loss: 0.0580\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0295 - val_loss: 0.0580\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0295 - val_loss: 0.0580\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0295 - val_loss: 0.0580\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0294 - val_loss: 0.0581\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0294 - val_loss: 0.0581\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0294 - val_loss: 0.0581\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0293 - val_loss: 0.0581\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0293 - val_loss: 0.0581\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0293 - val_loss: 0.0581\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0292 - val_loss: 0.0581\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - val_loss: 0.0581\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - val_loss: 0.0582\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0292 - val_loss: 0.0582\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0291 - val_loss: 0.0582\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0291 - val_loss: 0.0582\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0291 - val_loss: 0.0582\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0290 - val_loss: 0.0582\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0290 - val_loss: 0.0582\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0290 - val_loss: 0.0583\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0289 - val_loss: 0.0583\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0289 - val_loss: 0.0583\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - val_loss: 0.0583\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0288 - val_loss: 0.0583\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0288 - val_loss: 0.0583\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0288 - val_loss: 0.0583\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0288 - val_loss: 0.0584\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0287 - val_loss: 0.0584\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0287 - val_loss: 0.0584\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0287 - val_loss: 0.0584\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0286 - val_loss: 0.0584\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0286 - val_loss: 0.0584\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0286 - val_loss: 0.0584\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0286 - val_loss: 0.0585\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0285 - val_loss: 0.0585\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0285 - val_loss: 0.0585\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0285 - val_loss: 0.0585\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0284 - val_loss: 0.0585\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0284 - val_loss: 0.0585\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0284 - val_loss: 0.0585\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.5289 - val_loss: 1.2080\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4875 - val_loss: 1.1754\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4468 - val_loss: 1.1433\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4068 - val_loss: 1.1116\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3673 - val_loss: 1.0805\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3285 - val_loss: 1.0500\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2904 - val_loss: 1.0199\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2530 - val_loss: 0.9904\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2162 - val_loss: 0.9615\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1802 - val_loss: 0.9331\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1448 - val_loss: 0.9052\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1101 - val_loss: 0.8779\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0761 - val_loss: 0.8512\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0429 - val_loss: 0.8250\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0103 - val_loss: 0.7994\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9784 - val_loss: 0.7743\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9473 - val_loss: 0.7498\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9169 - val_loss: 0.7259\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8872 - val_loss: 0.7026\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8582 - val_loss: 0.6797\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8299 - val_loss: 0.6575\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8023 - val_loss: 0.6358\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7754 - val_loss: 0.6147\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7492 - val_loss: 0.5941\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7237 - val_loss: 0.5741\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6989 - val_loss: 0.5546\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6748 - val_loss: 0.5357\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6513 - val_loss: 0.5172\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6285 - val_loss: 0.4994\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6064 - val_loss: 0.4820\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5850 - val_loss: 0.4651\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5642 - val_loss: 0.4488\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5440 - val_loss: 0.4330\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5245 - val_loss: 0.4176\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5055 - val_loss: 0.4028\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4872 - val_loss: 0.3884\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4695 - val_loss: 0.3745\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4524 - val_loss: 0.3611\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4358 - val_loss: 0.3481\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4199 - val_loss: 0.3356\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4044 - val_loss: 0.3235\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3896 - val_loss: 0.3118\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3752 - val_loss: 0.3006\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3614 - val_loss: 0.2898\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3481 - val_loss: 0.2793\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3353 - val_loss: 0.2693\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3229 - val_loss: 0.2597\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3111 - val_loss: 0.2504\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2997 - val_loss: 0.2415\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2887 - val_loss: 0.2330\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2782 - val_loss: 0.2247\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2682 - val_loss: 0.2169\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2585 - val_loss: 0.2093\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2492 - val_loss: 0.2021\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2404 - val_loss: 0.1952\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2319 - val_loss: 0.1886\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2237 - val_loss: 0.1823\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2159 - val_loss: 0.1762\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2085 - val_loss: 0.1704\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2014 - val_loss: 0.1649\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1946 - val_loss: 0.1597\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1881 - val_loss: 0.1546\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1820 - val_loss: 0.1498\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1761 - val_loss: 0.1453\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1705 - val_loss: 0.1409\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1651 - val_loss: 0.1368\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1600 - val_loss: 0.1329\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1552 - val_loss: 0.1291\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1505 - val_loss: 0.1256\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1461 - val_loss: 0.1222\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1420 - val_loss: 0.1190\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1380 - val_loss: 0.1159\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1342 - val_loss: 0.1130\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1307 - val_loss: 0.1103\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1273 - val_loss: 0.1077\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1240 - val_loss: 0.1052\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1210 - val_loss: 0.1028\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1181 - val_loss: 0.1006\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1153 - val_loss: 0.0985\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1127 - val_loss: 0.0965\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1102 - val_loss: 0.0946\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1079 - val_loss: 0.0928\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1056 - val_loss: 0.0911\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1035 - val_loss: 0.0895\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1015 - val_loss: 0.0879\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0996 - val_loss: 0.0864\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0978 - val_loss: 0.0851\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0961 - val_loss: 0.0837\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0945 - val_loss: 0.0825\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0929 - val_loss: 0.0813\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0915 - val_loss: 0.0801\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0901 - val_loss: 0.0791\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0888 - val_loss: 0.0780\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0875 - val_loss: 0.0770\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0863 - val_loss: 0.0761\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0852 - val_loss: 0.0752\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0841 - val_loss: 0.0743\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0831 - val_loss: 0.0735\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0821 - val_loss: 0.0727\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0803 - val_loss: 0.0712\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0794 - val_loss: 0.0705\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0786 - val_loss: 0.0698\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0778 - val_loss: 0.0691\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0771 - val_loss: 0.0685\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0763 - val_loss: 0.0679\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0756 - val_loss: 0.0673\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0750 - val_loss: 0.0667\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0743 - val_loss: 0.0661\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0737 - val_loss: 0.0656\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0731 - val_loss: 0.0650\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0726 - val_loss: 0.0645\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0720 - val_loss: 0.0640\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0715 - val_loss: 0.0635\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0710 - val_loss: 0.0630\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0704 - val_loss: 0.0625\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0700 - val_loss: 0.0620\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0695 - val_loss: 0.0615\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0690 - val_loss: 0.0610\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0686 - val_loss: 0.0606\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0681 - val_loss: 0.0601\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0677 - val_loss: 0.0597\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0673 - val_loss: 0.0592\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0669 - val_loss: 0.0588\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0665 - val_loss: 0.0584\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0661 - val_loss: 0.0579\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0657 - val_loss: 0.0575\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0654 - val_loss: 0.0571\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0650 - val_loss: 0.0567\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0646 - val_loss: 0.0563\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0643 - val_loss: 0.0559\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0639 - val_loss: 0.0555\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0636 - val_loss: 0.0551\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0633 - val_loss: 0.0547\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0630 - val_loss: 0.0543\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0626 - val_loss: 0.0539\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0623 - val_loss: 0.0535\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0620 - val_loss: 0.0531\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0617 - val_loss: 0.0527\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0614 - val_loss: 0.0524\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0611 - val_loss: 0.0520\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0608 - val_loss: 0.0516\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0605 - val_loss: 0.0513\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0603 - val_loss: 0.0509\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0600 - val_loss: 0.0505\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0597 - val_loss: 0.0502\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0595 - val_loss: 0.0498\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0592 - val_loss: 0.0495\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0589 - val_loss: 0.0491\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0587 - val_loss: 0.0488\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0584 - val_loss: 0.0484\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0582 - val_loss: 0.0481\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0579 - val_loss: 0.0477\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0577 - val_loss: 0.0474\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0574 - val_loss: 0.0471\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0572 - val_loss: 0.0468\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0570 - val_loss: 0.0464\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0567 - val_loss: 0.0461\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0565 - val_loss: 0.0458\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0563 - val_loss: 0.0455\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0561 - val_loss: 0.0452\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0558 - val_loss: 0.0449\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0556 - val_loss: 0.0446\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0554 - val_loss: 0.0443\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0552 - val_loss: 0.0440\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0550 - val_loss: 0.0437\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0548 - val_loss: 0.0434\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0546 - val_loss: 0.0431\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0544 - val_loss: 0.0428\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0542 - val_loss: 0.0425\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0540 - val_loss: 0.0422\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0538 - val_loss: 0.0420\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0536 - val_loss: 0.0417\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0534 - val_loss: 0.0414\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0533 - val_loss: 0.0412\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0531 - val_loss: 0.0409\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0529 - val_loss: 0.0406\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0527 - val_loss: 0.0404\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0525 - val_loss: 0.0401\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0524 - val_loss: 0.0399\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0522 - val_loss: 0.0396\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0520 - val_loss: 0.0394\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0518 - val_loss: 0.0392\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0517 - val_loss: 0.0389\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0515 - val_loss: 0.0387\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0514 - val_loss: 0.0385\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0512 - val_loss: 0.0382\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0510 - val_loss: 0.0380\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0509 - val_loss: 0.0378\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0507 - val_loss: 0.0376\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0506 - val_loss: 0.0373\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0504 - val_loss: 0.0371\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0503 - val_loss: 0.0369\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0501 - val_loss: 0.0367\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0500 - val_loss: 0.0365\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0498 - val_loss: 0.0363\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0497 - val_loss: 0.0361\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0495 - val_loss: 0.0359\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0494 - val_loss: 0.0357\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0493 - val_loss: 0.0355\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0491 - val_loss: 0.0353\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0490 - val_loss: 0.0352\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0488 - val_loss: 0.0350\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0487 - val_loss: 0.0348\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0486 - val_loss: 0.0346\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0484 - val_loss: 0.0345\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0483 - val_loss: 0.0343\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0482 - val_loss: 0.0341\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0481 - val_loss: 0.0339\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0479 - val_loss: 0.0338\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0478 - val_loss: 0.0336\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0477 - val_loss: 0.0335\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0476 - val_loss: 0.0333\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0474 - val_loss: 0.0332\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0473 - val_loss: 0.0330\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0472 - val_loss: 0.0328\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0471 - val_loss: 0.0327\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0470 - val_loss: 0.0326\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0469 - val_loss: 0.0324\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0467 - val_loss: 0.0323\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0466 - val_loss: 0.0321\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0465 - val_loss: 0.0320\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0464 - val_loss: 0.0319\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0463 - val_loss: 0.0317\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0462 - val_loss: 0.0316\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0461 - val_loss: 0.0315\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0460 - val_loss: 0.0313\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0459 - val_loss: 0.0312\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0458 - val_loss: 0.0311\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0457 - val_loss: 0.0310\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0456 - val_loss: 0.0309\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0455 - val_loss: 0.0307\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0454 - val_loss: 0.0306\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0453 - val_loss: 0.0305\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0452 - val_loss: 0.0304\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0451 - val_loss: 0.0303\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0450 - val_loss: 0.0302\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0449 - val_loss: 0.0301\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0448 - val_loss: 0.0300\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0447 - val_loss: 0.0299\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0446 - val_loss: 0.0298\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0445 - val_loss: 0.0297\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0444 - val_loss: 0.0296\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0443 - val_loss: 0.0295\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0442 - val_loss: 0.0294\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0441 - val_loss: 0.0293\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0440 - val_loss: 0.0292\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0439 - val_loss: 0.0291\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0439 - val_loss: 0.0290\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0438 - val_loss: 0.0289\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0437 - val_loss: 0.0289\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0436 - val_loss: 0.0288\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0434 - val_loss: 0.0286\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0433 - val_loss: 0.0285\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0433 - val_loss: 0.0285\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0432 - val_loss: 0.0284\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0431 - val_loss: 0.0283\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0430 - val_loss: 0.0282\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0429 - val_loss: 0.0281\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0429 - val_loss: 0.0281\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0428 - val_loss: 0.0280\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0427 - val_loss: 0.0279\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0426 - val_loss: 0.0279\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0425 - val_loss: 0.0278\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0425 - val_loss: 0.0277\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0424 - val_loss: 0.0277\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0423 - val_loss: 0.0276\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0422 - val_loss: 0.0275\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0422 - val_loss: 0.0275\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0421 - val_loss: 0.0274\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0420 - val_loss: 0.0274\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0419 - val_loss: 0.0273\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0419 - val_loss: 0.0272\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0418 - val_loss: 0.0272\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0417 - val_loss: 0.0271\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0417 - val_loss: 0.0271\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0416 - val_loss: 0.0270\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0415 - val_loss: 0.0270\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0414 - val_loss: 0.0269\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0414 - val_loss: 0.0269\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0413 - val_loss: 0.0268\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0412 - val_loss: 0.0268\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0412 - val_loss: 0.0267\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0411 - val_loss: 0.0267\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0410 - val_loss: 0.0266\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0410 - val_loss: 0.0266\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0409 - val_loss: 0.0265\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0408 - val_loss: 0.0265\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0408 - val_loss: 0.0264\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0407 - val_loss: 0.0264\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0406 - val_loss: 0.0263\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0406 - val_loss: 0.0263\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0405 - val_loss: 0.0263\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0405 - val_loss: 0.0262\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0404 - val_loss: 0.0262\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0403 - val_loss: 0.0261\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0403 - val_loss: 0.0261\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0402 - val_loss: 0.0261\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0402 - val_loss: 0.0260\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0401 - val_loss: 0.0260\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0400 - val_loss: 0.0259\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0400 - val_loss: 0.0259\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0399 - val_loss: 0.0259\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0399 - val_loss: 0.0258\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0398 - val_loss: 0.0258\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0397 - val_loss: 0.0258\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0397 - val_loss: 0.0257\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0396 - val_loss: 0.0257\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0396 - val_loss: 0.0257\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0395 - val_loss: 0.0256\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0395 - val_loss: 0.0256\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0394 - val_loss: 0.0256\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0393 - val_loss: 0.0256\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0393 - val_loss: 0.0255\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0392 - val_loss: 0.0255\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0392 - val_loss: 0.0255\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0391 - val_loss: 0.0254\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0391 - val_loss: 0.0254\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0390 - val_loss: 0.0254\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0390 - val_loss: 0.0254\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0389 - val_loss: 0.0253\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0389 - val_loss: 0.0253\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0388 - val_loss: 0.0253\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0388 - val_loss: 0.0253\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0387 - val_loss: 0.0252\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0387 - val_loss: 0.0252\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0386 - val_loss: 0.0252\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0386 - val_loss: 0.0252\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0385 - val_loss: 0.0251\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0385 - val_loss: 0.0251\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0384 - val_loss: 0.0251\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0384 - val_loss: 0.0251\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0383 - val_loss: 0.0251\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0383 - val_loss: 0.0250\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0382 - val_loss: 0.0250\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0382 - val_loss: 0.0250\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0381 - val_loss: 0.0250\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0381 - val_loss: 0.0250\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - val_loss: 0.0249\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0380 - val_loss: 0.0249\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0379 - val_loss: 0.0249\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0379 - val_loss: 0.0249\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0378 - val_loss: 0.0249\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0378 - val_loss: 0.0249\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0377 - val_loss: 0.0248\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0377 - val_loss: 0.0248\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0377 - val_loss: 0.0248\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0376 - val_loss: 0.0248\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0376 - val_loss: 0.0248\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0375 - val_loss: 0.0248\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0375 - val_loss: 0.0247\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0374 - val_loss: 0.0247\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0374 - val_loss: 0.0247\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0373 - val_loss: 0.0247\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0373 - val_loss: 0.0247\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0373 - val_loss: 0.0247\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0372 - val_loss: 0.0247\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0372 - val_loss: 0.0246\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0371 - val_loss: 0.0246\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0371 - val_loss: 0.0246\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0371 - val_loss: 0.0246\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0370 - val_loss: 0.0246\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0370 - val_loss: 0.0246\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0369 - val_loss: 0.0246\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0369 - val_loss: 0.0246\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0368 - val_loss: 0.0245\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0368 - val_loss: 0.0245\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0368 - val_loss: 0.0245\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0367 - val_loss: 0.0245\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0367 - val_loss: 0.0245\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0366 - val_loss: 0.0245\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0366 - val_loss: 0.0245\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0366 - val_loss: 0.0245\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0365 - val_loss: 0.0245\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0365 - val_loss: 0.0244\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0365 - val_loss: 0.0244\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0364 - val_loss: 0.0244\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0364 - val_loss: 0.0244\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0363 - val_loss: 0.0244\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0363 - val_loss: 0.0244\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0363 - val_loss: 0.0244\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - val_loss: 0.0243\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0361 - val_loss: 0.0243\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.0243\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.0243\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0360 - val_loss: 0.0243\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0359 - val_loss: 0.0243\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0359 - val_loss: 0.0243\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0359 - val_loss: 0.0243\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0357 - val_loss: 0.0243\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - val_loss: 0.0243\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0357 - val_loss: 0.0242\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0356 - val_loss: 0.0242\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0356 - val_loss: 0.0242\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0356 - val_loss: 0.0242\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0355 - val_loss: 0.0242\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0355 - val_loss: 0.0242\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0355 - val_loss: 0.0242\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0354 - val_loss: 0.0242\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0354 - val_loss: 0.0242\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0354 - val_loss: 0.0242\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0352 - val_loss: 0.0242\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0352 - val_loss: 0.0242\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0352 - val_loss: 0.0242\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0351 - val_loss: 0.0242\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0351 - val_loss: 0.0241\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0351 - val_loss: 0.0241\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0350 - val_loss: 0.0241\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0350 - val_loss: 0.0241\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0350 - val_loss: 0.0241\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.0241\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0349 - val_loss: 0.0241\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0349 - val_loss: 0.0241\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0349 - val_loss: 0.0241\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0348 - val_loss: 0.0241\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0348 - val_loss: 0.0241\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0348 - val_loss: 0.0241\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0347 - val_loss: 0.0241\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0347 - val_loss: 0.0241\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0347 - val_loss: 0.0241\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0347 - val_loss: 0.0241\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0346 - val_loss: 0.0241\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.0241\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - val_loss: 0.0241\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0345 - val_loss: 0.0241\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0345 - val_loss: 0.0241\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0345 - val_loss: 0.0241\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0345 - val_loss: 0.0240\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0344 - val_loss: 0.0240\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0344 - val_loss: 0.0240\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0344 - val_loss: 0.0240\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0343 - val_loss: 0.0240\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0343 - val_loss: 0.0240\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0343 - val_loss: 0.0240\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0343 - val_loss: 0.0240\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0341 - val_loss: 0.0240\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0341 - val_loss: 0.0240\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0341 - val_loss: 0.0240\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0339 - val_loss: 0.0240\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0339 - val_loss: 0.0240\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0339 - val_loss: 0.0240\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0339 - val_loss: 0.0240\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0338 - val_loss: 0.0240\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0338 - val_loss: 0.0240\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0338 - val_loss: 0.0240\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0338 - val_loss: 0.0240\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0336 - val_loss: 0.0239\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0239\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0336 - val_loss: 0.0239\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0336 - val_loss: 0.0239\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0334 - val_loss: 0.0239\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0334 - val_loss: 0.0239\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0334 - val_loss: 0.0239\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0334 - val_loss: 0.0239\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0333 - val_loss: 0.0239\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0333 - val_loss: 0.0239\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0333 - val_loss: 0.0239\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0333 - val_loss: 0.0239\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0331 - val_loss: 0.0239\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0331 - val_loss: 0.0239\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0331 - val_loss: 0.0239\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0331 - val_loss: 0.0239\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0329 - val_loss: 0.0239\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0328 - val_loss: 0.0239\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0328 - val_loss: 0.0239\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0328 - val_loss: 0.0239\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0328 - val_loss: 0.0239\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0239\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0239\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0239\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0239\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0238\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0325 - val_loss: 0.0238\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0325 - val_loss: 0.0238\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0325 - val_loss: 0.0238\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0325 - val_loss: 0.0238\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0325 - val_loss: 0.0238\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0323 - val_loss: 0.0238\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0320 - val_loss: 0.0238\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0318 - val_loss: 0.0238\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0317 - val_loss: 0.0238\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0317 - val_loss: 0.0238\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0317 - val_loss: 0.0238\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0317 - val_loss: 0.0238\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0317 - val_loss: 0.0238\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0316 - val_loss: 0.0238\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - val_loss: 0.0238\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0314 - val_loss: 0.0238\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0313 - val_loss: 0.0238\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0312 - val_loss: 0.0238\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0311 - val_loss: 0.0238\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.9343 - val_loss: 1.2750\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9048 - val_loss: 1.2439\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8759 - val_loss: 1.2132\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8476 - val_loss: 1.1831\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8199 - val_loss: 1.1535\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7928 - val_loss: 1.1244\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7664 - val_loss: 1.0958\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7406 - val_loss: 1.0678\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7155 - val_loss: 1.0403\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6910 - val_loss: 1.0134\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6672 - val_loss: 0.9871\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6440 - val_loss: 0.9613\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6215 - val_loss: 0.9360\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5997 - val_loss: 0.9114\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5785 - val_loss: 0.8873\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5579 - val_loss: 0.8638\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5380 - val_loss: 0.8408\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5188 - val_loss: 0.8185\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5002 - val_loss: 0.7967\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4822 - val_loss: 0.7755\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4649 - val_loss: 0.7548\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4482 - val_loss: 0.7347\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4321 - val_loss: 0.7152\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4166 - val_loss: 0.6963\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4017 - val_loss: 0.6779\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3873 - val_loss: 0.6600\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3736 - val_loss: 0.6427\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3604 - val_loss: 0.6259\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3477 - val_loss: 0.6097\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3356 - val_loss: 0.5940\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3240 - val_loss: 0.5788\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3128 - val_loss: 0.5640\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3022 - val_loss: 0.5498\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2921 - val_loss: 0.5361\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2824 - val_loss: 0.5229\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2731 - val_loss: 0.5101\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2643 - val_loss: 0.4978\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2559 - val_loss: 0.4859\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2479 - val_loss: 0.4744\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2403 - val_loss: 0.4634\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2331 - val_loss: 0.4528\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2262 - val_loss: 0.4426\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2196 - val_loss: 0.4327\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2134 - val_loss: 0.4233\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2075 - val_loss: 0.4142\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2019 - val_loss: 0.4055\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1965 - val_loss: 0.3971\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1915 - val_loss: 0.3890\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1867 - val_loss: 0.3813\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1821 - val_loss: 0.3739\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1778 - val_loss: 0.3667\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1736 - val_loss: 0.3599\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1697 - val_loss: 0.3533\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1660 - val_loss: 0.3471\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1625 - val_loss: 0.3410\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1592 - val_loss: 0.3352\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1560 - val_loss: 0.3297\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1530 - val_loss: 0.3244\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1501 - val_loss: 0.3193\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1474 - val_loss: 0.3144\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1448 - val_loss: 0.3097\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1423 - val_loss: 0.3052\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1400 - val_loss: 0.3009\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1377 - val_loss: 0.2967\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1356 - val_loss: 0.2927\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1335 - val_loss: 0.2889\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1315 - val_loss: 0.2853\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1297 - val_loss: 0.2818\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1279 - val_loss: 0.2784\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1261 - val_loss: 0.2752\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1245 - val_loss: 0.2721\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1229 - val_loss: 0.2691\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1213 - val_loss: 0.2662\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1198 - val_loss: 0.2634\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1184 - val_loss: 0.2608\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1170 - val_loss: 0.2582\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1157 - val_loss: 0.2557\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1144 - val_loss: 0.2534\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1132 - val_loss: 0.2511\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1119 - val_loss: 0.2488\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1107 - val_loss: 0.2467\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1096 - val_loss: 0.2446\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1085 - val_loss: 0.2427\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1074 - val_loss: 0.2407\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1063 - val_loss: 0.2389\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1053 - val_loss: 0.2371\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1043 - val_loss: 0.2353\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1033 - val_loss: 0.2336\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1023 - val_loss: 0.2320\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1013 - val_loss: 0.2304\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1004 - val_loss: 0.2288\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0995 - val_loss: 0.2273\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0986 - val_loss: 0.2258\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0977 - val_loss: 0.2244\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0969 - val_loss: 0.2230\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0960 - val_loss: 0.2217\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0952 - val_loss: 0.2204\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0943 - val_loss: 0.2191\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0935 - val_loss: 0.2178\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0927 - val_loss: 0.2166\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0920 - val_loss: 0.2154\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0912 - val_loss: 0.2142\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0904 - val_loss: 0.2131\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0897 - val_loss: 0.2120\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0889 - val_loss: 0.2109\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0882 - val_loss: 0.2098\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0875 - val_loss: 0.2088\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0868 - val_loss: 0.2078\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0861 - val_loss: 0.2068\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0854 - val_loss: 0.2058\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0847 - val_loss: 0.2048\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0840 - val_loss: 0.2039\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0834 - val_loss: 0.2030\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0827 - val_loss: 0.2021\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0821 - val_loss: 0.2012\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0814 - val_loss: 0.2003\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0808 - val_loss: 0.1994\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0802 - val_loss: 0.1986\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0796 - val_loss: 0.1978\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0790 - val_loss: 0.1970\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0784 - val_loss: 0.1962\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0778 - val_loss: 0.1954\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0772 - val_loss: 0.1946\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0766 - val_loss: 0.1939\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0761 - val_loss: 0.1931\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0755 - val_loss: 0.1924\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0750 - val_loss: 0.1917\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0744 - val_loss: 0.1910\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0739 - val_loss: 0.1903\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0733 - val_loss: 0.1896\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0728 - val_loss: 0.1889\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0723 - val_loss: 0.1882\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0718 - val_loss: 0.1876\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0713 - val_loss: 0.1870\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0708 - val_loss: 0.1863\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0703 - val_loss: 0.1857\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0698 - val_loss: 0.1851\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0693 - val_loss: 0.1845\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0688 - val_loss: 0.1839\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0684 - val_loss: 0.1833\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0679 - val_loss: 0.1827\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0674 - val_loss: 0.1822\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0670 - val_loss: 0.1816\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0665 - val_loss: 0.1810\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0661 - val_loss: 0.1805\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0657 - val_loss: 0.1800\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0652 - val_loss: 0.1794\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0648 - val_loss: 0.1789\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0644 - val_loss: 0.1784\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0640 - val_loss: 0.1779\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0635 - val_loss: 0.1774\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0631 - val_loss: 0.1769\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0627 - val_loss: 0.1764\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0623 - val_loss: 0.1759\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0619 - val_loss: 0.1754\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0615 - val_loss: 0.1749\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0612 - val_loss: 0.1745\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0608 - val_loss: 0.1740\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0604 - val_loss: 0.1735\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0600 - val_loss: 0.1731\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0597 - val_loss: 0.1726\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0593 - val_loss: 0.1722\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0589 - val_loss: 0.1717\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0586 - val_loss: 0.1713\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0582 - val_loss: 0.1709\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0579 - val_loss: 0.1705\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0575 - val_loss: 0.1700\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0572 - val_loss: 0.1696\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0569 - val_loss: 0.1692\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0565 - val_loss: 0.1688\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0562 - val_loss: 0.1684\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0559 - val_loss: 0.1680\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0556 - val_loss: 0.1676\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0552 - val_loss: 0.1672\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0549 - val_loss: 0.1668\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0546 - val_loss: 0.1664\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0543 - val_loss: 0.1660\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0540 - val_loss: 0.1657\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0537 - val_loss: 0.1653\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0534 - val_loss: 0.1649\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0531 - val_loss: 0.1645\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0528 - val_loss: 0.1642\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0525 - val_loss: 0.1638\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0523 - val_loss: 0.1635\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0520 - val_loss: 0.1631\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0517 - val_loss: 0.1628\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0514 - val_loss: 0.1624\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0512 - val_loss: 0.1621\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0509 - val_loss: 0.1617\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0506 - val_loss: 0.1614\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0504 - val_loss: 0.1610\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0501 - val_loss: 0.1607\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0498 - val_loss: 0.1604\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0496 - val_loss: 0.1601\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0493 - val_loss: 0.1597\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0491 - val_loss: 0.1594\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0488 - val_loss: 0.1591\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0486 - val_loss: 0.1588\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0483 - val_loss: 0.1585\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0481 - val_loss: 0.1582\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0479 - val_loss: 0.1579\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0476 - val_loss: 0.1575\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0474 - val_loss: 0.1572\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0472 - val_loss: 0.1569\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0470 - val_loss: 0.1566\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0467 - val_loss: 0.1564\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0465 - val_loss: 0.1561\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0463 - val_loss: 0.1558\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0461 - val_loss: 0.1555\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - val_loss: 0.1552\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0457 - val_loss: 0.1549\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0454 - val_loss: 0.1546\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0452 - val_loss: 0.1544\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0450 - val_loss: 0.1541\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0448 - val_loss: 0.1538\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0446 - val_loss: 0.1535\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0444 - val_loss: 0.1533\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0442 - val_loss: 0.1530\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0440 - val_loss: 0.1527\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0438 - val_loss: 0.1525\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0437 - val_loss: 0.1522\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0435 - val_loss: 0.1520\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0433 - val_loss: 0.1517\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0431 - val_loss: 0.1515\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0429 - val_loss: 0.1512\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0427 - val_loss: 0.1510\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0425 - val_loss: 0.1507\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0424 - val_loss: 0.1505\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0422 - val_loss: 0.1502\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0420 - val_loss: 0.1500\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0419 - val_loss: 0.1497\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0417 - val_loss: 0.1495\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0415 - val_loss: 0.1492\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0413 - val_loss: 0.1490\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0412 - val_loss: 0.1488\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.1485\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0409 - val_loss: 0.1483\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0407 - val_loss: 0.1481\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0405 - val_loss: 0.1479\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0404 - val_loss: 0.1476\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0402 - val_loss: 0.1474\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0401 - val_loss: 0.1472\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0399 - val_loss: 0.1470\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0398 - val_loss: 0.1467\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0396 - val_loss: 0.1465\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0395 - val_loss: 0.1463\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0393 - val_loss: 0.1461\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0392 - val_loss: 0.1459\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0390 - val_loss: 0.1456\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0389 - val_loss: 0.1454\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0388 - val_loss: 0.1452\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0386 - val_loss: 0.1450\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0385 - val_loss: 0.1448\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0384 - val_loss: 0.1446\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0382 - val_loss: 0.1444\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0381 - val_loss: 0.1442\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - val_loss: 0.1440\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0378 - val_loss: 0.1438\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0377 - val_loss: 0.1436\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0376 - val_loss: 0.1434\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0374 - val_loss: 0.1432\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0373 - val_loss: 0.1430\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0372 - val_loss: 0.1428\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0371 - val_loss: 0.1426\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0369 - val_loss: 0.1424\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0368 - val_loss: 0.1422\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0367 - val_loss: 0.1420\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0366 - val_loss: 0.1418\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0365 - val_loss: 0.1416\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0364 - val_loss: 0.1414\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0362 - val_loss: 0.1412\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0361 - val_loss: 0.1411\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0360 - val_loss: 0.1409\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0359 - val_loss: 0.1407\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0358 - val_loss: 0.1405\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0357 - val_loss: 0.1403\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0356 - val_loss: 0.1401\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0355 - val_loss: 0.1400\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0354 - val_loss: 0.1398\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0353 - val_loss: 0.1396\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0352 - val_loss: 0.1394\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0351 - val_loss: 0.1392\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0350 - val_loss: 0.1391\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0349 - val_loss: 0.1389\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0348 - val_loss: 0.1387\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0347 - val_loss: 0.1385\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0346 - val_loss: 0.1384\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0345 - val_loss: 0.1382\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0344 - val_loss: 0.1380\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0343 - val_loss: 0.1379\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0342 - val_loss: 0.1377\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0341 - val_loss: 0.1375\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0340 - val_loss: 0.1373\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0339 - val_loss: 0.1372\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0338 - val_loss: 0.1370\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.1368\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0336 - val_loss: 0.1367\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0335 - val_loss: 0.1365\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0335 - val_loss: 0.1364\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0334 - val_loss: 0.1362\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0333 - val_loss: 0.1360\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0332 - val_loss: 0.1359\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0331 - val_loss: 0.1357\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.1356\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0329 - val_loss: 0.1354\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0329 - val_loss: 0.1352\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0328 - val_loss: 0.1351\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - val_loss: 0.1349\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.1348\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0325 - val_loss: 0.1346\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0325 - val_loss: 0.1345\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0324 - val_loss: 0.1343\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0323 - val_loss: 0.1342\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0322 - val_loss: 0.1340\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0322 - val_loss: 0.1339\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0321 - val_loss: 0.1337\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0320 - val_loss: 0.1336\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0319 - val_loss: 0.1334\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0319 - val_loss: 0.1333\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0318 - val_loss: 0.1331\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0317 - val_loss: 0.1330\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0317 - val_loss: 0.1328\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0316 - val_loss: 0.1327\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0315 - val_loss: 0.1326\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0314 - val_loss: 0.1324\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0314 - val_loss: 0.1323\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0313 - val_loss: 0.1321\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0312 - val_loss: 0.1320\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0312 - val_loss: 0.1318\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0311 - val_loss: 0.1317\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0311 - val_loss: 0.1316\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0310 - val_loss: 0.1314\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0309 - val_loss: 0.1313\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0309 - val_loss: 0.1312\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0308 - val_loss: 0.1310\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0307 - val_loss: 0.1309\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0307 - val_loss: 0.1308\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0306 - val_loss: 0.1306\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0306 - val_loss: 0.1305\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0305 - val_loss: 0.1304\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0304 - val_loss: 0.1302\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0304 - val_loss: 0.1301\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0303 - val_loss: 0.1300\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0303 - val_loss: 0.1298\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0302 - val_loss: 0.1297\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0301 - val_loss: 0.1296\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0301 - val_loss: 0.1295\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0300 - val_loss: 0.1293\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0300 - val_loss: 0.1292\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0299 - val_loss: 0.1291\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0299 - val_loss: 0.1289\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0298 - val_loss: 0.1288\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0298 - val_loss: 0.1287\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0297 - val_loss: 0.1286\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0297 - val_loss: 0.1285\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0296 - val_loss: 0.1283\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0296 - val_loss: 0.1282\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0295 - val_loss: 0.1281\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0295 - val_loss: 0.1280\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0294 - val_loss: 0.1279\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0294 - val_loss: 0.1277\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0293 - val_loss: 0.1276\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0293 - val_loss: 0.1275\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0292 - val_loss: 0.1274\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0292 - val_loss: 0.1273\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0291 - val_loss: 0.1271\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0291 - val_loss: 0.1270\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0290 - val_loss: 0.1269\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0290 - val_loss: 0.1268\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0289 - val_loss: 0.1267\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0289 - val_loss: 0.1266\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0288 - val_loss: 0.1265\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0288 - val_loss: 0.1264\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0287 - val_loss: 0.1262\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0287 - val_loss: 0.1261\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0287 - val_loss: 0.1260\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0286 - val_loss: 0.1259\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0286 - val_loss: 0.1258\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0285 - val_loss: 0.1257\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0285 - val_loss: 0.1256\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0284 - val_loss: 0.1255\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0284 - val_loss: 0.1254\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0284 - val_loss: 0.1253\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0283 - val_loss: 0.1252\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0283 - val_loss: 0.1251\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0282 - val_loss: 0.1250\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0282 - val_loss: 0.1249\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0282 - val_loss: 0.1248\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0281 - val_loss: 0.1247\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0281 - val_loss: 0.1246\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0280 - val_loss: 0.1244\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0280 - val_loss: 0.1243\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0280 - val_loss: 0.1242\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0279 - val_loss: 0.1241\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0279 - val_loss: 0.1241\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0279 - val_loss: 0.1240\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0278 - val_loss: 0.1239\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0278 - val_loss: 0.1238\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0277 - val_loss: 0.1237\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0277 - val_loss: 0.1236\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0277 - val_loss: 0.1235\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0276 - val_loss: 0.1234\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0276 - val_loss: 0.1233\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0276 - val_loss: 0.1232\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0275 - val_loss: 0.1231\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0275 - val_loss: 0.1230\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0275 - val_loss: 0.1229\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0274 - val_loss: 0.1228\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0274 - val_loss: 0.1227\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0274 - val_loss: 0.1226\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0273 - val_loss: 0.1225\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0273 - val_loss: 0.1225\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0273 - val_loss: 0.1224\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0272 - val_loss: 0.1223\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0272 - val_loss: 0.1222\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0272 - val_loss: 0.1221\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0271 - val_loss: 0.1220\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0271 - val_loss: 0.1219\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0271 - val_loss: 0.1218\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0270 - val_loss: 0.1217\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0270 - val_loss: 0.1217\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0270 - val_loss: 0.1216\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0269 - val_loss: 0.1215\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0269 - val_loss: 0.1214\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0269 - val_loss: 0.1213\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0269 - val_loss: 0.1212\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0268 - val_loss: 0.1212\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0268 - val_loss: 0.1211\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0268 - val_loss: 0.1210\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0267 - val_loss: 0.1209\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0267 - val_loss: 0.1208\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0267 - val_loss: 0.1208\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0266 - val_loss: 0.1207\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0266 - val_loss: 0.1206\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0266 - val_loss: 0.1205\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0266 - val_loss: 0.1204\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0265 - val_loss: 0.1204\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0265 - val_loss: 0.1203\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0265 - val_loss: 0.1202\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0265 - val_loss: 0.1201\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0264 - val_loss: 0.1201\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0264 - val_loss: 0.1200\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0264 - val_loss: 0.1199\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0263 - val_loss: 0.1198\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0263 - val_loss: 0.1198\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0263 - val_loss: 0.1197\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0263 - val_loss: 0.1196\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0262 - val_loss: 0.1195\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0262 - val_loss: 0.1195\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0262 - val_loss: 0.1194\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0262 - val_loss: 0.1193\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0261 - val_loss: 0.1193\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0261 - val_loss: 0.1192\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0261 - val_loss: 0.1191\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0261 - val_loss: 0.1190\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0260 - val_loss: 0.1190\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0260 - val_loss: 0.1189\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0260 - val_loss: 0.1188\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0260 - val_loss: 0.1188\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0259 - val_loss: 0.1187\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0259 - val_loss: 0.1186\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0259 - val_loss: 0.1186\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0259 - val_loss: 0.1185\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0258 - val_loss: 0.1184\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0258 - val_loss: 0.1184\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0258 - val_loss: 0.1183\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0258 - val_loss: 0.1182\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0257 - val_loss: 0.1182\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0257 - val_loss: 0.1181\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0257 - val_loss: 0.1180\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0257 - val_loss: 0.1180\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0257 - val_loss: 0.1179\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0256 - val_loss: 0.1179\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0256 - val_loss: 0.1178\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0256 - val_loss: 0.1177\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0256 - val_loss: 0.1177\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0255 - val_loss: 0.1176\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0255 - val_loss: 0.1175\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0255 - val_loss: 0.1175\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0255 - val_loss: 0.1174\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0255 - val_loss: 0.1174\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0254 - val_loss: 0.1173\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0254 - val_loss: 0.1173\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0254 - val_loss: 0.1172\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0254 - val_loss: 0.1171\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0253 - val_loss: 0.1171\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0253 - val_loss: 0.1170\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0253 - val_loss: 0.1170\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0253 - val_loss: 0.1169\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0253 - val_loss: 0.1169\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0252 - val_loss: 0.1168\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0252 - val_loss: 0.1167\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0252 - val_loss: 0.1167\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0252 - val_loss: 0.1166\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0252 - val_loss: 0.1166\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0251 - val_loss: 0.1165\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0251 - val_loss: 0.1165\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0251 - val_loss: 0.1164\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0251 - val_loss: 0.1164\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0251 - val_loss: 0.1163\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0250 - val_loss: 0.1163\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0250 - val_loss: 0.1162\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0250 - val_loss: 0.1162\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0250 - val_loss: 0.1161\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0250 - val_loss: 0.1161\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0249 - val_loss: 0.1160\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0249 - val_loss: 0.1160\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0249 - val_loss: 0.1159\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0249 - val_loss: 0.1159\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0249 - val_loss: 0.1158\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0248 - val_loss: 0.1158\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0248 - val_loss: 0.1157\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0248 - val_loss: 0.1157\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0248 - val_loss: 0.1156\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0248 - val_loss: 0.1156\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0248 - val_loss: 0.1155\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0247 - val_loss: 0.1155\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0247 - val_loss: 0.1154\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0247 - val_loss: 0.1154\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0247 - val_loss: 0.1153\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0247 - val_loss: 0.1153\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0246 - val_loss: 0.1152\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0246 - val_loss: 0.1152\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0246 - val_loss: 0.1152\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0246 - val_loss: 0.1151\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0246 - val_loss: 0.1151\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0246 - val_loss: 0.1150\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0245 - val_loss: 0.1150\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0245 - val_loss: 0.1149\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0245 - val_loss: 0.1149\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0245 - val_loss: 0.1148\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0245 - val_loss: 0.1148\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0244 - val_loss: 0.1148\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0244 - val_loss: 0.1147\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0244 - val_loss: 0.1147\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0244 - val_loss: 0.1146\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0244 - val_loss: 0.1146\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0244 - val_loss: 0.1146\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0243 - val_loss: 0.1145\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0243 - val_loss: 0.1145\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0243 - val_loss: 0.1144\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0243 - val_loss: 0.1144\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0243 - val_loss: 0.1144\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0243 - val_loss: 0.1143\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0242 - val_loss: 0.1143\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0242 - val_loss: 0.1142\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0242 - val_loss: 0.1142\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0242 - val_loss: 0.1142\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0242 - val_loss: 0.1141\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0242 - val_loss: 0.1141\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0241 - val_loss: 0.1140\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.1140\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.1140\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.1139\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0241 - val_loss: 0.1139\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.1139\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0240 - val_loss: 0.1138\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0240 - val_loss: 0.1138\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0240 - val_loss: 0.1138\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0240 - val_loss: 0.1137\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0240 - val_loss: 0.1137\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0240 - val_loss: 0.1137\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0239 - val_loss: 0.1136\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0239 - val_loss: 0.1136\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0239 - val_loss: 0.1135\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.1135\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.1135\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0239 - val_loss: 0.1134\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0239 - val_loss: 0.1134\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0238 - val_loss: 0.1134\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0238 - val_loss: 0.1134\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0238 - val_loss: 0.1133\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0238 - val_loss: 0.1133\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0238 - val_loss: 0.1133\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0238 - val_loss: 0.1132\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0237 - val_loss: 0.1132\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0237 - val_loss: 0.1132\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0237 - val_loss: 0.1131\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0237 - val_loss: 0.1131\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0237 - val_loss: 0.1131\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0237 - val_loss: 0.1130\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0236 - val_loss: 0.1130\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0236 - val_loss: 0.1130\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0236 - val_loss: 0.1129\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0236 - val_loss: 0.1129\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0236 - val_loss: 0.1129\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0236 - val_loss: 0.1129\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0236 - val_loss: 0.1128\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0235 - val_loss: 0.1128\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0235 - val_loss: 0.1128\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0235 - val_loss: 0.1127\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0235 - val_loss: 0.1127\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0235 - val_loss: 0.1127\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0235 - val_loss: 0.1127\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0235 - val_loss: 0.1126\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0234 - val_loss: 0.1126\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0234 - val_loss: 0.1126\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0234 - val_loss: 0.1125\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0234 - val_loss: 0.1125\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0234 - val_loss: 0.1125\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 1.2681 - val_loss: 1.4261\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2334 - val_loss: 1.3915\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1993 - val_loss: 1.3575\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1658 - val_loss: 1.3242\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1330 - val_loss: 1.2916\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1008 - val_loss: 1.2596\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0694 - val_loss: 1.2284\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0385 - val_loss: 1.1978\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0084 - val_loss: 1.1679\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9790 - val_loss: 1.1387\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9502 - val_loss: 1.1102\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9221 - val_loss: 1.0823\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8947 - val_loss: 1.0552\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8680 - val_loss: 1.0287\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8420 - val_loss: 1.0030\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8166 - val_loss: 0.9779\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7920 - val_loss: 0.9534\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7680 - val_loss: 0.9297\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7447 - val_loss: 0.9066\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7220 - val_loss: 0.8841\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7000 - val_loss: 0.8623\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6786 - val_loss: 0.8412\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6579 - val_loss: 0.8206\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6379 - val_loss: 0.8007\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6184 - val_loss: 0.7814\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5995 - val_loss: 0.7627\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5813 - val_loss: 0.7446\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5637 - val_loss: 0.7271\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5466 - val_loss: 0.7101\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5301 - val_loss: 0.6937\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5141 - val_loss: 0.6778\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4987 - val_loss: 0.6625\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4839 - val_loss: 0.6476\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4695 - val_loss: 0.6333\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4557 - val_loss: 0.6195\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4423 - val_loss: 0.6061\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4294 - val_loss: 0.5932\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4170 - val_loss: 0.5808\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4051 - val_loss: 0.5688\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3936 - val_loss: 0.5572\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3825 - val_loss: 0.5460\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3718 - val_loss: 0.5352\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3615 - val_loss: 0.5248\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3517 - val_loss: 0.5148\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3421 - val_loss: 0.5051\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3330 - val_loss: 0.4958\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3242 - val_loss: 0.4868\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3158 - val_loss: 0.4782\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3076 - val_loss: 0.4698\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2998 - val_loss: 0.4618\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2923 - val_loss: 0.4540\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2851 - val_loss: 0.4465\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2781 - val_loss: 0.4392\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2715 - val_loss: 0.4322\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2651 - val_loss: 0.4255\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2589 - val_loss: 0.4190\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2530 - val_loss: 0.4127\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2473 - val_loss: 0.4066\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2418 - val_loss: 0.4007\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2366 - val_loss: 0.3950\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2315 - val_loss: 0.3894\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2266 - val_loss: 0.3841\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2220 - val_loss: 0.3789\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2175 - val_loss: 0.3739\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2131 - val_loss: 0.3690\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2090 - val_loss: 0.3643\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2050 - val_loss: 0.3597\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2011 - val_loss: 0.3552\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1974 - val_loss: 0.3509\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1938 - val_loss: 0.3467\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1903 - val_loss: 0.3425\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1870 - val_loss: 0.3385\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1838 - val_loss: 0.3346\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1807 - val_loss: 0.3308\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1777 - val_loss: 0.3271\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1748 - val_loss: 0.3234\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1720 - val_loss: 0.3199\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1693 - val_loss: 0.3164\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1667 - val_loss: 0.3130\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1642 - val_loss: 0.3096\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1618 - val_loss: 0.3063\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1594 - val_loss: 0.3031\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1571 - val_loss: 0.2999\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1549 - val_loss: 0.2968\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1528 - val_loss: 0.2938\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1507 - val_loss: 0.2908\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1487 - val_loss: 0.2878\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1467 - val_loss: 0.2849\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1448 - val_loss: 0.2820\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1429 - val_loss: 0.2792\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1411 - val_loss: 0.2764\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1394 - val_loss: 0.2737\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1377 - val_loss: 0.2710\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1360 - val_loss: 0.2683\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1344 - val_loss: 0.2657\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1328 - val_loss: 0.2631\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1313 - val_loss: 0.2605\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1298 - val_loss: 0.2579\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1283 - val_loss: 0.2554\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1269 - val_loss: 0.2529\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1255 - val_loss: 0.2504\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1241 - val_loss: 0.2480\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1228 - val_loss: 0.2456\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1215 - val_loss: 0.2432\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1202 - val_loss: 0.2408\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1189 - val_loss: 0.2385\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1177 - val_loss: 0.2362\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1165 - val_loss: 0.2339\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1153 - val_loss: 0.2316\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1142 - val_loss: 0.2294\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1130 - val_loss: 0.2272\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1119 - val_loss: 0.2250\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1109 - val_loss: 0.2228\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1098 - val_loss: 0.2206\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1087 - val_loss: 0.2185\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1077 - val_loss: 0.2164\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1067 - val_loss: 0.2143\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1057 - val_loss: 0.2122\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1047 - val_loss: 0.2102\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1038 - val_loss: 0.2081\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1029 - val_loss: 0.2061\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1019 - val_loss: 0.2041\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1010 - val_loss: 0.2022\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1001 - val_loss: 0.2002\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0993 - val_loss: 0.1983\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0984 - val_loss: 0.1964\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0975 - val_loss: 0.1945\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0967 - val_loss: 0.1926\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0959 - val_loss: 0.1908\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0951 - val_loss: 0.1889\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0943 - val_loss: 0.1871\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0935 - val_loss: 0.1853\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0927 - val_loss: 0.1836\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0920 - val_loss: 0.1818\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0912 - val_loss: 0.1801\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0905 - val_loss: 0.1784\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0898 - val_loss: 0.1767\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0890 - val_loss: 0.1750\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0883 - val_loss: 0.1733\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0876 - val_loss: 0.1717\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0870 - val_loss: 0.1701\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0863 - val_loss: 0.1685\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0856 - val_loss: 0.1669\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0850 - val_loss: 0.1654\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0843 - val_loss: 0.1638\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0837 - val_loss: 0.1623\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0831 - val_loss: 0.1608\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0825 - val_loss: 0.1593\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0818 - val_loss: 0.1579\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0812 - val_loss: 0.1564\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0807 - val_loss: 0.1550\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0801 - val_loss: 0.1536\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0795 - val_loss: 0.1522\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0789 - val_loss: 0.1508\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0784 - val_loss: 0.1494\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0778 - val_loss: 0.1481\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0773 - val_loss: 0.1468\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0767 - val_loss: 0.1455\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0762 - val_loss: 0.1442\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0757 - val_loss: 0.1429\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0752 - val_loss: 0.1417\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0747 - val_loss: 0.1405\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0742 - val_loss: 0.1392\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0737 - val_loss: 0.1380\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0732 - val_loss: 0.1369\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0727 - val_loss: 0.1357\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0722 - val_loss: 0.1345\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0718 - val_loss: 0.1334\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0713 - val_loss: 0.1323\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0708 - val_loss: 0.1312\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0704 - val_loss: 0.1301\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0700 - val_loss: 0.1290\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0695 - val_loss: 0.1280\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0691 - val_loss: 0.1269\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0687 - val_loss: 0.1259\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0682 - val_loss: 0.1249\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0678 - val_loss: 0.1239\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0674 - val_loss: 0.1229\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0670 - val_loss: 0.1219\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0666 - val_loss: 0.1210\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0662 - val_loss: 0.1201\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0658 - val_loss: 0.1191\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0654 - val_loss: 0.1182\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0650 - val_loss: 0.1173\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0647 - val_loss: 0.1164\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0643 - val_loss: 0.1156\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0639 - val_loss: 0.1147\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0636 - val_loss: 0.1139\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0632 - val_loss: 0.1130\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0629 - val_loss: 0.1122\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0625 - val_loss: 0.1114\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0622 - val_loss: 0.1106\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0618 - val_loss: 0.1098\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0615 - val_loss: 0.1091\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0612 - val_loss: 0.1083\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0608 - val_loss: 0.1075\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0605 - val_loss: 0.1068\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0602 - val_loss: 0.1061\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0599 - val_loss: 0.1054\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0596 - val_loss: 0.1047\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0593 - val_loss: 0.1040\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0590 - val_loss: 0.1033\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0587 - val_loss: 0.1026\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0584 - val_loss: 0.1020\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0581 - val_loss: 0.1013\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0578 - val_loss: 0.1007\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0575 - val_loss: 0.1000\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0572 - val_loss: 0.0994\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0569 - val_loss: 0.0988\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0567 - val_loss: 0.0982\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0564 - val_loss: 0.0976\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0561 - val_loss: 0.0970\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0558 - val_loss: 0.0965\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0556 - val_loss: 0.0959\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0553 - val_loss: 0.0953\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0551 - val_loss: 0.0948\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0548 - val_loss: 0.0943\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0546 - val_loss: 0.0937\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0543 - val_loss: 0.0932\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0541 - val_loss: 0.0927\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0538 - val_loss: 0.0922\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0536 - val_loss: 0.0917\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0533 - val_loss: 0.0912\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0531 - val_loss: 0.0907\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0529 - val_loss: 0.0902\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0527 - val_loss: 0.0898\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0524 - val_loss: 0.0893\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0522 - val_loss: 0.0889\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0520 - val_loss: 0.0884\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0518 - val_loss: 0.0880\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0516 - val_loss: 0.0876\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0513 - val_loss: 0.0871\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0511 - val_loss: 0.0867\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0509 - val_loss: 0.0863\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0507 - val_loss: 0.0859\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0505 - val_loss: 0.0855\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0503 - val_loss: 0.0851\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0501 - val_loss: 0.0847\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0499 - val_loss: 0.0843\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0497 - val_loss: 0.0840\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0495 - val_loss: 0.0836\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0493 - val_loss: 0.0832\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0491 - val_loss: 0.0829\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0490 - val_loss: 0.0825\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0488 - val_loss: 0.0822\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0486 - val_loss: 0.0819\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0484 - val_loss: 0.0815\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0482 - val_loss: 0.0812\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0481 - val_loss: 0.0809\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0479 - val_loss: 0.0805\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0477 - val_loss: 0.0802\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0475 - val_loss: 0.0799\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0474 - val_loss: 0.0796\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0472 - val_loss: 0.0793\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0470 - val_loss: 0.0790\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0469 - val_loss: 0.0787\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0467 - val_loss: 0.0785\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0466 - val_loss: 0.0782\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0464 - val_loss: 0.0779\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0463 - val_loss: 0.0776\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0461 - val_loss: 0.0774\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0459 - val_loss: 0.0771\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0458 - val_loss: 0.0769\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0456 - val_loss: 0.0766\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0455 - val_loss: 0.0763\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0454 - val_loss: 0.0761\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0452 - val_loss: 0.0759\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0451 - val_loss: 0.0756\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0449 - val_loss: 0.0754\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0448 - val_loss: 0.0752\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0446 - val_loss: 0.0749\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0445 - val_loss: 0.0747\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0444 - val_loss: 0.0745\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0442 - val_loss: 0.0743\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0441 - val_loss: 0.0741\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0440 - val_loss: 0.0739\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0438 - val_loss: 0.0736\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0437 - val_loss: 0.0734\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0436 - val_loss: 0.0732\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0435 - val_loss: 0.0730\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0433 - val_loss: 0.0729\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0432 - val_loss: 0.0727\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0431 - val_loss: 0.0725\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0430 - val_loss: 0.0723\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0428 - val_loss: 0.0721\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0427 - val_loss: 0.0719\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0426 - val_loss: 0.0718\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0425 - val_loss: 0.0716\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0424 - val_loss: 0.0714\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0423 - val_loss: 0.0713\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0422 - val_loss: 0.0711\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0420 - val_loss: 0.0709\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0419 - val_loss: 0.0708\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0418 - val_loss: 0.0706\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0417 - val_loss: 0.0705\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0416 - val_loss: 0.0703\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0415 - val_loss: 0.0702\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0414 - val_loss: 0.0700\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0413 - val_loss: 0.0699\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0412 - val_loss: 0.0697\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0411 - val_loss: 0.0696\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0410 - val_loss: 0.0695\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0409 - val_loss: 0.0693\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0408 - val_loss: 0.0692\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0407 - val_loss: 0.0691\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0406 - val_loss: 0.0689\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0405 - val_loss: 0.0688\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0404 - val_loss: 0.0687\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0403 - val_loss: 0.0686\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0402 - val_loss: 0.0684\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0401 - val_loss: 0.0683\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0400 - val_loss: 0.0682\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0399 - val_loss: 0.0681\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0399 - val_loss: 0.0680\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0398 - val_loss: 0.0679\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0397 - val_loss: 0.0678\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0396 - val_loss: 0.0677\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0395 - val_loss: 0.0675\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0394 - val_loss: 0.0674\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0393 - val_loss: 0.0673\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0392 - val_loss: 0.0672\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0392 - val_loss: 0.0671\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0391 - val_loss: 0.0671\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0390 - val_loss: 0.0670\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0389 - val_loss: 0.0669\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0388 - val_loss: 0.0668\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0388 - val_loss: 0.0667\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0387 - val_loss: 0.0666\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0386 - val_loss: 0.0665\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0385 - val_loss: 0.0664\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0384 - val_loss: 0.0663\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0384 - val_loss: 0.0663\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0383 - val_loss: 0.0662\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0382 - val_loss: 0.0661\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0381 - val_loss: 0.0660\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0381 - val_loss: 0.0659\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0380 - val_loss: 0.0659\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0379 - val_loss: 0.0658\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0379 - val_loss: 0.0657\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0378 - val_loss: 0.0656\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0377 - val_loss: 0.0656\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0376 - val_loss: 0.0655\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0376 - val_loss: 0.0654\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0375 - val_loss: 0.0654\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0374 - val_loss: 0.0653\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0374 - val_loss: 0.0652\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0373 - val_loss: 0.0652\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0372 - val_loss: 0.0651\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0372 - val_loss: 0.0650\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0371 - val_loss: 0.0650\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0370 - val_loss: 0.0649\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0370 - val_loss: 0.0649\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0369 - val_loss: 0.0648\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0369 - val_loss: 0.0647\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0368 - val_loss: 0.0647\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0367 - val_loss: 0.0646\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - val_loss: 0.0646\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0366 - val_loss: 0.0645\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.0645\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0365 - val_loss: 0.0644\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0364 - val_loss: 0.0644\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0364 - val_loss: 0.0643\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0363 - val_loss: 0.0643\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0363 - val_loss: 0.0642\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0362 - val_loss: 0.0642\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0361 - val_loss: 0.0641\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0361 - val_loss: 0.0641\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0360 - val_loss: 0.0641\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0360 - val_loss: 0.0640\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0359 - val_loss: 0.0640\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0359 - val_loss: 0.0639\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0358 - val_loss: 0.0639\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0358 - val_loss: 0.0638\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0357 - val_loss: 0.0638\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0356 - val_loss: 0.0638\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0356 - val_loss: 0.0637\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0355 - val_loss: 0.0637\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0355 - val_loss: 0.0637\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0354 - val_loss: 0.0636\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0354 - val_loss: 0.0636\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0353 - val_loss: 0.0635\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0353 - val_loss: 0.0635\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0352 - val_loss: 0.0635\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0352 - val_loss: 0.0634\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0351 - val_loss: 0.0634\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0351 - val_loss: 0.0634\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0350 - val_loss: 0.0634\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0350 - val_loss: 0.0633\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0349 - val_loss: 0.0633\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0349 - val_loss: 0.0633\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0348 - val_loss: 0.0632\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0348 - val_loss: 0.0632\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0348 - val_loss: 0.0632\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0347 - val_loss: 0.0632\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0347 - val_loss: 0.0631\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0346 - val_loss: 0.0631\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0346 - val_loss: 0.0631\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0345 - val_loss: 0.0630\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0345 - val_loss: 0.0630\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0344 - val_loss: 0.0630\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0344 - val_loss: 0.0630\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0344 - val_loss: 0.0630\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0343 - val_loss: 0.0629\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0343 - val_loss: 0.0629\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0342 - val_loss: 0.0629\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0342 - val_loss: 0.0629\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0341 - val_loss: 0.0628\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0341 - val_loss: 0.0628\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0341 - val_loss: 0.0628\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0340 - val_loss: 0.0628\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0340 - val_loss: 0.0628\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0339 - val_loss: 0.0627\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0339 - val_loss: 0.0627\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0339 - val_loss: 0.0627\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0338 - val_loss: 0.0627\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0338 - val_loss: 0.0627\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0337 - val_loss: 0.0627\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0337 - val_loss: 0.0626\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0626\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0336 - val_loss: 0.0626\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0336 - val_loss: 0.0626\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0335 - val_loss: 0.0626\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0335 - val_loss: 0.0626\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0335 - val_loss: 0.0626\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0334 - val_loss: 0.0625\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0334 - val_loss: 0.0625\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0334 - val_loss: 0.0625\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0333 - val_loss: 0.0625\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0333 - val_loss: 0.0625\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0332 - val_loss: 0.0625\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0625\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0624\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0331 - val_loss: 0.0624\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0331 - val_loss: 0.0624\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0331 - val_loss: 0.0624\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0330 - val_loss: 0.0624\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0330 - val_loss: 0.0624\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0330 - val_loss: 0.0624\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0329 - val_loss: 0.0624\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0329 - val_loss: 0.0624\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0329 - val_loss: 0.0623\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0328 - val_loss: 0.0623\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0328 - val_loss: 0.0623\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0328 - val_loss: 0.0623\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - val_loss: 0.0623\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0327 - val_loss: 0.0623\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0327 - val_loss: 0.0623\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0326 - val_loss: 0.0623\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0326 - val_loss: 0.0623\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0326 - val_loss: 0.0623\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0325 - val_loss: 0.0623\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0325 - val_loss: 0.0622\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0325 - val_loss: 0.0622\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0622\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0622\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0324 - val_loss: 0.0622\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0323 - val_loss: 0.0622\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0323 - val_loss: 0.0622\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0323 - val_loss: 0.0622\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0322 - val_loss: 0.0622\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0322 - val_loss: 0.0622\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.0622\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0322 - val_loss: 0.0622\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0321 - val_loss: 0.0622\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0321 - val_loss: 0.0622\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0321 - val_loss: 0.0622\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0320 - val_loss: 0.0622\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0320 - val_loss: 0.0621\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.0621\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0319 - val_loss: 0.0621\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0319 - val_loss: 0.0621\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0319 - val_loss: 0.0621\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0319 - val_loss: 0.0621\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0318 - val_loss: 0.0621\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0318 - val_loss: 0.0621\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0318 - val_loss: 0.0621\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0317 - val_loss: 0.0621\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0317 - val_loss: 0.0621\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0317 - val_loss: 0.0621\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0317 - val_loss: 0.0621\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0316 - val_loss: 0.0621\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0316 - val_loss: 0.0621\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0316 - val_loss: 0.0621\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0315 - val_loss: 0.0621\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0315 - val_loss: 0.0621\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0315 - val_loss: 0.0621\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0315 - val_loss: 0.0621\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0314 - val_loss: 0.0621\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0314 - val_loss: 0.0621\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0314 - val_loss: 0.0621\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0314 - val_loss: 0.0621\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - val_loss: 0.0620\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0313 - val_loss: 0.0620\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0313 - val_loss: 0.0620\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0313 - val_loss: 0.0620\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0312 - val_loss: 0.0620\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0312 - val_loss: 0.0620\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0312 - val_loss: 0.0620\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0311 - val_loss: 0.0620\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0311 - val_loss: 0.0620\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0311 - val_loss: 0.0620\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0311 - val_loss: 0.0620\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0310 - val_loss: 0.0620\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0310 - val_loss: 0.0620\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0310 - val_loss: 0.0620\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0310 - val_loss: 0.0620\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0309 - val_loss: 0.0620\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0309 - val_loss: 0.0620\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0309 - val_loss: 0.0620\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0309 - val_loss: 0.0620\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0308 - val_loss: 0.0620\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0308 - val_loss: 0.0620\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0308 - val_loss: 0.0620\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0308 - val_loss: 0.0620\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0308 - val_loss: 0.0620\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0307 - val_loss: 0.0620\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0307 - val_loss: 0.0620\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0307 - val_loss: 0.0620\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0307 - val_loss: 0.0620\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0306 - val_loss: 0.0620\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0306 - val_loss: 0.0620\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0306 - val_loss: 0.0620\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0306 - val_loss: 0.0620\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0305 - val_loss: 0.0620\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0305 - val_loss: 0.0620\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0305 - val_loss: 0.0620\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0305 - val_loss: 0.0620\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0304 - val_loss: 0.0620\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0303 - val_loss: 0.0620\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.0620\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.0620\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.0620\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0302 - val_loss: 0.0620\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0302 - val_loss: 0.0619\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0302 - val_loss: 0.0619\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0302 - val_loss: 0.0619\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0301 - val_loss: 0.0619\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0301 - val_loss: 0.0619\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0301 - val_loss: 0.0619\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0301 - val_loss: 0.0619\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0301 - val_loss: 0.0619\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0300 - val_loss: 0.0619\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0300 - val_loss: 0.0619\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0300 - val_loss: 0.0619\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0300 - val_loss: 0.0619\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0300 - val_loss: 0.0619\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0299 - val_loss: 0.0619\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0299 - val_loss: 0.0619\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0299 - val_loss: 0.0619\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0299 - val_loss: 0.0619\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0298 - val_loss: 0.0619\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0298 - val_loss: 0.0619\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0298 - val_loss: 0.0619\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0298 - val_loss: 0.0619\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0298 - val_loss: 0.0619\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0297 - val_loss: 0.0619\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0297 - val_loss: 0.0619\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0297 - val_loss: 0.0619\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0297 - val_loss: 0.0619\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0297 - val_loss: 0.0619\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0296 - val_loss: 0.0619\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0296 - val_loss: 0.0619\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0296 - val_loss: 0.0619\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0296 - val_loss: 0.0619\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0296 - val_loss: 0.0619\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0295 - val_loss: 0.0619\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0295 - val_loss: 0.0619\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0295 - val_loss: 0.0619\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0295 - val_loss: 0.0619\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0295 - val_loss: 0.0619\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0294 - val_loss: 0.0619\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0294 - val_loss: 0.0619\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0294 - val_loss: 0.0619\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0294 - val_loss: 0.0619\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0292 - val_loss: 0.0619\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0292 - val_loss: 0.0619\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0292 - val_loss: 0.0619\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0292 - val_loss: 0.0619\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0292 - val_loss: 0.0619\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0291 - val_loss: 0.0619\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0291 - val_loss: 0.0619\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0291 - val_loss: 0.0619\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0291 - val_loss: 0.0619\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0291 - val_loss: 0.0619\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0290 - val_loss: 0.0619\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0290 - val_loss: 0.0618\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0290 - val_loss: 0.0618\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0290 - val_loss: 0.0618\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0290 - val_loss: 0.0618\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0289 - val_loss: 0.0618\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 2.1020 - val_loss: 1.6535\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0504 - val_loss: 1.6064\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9995 - val_loss: 1.5601\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9493 - val_loss: 1.5145\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.8999 - val_loss: 1.4698\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.8513 - val_loss: 1.4258\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8033 - val_loss: 1.3827\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7562 - val_loss: 1.3403\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7098 - val_loss: 1.2988\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.6642 - val_loss: 1.2580\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6195 - val_loss: 1.2181\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5755 - val_loss: 1.1791\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5323 - val_loss: 1.1409\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4899 - val_loss: 1.1035\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4484 - val_loss: 1.0669\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4076 - val_loss: 1.0312\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3677 - val_loss: 0.9964\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3286 - val_loss: 0.9623\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2903 - val_loss: 0.9291\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2528 - val_loss: 0.8968\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2162 - val_loss: 0.8653\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1804 - val_loss: 0.8346\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1454 - val_loss: 0.8047\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1112 - val_loss: 0.7757\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0778 - val_loss: 0.7474\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0452 - val_loss: 0.7200\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0135 - val_loss: 0.6934\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9825 - val_loss: 0.6675\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9523 - val_loss: 0.6425\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9229 - val_loss: 0.6182\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8942 - val_loss: 0.5946\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8664 - val_loss: 0.5718\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8392 - val_loss: 0.5498\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8129 - val_loss: 0.5284\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7872 - val_loss: 0.5078\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7623 - val_loss: 0.4879\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7381 - val_loss: 0.4687\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7147 - val_loss: 0.4501\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6919 - val_loss: 0.4322\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6698 - val_loss: 0.4149\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6484 - val_loss: 0.3983\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6276 - val_loss: 0.3823\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6075 - val_loss: 0.3670\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5880 - val_loss: 0.3522\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5692 - val_loss: 0.3379\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5509 - val_loss: 0.3243\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5333 - val_loss: 0.3112\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5162 - val_loss: 0.2986\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4998 - val_loss: 0.2866\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4838 - val_loss: 0.2750\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4685 - val_loss: 0.2640\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4537 - val_loss: 0.2534\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4394 - val_loss: 0.2433\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4256 - val_loss: 0.2337\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4123 - val_loss: 0.2244\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3994 - val_loss: 0.2156\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3871 - val_loss: 0.2073\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3752 - val_loss: 0.1993\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3638 - val_loss: 0.1917\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3528 - val_loss: 0.1844\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3422 - val_loss: 0.1775\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3320 - val_loss: 0.1710\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3222 - val_loss: 0.1647\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3128 - val_loss: 0.1588\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3038 - val_loss: 0.1532\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2951 - val_loss: 0.1479\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2868 - val_loss: 0.1429\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2788 - val_loss: 0.1382\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2711 - val_loss: 0.1337\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2637 - val_loss: 0.1294\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2567 - val_loss: 0.1254\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2499 - val_loss: 0.1216\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2435 - val_loss: 0.1180\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2372 - val_loss: 0.1146\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2313 - val_loss: 0.1114\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2256 - val_loss: 0.1085\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2202 - val_loss: 0.1056\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2149 - val_loss: 0.1030\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2099 - val_loss: 0.1005\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2051 - val_loss: 0.0982\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2006 - val_loss: 0.0960\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1962 - val_loss: 0.0939\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1920 - val_loss: 0.0920\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1880 - val_loss: 0.0901\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1841 - val_loss: 0.0884\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1804 - val_loss: 0.0868\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1769 - val_loss: 0.0854\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1736 - val_loss: 0.0839\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1703 - val_loss: 0.0826\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1672 - val_loss: 0.0814\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1643 - val_loss: 0.0803\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1615 - val_loss: 0.0792\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1587 - val_loss: 0.0782\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1561 - val_loss: 0.0772\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1537 - val_loss: 0.0763\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1513 - val_loss: 0.0755\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1490 - val_loss: 0.0747\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1468 - val_loss: 0.0740\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1447 - val_loss: 0.0733\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1426 - val_loss: 0.0726\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1407 - val_loss: 0.0720\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1388 - val_loss: 0.0714\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1370 - val_loss: 0.0708\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1353 - val_loss: 0.0703\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1336 - val_loss: 0.0698\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1320 - val_loss: 0.0693\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1305 - val_loss: 0.0689\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1290 - val_loss: 0.0684\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1276 - val_loss: 0.0680\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1262 - val_loss: 0.0676\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1249 - val_loss: 0.0672\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1236 - val_loss: 0.0668\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1223 - val_loss: 0.0665\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1211 - val_loss: 0.0661\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1199 - val_loss: 0.0658\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1188 - val_loss: 0.0654\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1177 - val_loss: 0.0651\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1166 - val_loss: 0.0648\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1156 - val_loss: 0.0645\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1146 - val_loss: 0.0641\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1136 - val_loss: 0.0638\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1126 - val_loss: 0.0635\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1117 - val_loss: 0.0632\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1108 - val_loss: 0.0629\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1099 - val_loss: 0.0626\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1090 - val_loss: 0.0623\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1082 - val_loss: 0.0620\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1073 - val_loss: 0.0617\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1065 - val_loss: 0.0614\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1057 - val_loss: 0.0611\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1050 - val_loss: 0.0608\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1042 - val_loss: 0.0605\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1035 - val_loss: 0.0602\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1027 - val_loss: 0.0600\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1020 - val_loss: 0.0597\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1013 - val_loss: 0.0594\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1006 - val_loss: 0.0591\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1000 - val_loss: 0.0588\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0993 - val_loss: 0.0585\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0987 - val_loss: 0.0582\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0980 - val_loss: 0.0579\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0974 - val_loss: 0.0576\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0968 - val_loss: 0.0573\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0962 - val_loss: 0.0570\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0956 - val_loss: 0.0567\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0950 - val_loss: 0.0565\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0944 - val_loss: 0.0562\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0938 - val_loss: 0.0559\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0933 - val_loss: 0.0556\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0927 - val_loss: 0.0553\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0921 - val_loss: 0.0550\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0916 - val_loss: 0.0547\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0911 - val_loss: 0.0544\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0906 - val_loss: 0.0542\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0900 - val_loss: 0.0539\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0895 - val_loss: 0.0536\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0890 - val_loss: 0.0533\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0885 - val_loss: 0.0530\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0880 - val_loss: 0.0528\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0875 - val_loss: 0.0525\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0871 - val_loss: 0.0522\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0866 - val_loss: 0.0519\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0861 - val_loss: 0.0517\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0857 - val_loss: 0.0514\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0852 - val_loss: 0.0511\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0848 - val_loss: 0.0509\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0843 - val_loss: 0.0506\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0839 - val_loss: 0.0503\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0835 - val_loss: 0.0501\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0830 - val_loss: 0.0498\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0826 - val_loss: 0.0496\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0822 - val_loss: 0.0493\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0818 - val_loss: 0.0491\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0814 - val_loss: 0.0488\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0810 - val_loss: 0.0486\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0806 - val_loss: 0.0483\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0802 - val_loss: 0.0481\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0798 - val_loss: 0.0478\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0794 - val_loss: 0.0476\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0790 - val_loss: 0.0474\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0786 - val_loss: 0.0471\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0783 - val_loss: 0.0469\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0779 - val_loss: 0.0467\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0775 - val_loss: 0.0464\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0772 - val_loss: 0.0462\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0768 - val_loss: 0.0460\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0765 - val_loss: 0.0458\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0761 - val_loss: 0.0456\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0758 - val_loss: 0.0453\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0755 - val_loss: 0.0451\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0751 - val_loss: 0.0449\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0748 - val_loss: 0.0447\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0745 - val_loss: 0.0445\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0741 - val_loss: 0.0443\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0738 - val_loss: 0.0441\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0735 - val_loss: 0.0439\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0732 - val_loss: 0.0437\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0729 - val_loss: 0.0435\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0726 - val_loss: 0.0433\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0723 - val_loss: 0.0431\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0720 - val_loss: 0.0429\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0717 - val_loss: 0.0427\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0714 - val_loss: 0.0425\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0711 - val_loss: 0.0424\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0708 - val_loss: 0.0422\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0705 - val_loss: 0.0420\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0702 - val_loss: 0.0418\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0699 - val_loss: 0.0417\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0696 - val_loss: 0.0415\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0694 - val_loss: 0.0413\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0691 - val_loss: 0.0411\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0688 - val_loss: 0.0410\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0686 - val_loss: 0.0408\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0683 - val_loss: 0.0406\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0680 - val_loss: 0.0405\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0678 - val_loss: 0.0403\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0675 - val_loss: 0.0402\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0673 - val_loss: 0.0400\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0670 - val_loss: 0.0398\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0668 - val_loss: 0.0397\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0665 - val_loss: 0.0395\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0663 - val_loss: 0.0394\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0660 - val_loss: 0.0392\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0658 - val_loss: 0.0391\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0656 - val_loss: 0.0390\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0653 - val_loss: 0.0388\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0651 - val_loss: 0.0387\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0649 - val_loss: 0.0385\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0646 - val_loss: 0.0384\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0644 - val_loss: 0.0383\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0642 - val_loss: 0.0381\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0640 - val_loss: 0.0380\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0637 - val_loss: 0.0379\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0635 - val_loss: 0.0377\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0633 - val_loss: 0.0376\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0631 - val_loss: 0.0375\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0629 - val_loss: 0.0373\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0627 - val_loss: 0.0372\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0624 - val_loss: 0.0371\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0622 - val_loss: 0.0370\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0620 - val_loss: 0.0369\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0618 - val_loss: 0.0367\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0616 - val_loss: 0.0366\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0614 - val_loss: 0.0365\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0612 - val_loss: 0.0364\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0610 - val_loss: 0.0363\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0608 - val_loss: 0.0362\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0606 - val_loss: 0.0361\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0605 - val_loss: 0.0360\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0603 - val_loss: 0.0358\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0601 - val_loss: 0.0357\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0599 - val_loss: 0.0356\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0597 - val_loss: 0.0355\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0595 - val_loss: 0.0354\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0593 - val_loss: 0.0353\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0591 - val_loss: 0.0352\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0590 - val_loss: 0.0351\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0588 - val_loss: 0.0350\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0586 - val_loss: 0.0349\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0584 - val_loss: 0.0348\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0583 - val_loss: 0.0348\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0581 - val_loss: 0.0347\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0579 - val_loss: 0.0346\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0577 - val_loss: 0.0345\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0576 - val_loss: 0.0344\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0574 - val_loss: 0.0343\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0572 - val_loss: 0.0342\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0571 - val_loss: 0.0341\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0569 - val_loss: 0.0341\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0567 - val_loss: 0.0340\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0566 - val_loss: 0.0339\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0564 - val_loss: 0.0338\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0563 - val_loss: 0.0337\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0561 - val_loss: 0.0337\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0560 - val_loss: 0.0336\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0558 - val_loss: 0.0335\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0556 - val_loss: 0.0334\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0555 - val_loss: 0.0334\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0553 - val_loss: 0.0333\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0552 - val_loss: 0.0332\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0550 - val_loss: 0.0331\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0549 - val_loss: 0.0331\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0547 - val_loss: 0.0330\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0546 - val_loss: 0.0329\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0544 - val_loss: 0.0329\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0543 - val_loss: 0.0328\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0542 - val_loss: 0.0327\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0540 - val_loss: 0.0327\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0539 - val_loss: 0.0326\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0537 - val_loss: 0.0326\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0536 - val_loss: 0.0325\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0534 - val_loss: 0.0324\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0533 - val_loss: 0.0324\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0532 - val_loss: 0.0323\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0530 - val_loss: 0.0323\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0529 - val_loss: 0.0322\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0528 - val_loss: 0.0322\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0526 - val_loss: 0.0321\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0525 - val_loss: 0.0321\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0524 - val_loss: 0.0320\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0522 - val_loss: 0.0320\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0521 - val_loss: 0.0319\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0520 - val_loss: 0.0319\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0518 - val_loss: 0.0318\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0517 - val_loss: 0.0318\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0516 - val_loss: 0.0317\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0515 - val_loss: 0.0317\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0513 - val_loss: 0.0316\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0512 - val_loss: 0.0316\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0511 - val_loss: 0.0315\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0510 - val_loss: 0.0315\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0508 - val_loss: 0.0315\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0507 - val_loss: 0.0314\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0506 - val_loss: 0.0314\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0505 - val_loss: 0.0313\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0504 - val_loss: 0.0313\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0502 - val_loss: 0.0313\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0501 - val_loss: 0.0312\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0500 - val_loss: 0.0312\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0499 - val_loss: 0.0312\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0498 - val_loss: 0.0311\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0497 - val_loss: 0.0311\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0495 - val_loss: 0.0311\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0494 - val_loss: 0.0310\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0493 - val_loss: 0.0310\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0492 - val_loss: 0.0310\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0491 - val_loss: 0.0309\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0490 - val_loss: 0.0309\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0489 - val_loss: 0.0309\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0488 - val_loss: 0.0309\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0486 - val_loss: 0.0308\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0485 - val_loss: 0.0308\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0484 - val_loss: 0.0308\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0483 - val_loss: 0.0308\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0482 - val_loss: 0.0307\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0481 - val_loss: 0.0307\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0480 - val_loss: 0.0307\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0479 - val_loss: 0.0307\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0478 - val_loss: 0.0307\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0477 - val_loss: 0.0306\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0476 - val_loss: 0.0306\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0475 - val_loss: 0.0306\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0474 - val_loss: 0.0306\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0473 - val_loss: 0.0306\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0472 - val_loss: 0.0306\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0471 - val_loss: 0.0305\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0470 - val_loss: 0.0305\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0469 - val_loss: 0.0305\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0468 - val_loss: 0.0305\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0467 - val_loss: 0.0305\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0466 - val_loss: 0.0305\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0465 - val_loss: 0.0305\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0464 - val_loss: 0.0305\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0463 - val_loss: 0.0304\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0462 - val_loss: 0.0304\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0461 - val_loss: 0.0304\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0460 - val_loss: 0.0304\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - val_loss: 0.0304\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0458 - val_loss: 0.0304\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0457 - val_loss: 0.0304\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0456 - val_loss: 0.0304\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0455 - val_loss: 0.0304\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0454 - val_loss: 0.0304\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0453 - val_loss: 0.0304\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0453 - val_loss: 0.0304\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0452 - val_loss: 0.0304\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0451 - val_loss: 0.0304\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0450 - val_loss: 0.0304\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0449 - val_loss: 0.0304\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0448 - val_loss: 0.0304\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0447 - val_loss: 0.0304\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0446 - val_loss: 0.0304\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0444 - val_loss: 0.0304\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0443 - val_loss: 0.0304\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0442 - val_loss: 0.0304\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0441 - val_loss: 0.0304\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0440 - val_loss: 0.0304\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0439 - val_loss: 0.0304\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0439 - val_loss: 0.0304\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0438 - val_loss: 0.0304\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0437 - val_loss: 0.0304\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0436 - val_loss: 0.0304\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0435 - val_loss: 0.0304\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0434 - val_loss: 0.0304\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0434 - val_loss: 0.0304\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0433 - val_loss: 0.0304\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0432 - val_loss: 0.0304\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0431 - val_loss: 0.0305\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0430 - val_loss: 0.0305\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0430 - val_loss: 0.0305\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0429 - val_loss: 0.0305\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0428 - val_loss: 0.0305\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0427 - val_loss: 0.0305\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0427 - val_loss: 0.0305\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0426 - val_loss: 0.0305\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0425 - val_loss: 0.0305\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0424 - val_loss: 0.0306\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0423 - val_loss: 0.0306\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0423 - val_loss: 0.0306\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0422 - val_loss: 0.0306\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0420 - val_loss: 0.0306\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0420 - val_loss: 0.0306\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0419 - val_loss: 0.0307\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0418 - val_loss: 0.0307\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0417 - val_loss: 0.0307\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0417 - val_loss: 0.0307\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0416 - val_loss: 0.0307\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0415 - val_loss: 0.0308\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0414 - val_loss: 0.0308\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0414 - val_loss: 0.0308\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0413 - val_loss: 0.0308\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0412 - val_loss: 0.0308\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0412 - val_loss: 0.0309\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0411 - val_loss: 0.0309\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0410 - val_loss: 0.0309\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0410 - val_loss: 0.0309\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0409 - val_loss: 0.0309\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0408 - val_loss: 0.0310\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0407 - val_loss: 0.0310\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0407 - val_loss: 0.0310\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0406 - val_loss: 0.0310\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0405 - val_loss: 0.0310\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0405 - val_loss: 0.0311\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0404 - val_loss: 0.0311\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0403 - val_loss: 0.0311\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0403 - val_loss: 0.0311\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0402 - val_loss: 0.0312\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0401 - val_loss: 0.0312\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0401 - val_loss: 0.0312\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0400 - val_loss: 0.0312\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0399 - val_loss: 0.0313\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0399 - val_loss: 0.0313\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0398 - val_loss: 0.0313\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0397 - val_loss: 0.0314\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0397 - val_loss: 0.0314\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0396 - val_loss: 0.0314\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0395 - val_loss: 0.0314\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0395 - val_loss: 0.0315\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0394 - val_loss: 0.0315\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0394 - val_loss: 0.0315\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0393 - val_loss: 0.0316\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0392 - val_loss: 0.0316\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0392 - val_loss: 0.0316\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0391 - val_loss: 0.0316\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0390 - val_loss: 0.0317\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0390 - val_loss: 0.0317\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0389 - val_loss: 0.0317\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0389 - val_loss: 0.0318\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0388 - val_loss: 0.0318\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0387 - val_loss: 0.0318\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0387 - val_loss: 0.0319\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0386 - val_loss: 0.0319\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0386 - val_loss: 0.0319\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0385 - val_loss: 0.0320\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0384 - val_loss: 0.0320\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0384 - val_loss: 0.0320\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0383 - val_loss: 0.0321\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0383 - val_loss: 0.0321\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0382 - val_loss: 0.0321\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0382 - val_loss: 0.0322\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0381 - val_loss: 0.0322\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0380 - val_loss: 0.0322\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0380 - val_loss: 0.0323\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - val_loss: 0.0323\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0379 - val_loss: 0.0323\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0378 - val_loss: 0.0324\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0378 - val_loss: 0.0324\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - val_loss: 0.0324\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0376 - val_loss: 0.0325\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0376 - val_loss: 0.0325\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0375 - val_loss: 0.0326\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0375 - val_loss: 0.0326\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - val_loss: 0.0326\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0374 - val_loss: 0.0327\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0373 - val_loss: 0.0327\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0373 - val_loss: 0.0327\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0372 - val_loss: 0.0328\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0371 - val_loss: 0.0328\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0371 - val_loss: 0.0329\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0370 - val_loss: 0.0329\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0370 - val_loss: 0.0329\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0369 - val_loss: 0.0330\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0369 - val_loss: 0.0330\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0368 - val_loss: 0.0331\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0368 - val_loss: 0.0331\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0367 - val_loss: 0.0331\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0367 - val_loss: 0.0332\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0366 - val_loss: 0.0332\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0366 - val_loss: 0.0333\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0365 - val_loss: 0.0333\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0365 - val_loss: 0.0333\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0364 - val_loss: 0.0334\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0364 - val_loss: 0.0334\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0363 - val_loss: 0.0335\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0363 - val_loss: 0.0335\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0362 - val_loss: 0.0335\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - val_loss: 0.0336\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0361 - val_loss: 0.0336\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0361 - val_loss: 0.0337\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0360 - val_loss: 0.0337\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0360 - val_loss: 0.0338\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0359 - val_loss: 0.0338\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0359 - val_loss: 0.0338\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0358 - val_loss: 0.0339\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0358 - val_loss: 0.0339\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0357 - val_loss: 0.0340\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0357 - val_loss: 0.0340\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0356 - val_loss: 0.0341\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0356 - val_loss: 0.0341\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0355 - val_loss: 0.0341\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0355 - val_loss: 0.0342\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0354 - val_loss: 0.0342\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0354 - val_loss: 0.0343\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0354 - val_loss: 0.0343\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - val_loss: 0.0344\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0353 - val_loss: 0.0344\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0352 - val_loss: 0.0345\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0352 - val_loss: 0.0345\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0351 - val_loss: 0.0345\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0351 - val_loss: 0.0346\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0350 - val_loss: 0.0346\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0350 - val_loss: 0.0347\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0349 - val_loss: 0.0347\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0349 - val_loss: 0.0348\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0349 - val_loss: 0.0348\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0348 - val_loss: 0.0349\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0348 - val_loss: 0.0349\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0347 - val_loss: 0.0349\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0347 - val_loss: 0.0350\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0346 - val_loss: 0.0350\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0346 - val_loss: 0.0351\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0345 - val_loss: 0.0351\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0345 - val_loss: 0.0352\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0345 - val_loss: 0.0352\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0344 - val_loss: 0.0353\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0344 - val_loss: 0.0353\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0343 - val_loss: 0.0354\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0343 - val_loss: 0.0354\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - val_loss: 0.0355\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0342 - val_loss: 0.0355\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - val_loss: 0.0355\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0341 - val_loss: 0.0356\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0341 - val_loss: 0.0356\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0340 - val_loss: 0.0357\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0340 - val_loss: 0.0357\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0340 - val_loss: 0.0358\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0339 - val_loss: 0.0358\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0339 - val_loss: 0.0359\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0338 - val_loss: 0.0359\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - val_loss: 0.0360\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0337 - val_loss: 0.0360\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0337 - val_loss: 0.0361\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0337 - val_loss: 0.0361\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0336 - val_loss: 0.0362\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0336 - val_loss: 0.0362\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0335 - val_loss: 0.0364\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0334 - val_loss: 0.0364\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0334 - val_loss: 0.0365\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0334 - val_loss: 0.0365\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0333 - val_loss: 0.0365\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0333 - val_loss: 0.0366\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0332 - val_loss: 0.0366\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0332 - val_loss: 0.0367\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0332 - val_loss: 0.0367\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0331 - val_loss: 0.0368\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0331 - val_loss: 0.0368\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0330 - val_loss: 0.0369\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0330 - val_loss: 0.0369\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0330 - val_loss: 0.0370\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0329 - val_loss: 0.0370\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0329 - val_loss: 0.0371\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0329 - val_loss: 0.0371\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0328 - val_loss: 0.0372\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0328 - val_loss: 0.0372\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0327 - val_loss: 0.0373\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0327 - val_loss: 0.0373\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0327 - val_loss: 0.0374\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0326 - val_loss: 0.0374\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - val_loss: 0.0375\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0326 - val_loss: 0.0375\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0325 - val_loss: 0.0376\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0325 - val_loss: 0.0376\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0325 - val_loss: 0.0377\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0324 - val_loss: 0.0377\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0324 - val_loss: 0.0378\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - val_loss: 0.0378\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0323 - val_loss: 0.0379\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0323 - val_loss: 0.0379\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0322 - val_loss: 0.0380\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0322 - val_loss: 0.0380\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0322 - val_loss: 0.0381\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0321 - val_loss: 0.0381\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0321 - val_loss: 0.0382\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0321 - val_loss: 0.0382\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0320 - val_loss: 0.0383\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 1.5978 - val_loss: 2.1799\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5638 - val_loss: 2.1340\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5302 - val_loss: 2.0886\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4970 - val_loss: 2.0437\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4643 - val_loss: 1.9993\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4320 - val_loss: 1.9555\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4002 - val_loss: 1.9123\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3688 - val_loss: 1.8696\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3379 - val_loss: 1.8276\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3075 - val_loss: 1.7861\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2775 - val_loss: 1.7452\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2480 - val_loss: 1.7048\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2190 - val_loss: 1.6651\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1905 - val_loss: 1.6261\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1625 - val_loss: 1.5876\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1350 - val_loss: 1.5497\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1080 - val_loss: 1.5125\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0814 - val_loss: 1.4759\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0554 - val_loss: 1.4399\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0298 - val_loss: 1.4046\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0048 - val_loss: 1.3699\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9802 - val_loss: 1.3358\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9561 - val_loss: 1.3024\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.9326 - val_loss: 1.2696\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9095 - val_loss: 1.2374\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8869 - val_loss: 1.2058\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8647 - val_loss: 1.1749\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8431 - val_loss: 1.1446\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8220 - val_loss: 1.1150\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8013 - val_loss: 1.0859\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7811 - val_loss: 1.0575\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7613 - val_loss: 1.0296\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7420 - val_loss: 1.0024\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7232 - val_loss: 0.9758\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7048 - val_loss: 0.9498\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6869 - val_loss: 0.9244\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.8995\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6524 - val_loss: 0.8753\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6357 - val_loss: 0.8516\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6195 - val_loss: 0.8284\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6038 - val_loss: 0.8058\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5884 - val_loss: 0.7838\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5734 - val_loss: 0.7623\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5589 - val_loss: 0.7414\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5447 - val_loss: 0.7210\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5309 - val_loss: 0.7011\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5175 - val_loss: 0.6817\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5044 - val_loss: 0.6628\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4917 - val_loss: 0.6444\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4794 - val_loss: 0.6265\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4674 - val_loss: 0.6091\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4558 - val_loss: 0.5921\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4445 - val_loss: 0.5756\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4335 - val_loss: 0.5596\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4229 - val_loss: 0.5440\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4125 - val_loss: 0.5288\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4025 - val_loss: 0.5141\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3928 - val_loss: 0.4998\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3833 - val_loss: 0.4859\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3742 - val_loss: 0.4724\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3653 - val_loss: 0.4592\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3567 - val_loss: 0.4465\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3484 - val_loss: 0.4341\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3403 - val_loss: 0.4221\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3325 - val_loss: 0.4105\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3249 - val_loss: 0.3992\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3176 - val_loss: 0.3883\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3104 - val_loss: 0.3776\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3036 - val_loss: 0.3674\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2969 - val_loss: 0.3574\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2904 - val_loss: 0.3477\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2842 - val_loss: 0.3384\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2782 - val_loss: 0.3293\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2723 - val_loss: 0.3205\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2666 - val_loss: 0.3120\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2612 - val_loss: 0.3037\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2559 - val_loss: 0.2958\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2508 - val_loss: 0.2880\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2458 - val_loss: 0.2806\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2410 - val_loss: 0.2733\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2364 - val_loss: 0.2663\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2319 - val_loss: 0.2596\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2275 - val_loss: 0.2530\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2233 - val_loss: 0.2467\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2193 - val_loss: 0.2406\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2153 - val_loss: 0.2347\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2115 - val_loss: 0.2289\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2079 - val_loss: 0.2234\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2043 - val_loss: 0.2181\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2009 - val_loss: 0.2129\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1975 - val_loss: 0.2079\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1943 - val_loss: 0.2031\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1912 - val_loss: 0.1984\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1882 - val_loss: 0.1939\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1852 - val_loss: 0.1895\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1824 - val_loss: 0.1853\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1797 - val_loss: 0.1813\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1770 - val_loss: 0.1774\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1744 - val_loss: 0.1736\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1720 - val_loss: 0.1699\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1695 - val_loss: 0.1664\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1672 - val_loss: 0.1630\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1649 - val_loss: 0.1597\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1627 - val_loss: 0.1565\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1606 - val_loss: 0.1534\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1585 - val_loss: 0.1504\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1565 - val_loss: 0.1476\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1545 - val_loss: 0.1448\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1526 - val_loss: 0.1421\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1508 - val_loss: 0.1395\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1490 - val_loss: 0.1371\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1473 - val_loss: 0.1346\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1456 - val_loss: 0.1323\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1439 - val_loss: 0.1301\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1423 - val_loss: 0.1279\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1408 - val_loss: 0.1258\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1393 - val_loss: 0.1238\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1378 - val_loss: 0.1218\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1363 - val_loss: 0.1199\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1349 - val_loss: 0.1181\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1336 - val_loss: 0.1164\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1322 - val_loss: 0.1147\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1309 - val_loss: 0.1130\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1297 - val_loss: 0.1114\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1284 - val_loss: 0.1099\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1272 - val_loss: 0.1084\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1260 - val_loss: 0.1070\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1249 - val_loss: 0.1056\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1237 - val_loss: 0.1042\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1226 - val_loss: 0.1029\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1215 - val_loss: 0.1017\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1205 - val_loss: 0.1005\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1194 - val_loss: 0.0993\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1184 - val_loss: 0.0981\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1174 - val_loss: 0.0970\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1165 - val_loss: 0.0960\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1155 - val_loss: 0.0949\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1146 - val_loss: 0.0939\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1136 - val_loss: 0.0930\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1127 - val_loss: 0.0920\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1119 - val_loss: 0.0911\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1110 - val_loss: 0.0903\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1101 - val_loss: 0.0894\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1093 - val_loss: 0.0886\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1085 - val_loss: 0.0878\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1077 - val_loss: 0.0870\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1069 - val_loss: 0.0862\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1061 - val_loss: 0.0855\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1053 - val_loss: 0.0848\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1046 - val_loss: 0.0841\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1038 - val_loss: 0.0834\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1031 - val_loss: 0.0828\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1024 - val_loss: 0.0822\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1017 - val_loss: 0.0816\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1010 - val_loss: 0.0810\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1003 - val_loss: 0.0804\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0996 - val_loss: 0.0798\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0990 - val_loss: 0.0793\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0983 - val_loss: 0.0787\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0977 - val_loss: 0.0782\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0970 - val_loss: 0.0777\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0964 - val_loss: 0.0772\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0958 - val_loss: 0.0767\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0952 - val_loss: 0.0763\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0946 - val_loss: 0.0758\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0940 - val_loss: 0.0754\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0934 - val_loss: 0.0749\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0929 - val_loss: 0.0745\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0923 - val_loss: 0.0741\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0917 - val_loss: 0.0737\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0912 - val_loss: 0.0733\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0906 - val_loss: 0.0729\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0901 - val_loss: 0.0726\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0896 - val_loss: 0.0722\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0890 - val_loss: 0.0718\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0885 - val_loss: 0.0715\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0880 - val_loss: 0.0711\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0875 - val_loss: 0.0708\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0870 - val_loss: 0.0705\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0865 - val_loss: 0.0702\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0860 - val_loss: 0.0699\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0856 - val_loss: 0.0695\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0851 - val_loss: 0.0692\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0846 - val_loss: 0.0689\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0842 - val_loss: 0.0687\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0837 - val_loss: 0.0684\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0833 - val_loss: 0.0681\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0828 - val_loss: 0.0678\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0824 - val_loss: 0.0676\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0819 - val_loss: 0.0673\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0815 - val_loss: 0.0670\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0811 - val_loss: 0.0668\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0807 - val_loss: 0.0665\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0803 - val_loss: 0.0663\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0798 - val_loss: 0.0661\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0794 - val_loss: 0.0658\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0790 - val_loss: 0.0656\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0786 - val_loss: 0.0654\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0783 - val_loss: 0.0651\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0779 - val_loss: 0.0649\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0775 - val_loss: 0.0647\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0771 - val_loss: 0.0645\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0767 - val_loss: 0.0643\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0764 - val_loss: 0.0641\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0760 - val_loss: 0.0638\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0756 - val_loss: 0.0636\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0753 - val_loss: 0.0634\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0749 - val_loss: 0.0633\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0746 - val_loss: 0.0631\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0742 - val_loss: 0.0629\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0739 - val_loss: 0.0627\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0735 - val_loss: 0.0625\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0732 - val_loss: 0.0623\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0728 - val_loss: 0.0621\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0725 - val_loss: 0.0620\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0722 - val_loss: 0.0618\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0719 - val_loss: 0.0616\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0715 - val_loss: 0.0614\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0712 - val_loss: 0.0613\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0709 - val_loss: 0.0611\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0706 - val_loss: 0.0609\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0703 - val_loss: 0.0608\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0700 - val_loss: 0.0606\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0697 - val_loss: 0.0604\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0694 - val_loss: 0.0603\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0691 - val_loss: 0.0601\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0688 - val_loss: 0.0600\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0685 - val_loss: 0.0598\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0682 - val_loss: 0.0597\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0679 - val_loss: 0.0595\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0676 - val_loss: 0.0594\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0673 - val_loss: 0.0592\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0671 - val_loss: 0.0591\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0668 - val_loss: 0.0589\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0665 - val_loss: 0.0588\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0662 - val_loss: 0.0587\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0660 - val_loss: 0.0585\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0657 - val_loss: 0.0584\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0654 - val_loss: 0.0583\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0652 - val_loss: 0.0581\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0649 - val_loss: 0.0580\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0646 - val_loss: 0.0579\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0644 - val_loss: 0.0577\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0641 - val_loss: 0.0576\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0639 - val_loss: 0.0575\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0636 - val_loss: 0.0573\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0634 - val_loss: 0.0572\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0631 - val_loss: 0.0571\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0629 - val_loss: 0.0570\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0627 - val_loss: 0.0569\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0624 - val_loss: 0.0567\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0622 - val_loss: 0.0566\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0619 - val_loss: 0.0565\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0617 - val_loss: 0.0564\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0615 - val_loss: 0.0563\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0612 - val_loss: 0.0561\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0610 - val_loss: 0.0560\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0608 - val_loss: 0.0559\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0606 - val_loss: 0.0558\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0603 - val_loss: 0.0557\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0601 - val_loss: 0.0556\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0599 - val_loss: 0.0555\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0597 - val_loss: 0.0554\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0595 - val_loss: 0.0553\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0593 - val_loss: 0.0552\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0590 - val_loss: 0.0551\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0588 - val_loss: 0.0549\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0586 - val_loss: 0.0548\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0584 - val_loss: 0.0547\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0582 - val_loss: 0.0546\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0580 - val_loss: 0.0545\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0578 - val_loss: 0.0544\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0576 - val_loss: 0.0543\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0574 - val_loss: 0.0542\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0572 - val_loss: 0.0541\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0570 - val_loss: 0.0540\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0568 - val_loss: 0.0539\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0566 - val_loss: 0.0538\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0564 - val_loss: 0.0538\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0562 - val_loss: 0.0537\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0561 - val_loss: 0.0536\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0559 - val_loss: 0.0535\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0557 - val_loss: 0.0534\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0555 - val_loss: 0.0533\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0553 - val_loss: 0.0532\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0551 - val_loss: 0.0531\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0549 - val_loss: 0.0530\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0548 - val_loss: 0.0529\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0546 - val_loss: 0.0528\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0544 - val_loss: 0.0528\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0542 - val_loss: 0.0527\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0541 - val_loss: 0.0526\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0539 - val_loss: 0.0525\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0537 - val_loss: 0.0524\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0535 - val_loss: 0.0523\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0534 - val_loss: 0.0522\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0532 - val_loss: 0.0522\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0530 - val_loss: 0.0521\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0529 - val_loss: 0.0520\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0527 - val_loss: 0.0519\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0525 - val_loss: 0.0518\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0524 - val_loss: 0.0518\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0522 - val_loss: 0.0517\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0521 - val_loss: 0.0516\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0519 - val_loss: 0.0515\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0517 - val_loss: 0.0514\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0516 - val_loss: 0.0514\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0514 - val_loss: 0.0513\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0513 - val_loss: 0.0512\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0511 - val_loss: 0.0511\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0510 - val_loss: 0.0510\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0508 - val_loss: 0.0510\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0507 - val_loss: 0.0509\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0505 - val_loss: 0.0508\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0504 - val_loss: 0.0507\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0502 - val_loss: 0.0507\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0501 - val_loss: 0.0506\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0499 - val_loss: 0.0505\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0498 - val_loss: 0.0505\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0497 - val_loss: 0.0504\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0495 - val_loss: 0.0503\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0494 - val_loss: 0.0502\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0492 - val_loss: 0.0502\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0491 - val_loss: 0.0501\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0490 - val_loss: 0.0500\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0488 - val_loss: 0.0500\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0487 - val_loss: 0.0499\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0486 - val_loss: 0.0498\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0484 - val_loss: 0.0498\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0483 - val_loss: 0.0497\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0482 - val_loss: 0.0496\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0480 - val_loss: 0.0496\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0479 - val_loss: 0.0495\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0478 - val_loss: 0.0494\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0476 - val_loss: 0.0494\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0475 - val_loss: 0.0493\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0474 - val_loss: 0.0492\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0473 - val_loss: 0.0492\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0471 - val_loss: 0.0491\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0470 - val_loss: 0.0490\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0469 - val_loss: 0.0490\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0468 - val_loss: 0.0489\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0466 - val_loss: 0.0488\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0465 - val_loss: 0.0488\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0464 - val_loss: 0.0487\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0463 - val_loss: 0.0487\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0462 - val_loss: 0.0486\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0460 - val_loss: 0.0485\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0459 - val_loss: 0.0485\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0458 - val_loss: 0.0484\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0457 - val_loss: 0.0484\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0456 - val_loss: 0.0483\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0455 - val_loss: 0.0482\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0454 - val_loss: 0.0482\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0452 - val_loss: 0.0481\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0451 - val_loss: 0.0481\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0450 - val_loss: 0.0480\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0449 - val_loss: 0.0479\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0448 - val_loss: 0.0479\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0447 - val_loss: 0.0478\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0446 - val_loss: 0.0478\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0445 - val_loss: 0.0477\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0444 - val_loss: 0.0477\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0443 - val_loss: 0.0476\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0442 - val_loss: 0.0475\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0441 - val_loss: 0.0475\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0440 - val_loss: 0.0474\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0438 - val_loss: 0.0474\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0437 - val_loss: 0.0473\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0436 - val_loss: 0.0473\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0435 - val_loss: 0.0472\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0434 - val_loss: 0.0472\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0433 - val_loss: 0.0471\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0432 - val_loss: 0.0470\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0432 - val_loss: 0.0470\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0431 - val_loss: 0.0469\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0430 - val_loss: 0.0469\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0429 - val_loss: 0.0468\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0428 - val_loss: 0.0468\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0427 - val_loss: 0.0467\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0426 - val_loss: 0.0467\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0425 - val_loss: 0.0466\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0424 - val_loss: 0.0466\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0423 - val_loss: 0.0465\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0422 - val_loss: 0.0465\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0421 - val_loss: 0.0464\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0420 - val_loss: 0.0464\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0419 - val_loss: 0.0463\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0418 - val_loss: 0.0463\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0418 - val_loss: 0.0462\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0417 - val_loss: 0.0462\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0416 - val_loss: 0.0461\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0415 - val_loss: 0.0461\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0414 - val_loss: 0.0460\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0413 - val_loss: 0.0460\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0412 - val_loss: 0.0459\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0412 - val_loss: 0.0459\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0411 - val_loss: 0.0458\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0410 - val_loss: 0.0458\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0409 - val_loss: 0.0457\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0408 - val_loss: 0.0457\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0407 - val_loss: 0.0456\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0407 - val_loss: 0.0456\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0406 - val_loss: 0.0456\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0405 - val_loss: 0.0455\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0404 - val_loss: 0.0455\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0403 - val_loss: 0.0454\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0403 - val_loss: 0.0454\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0402 - val_loss: 0.0453\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0401 - val_loss: 0.0453\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0400 - val_loss: 0.0452\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0400 - val_loss: 0.0452\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0399 - val_loss: 0.0451\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0398 - val_loss: 0.0451\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0397 - val_loss: 0.0451\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0396 - val_loss: 0.0450\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0396 - val_loss: 0.0450\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0395 - val_loss: 0.0449\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0394 - val_loss: 0.0449\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0394 - val_loss: 0.0448\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0393 - val_loss: 0.0448\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0392 - val_loss: 0.0448\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0391 - val_loss: 0.0447\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0391 - val_loss: 0.0447\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0390 - val_loss: 0.0446\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0389 - val_loss: 0.0446\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0389 - val_loss: 0.0445\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0388 - val_loss: 0.0445\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0387 - val_loss: 0.0445\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0387 - val_loss: 0.0444\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0386 - val_loss: 0.0444\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0385 - val_loss: 0.0443\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0385 - val_loss: 0.0443\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0384 - val_loss: 0.0443\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0383 - val_loss: 0.0442\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0383 - val_loss: 0.0442\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0382 - val_loss: 0.0441\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0381 - val_loss: 0.0441\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0381 - val_loss: 0.0441\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0380 - val_loss: 0.0440\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0379 - val_loss: 0.0440\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0379 - val_loss: 0.0439\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0378 - val_loss: 0.0439\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0377 - val_loss: 0.0439\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0377 - val_loss: 0.0438\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0376 - val_loss: 0.0438\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0376 - val_loss: 0.0437\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0375 - val_loss: 0.0437\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0374 - val_loss: 0.0437\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0374 - val_loss: 0.0436\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0373 - val_loss: 0.0436\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0373 - val_loss: 0.0435\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0372 - val_loss: 0.0435\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0371 - val_loss: 0.0435\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0371 - val_loss: 0.0434\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0370 - val_loss: 0.0434\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0370 - val_loss: 0.0434\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0369 - val_loss: 0.0433\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0369 - val_loss: 0.0433\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0368 - val_loss: 0.0432\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0367 - val_loss: 0.0432\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0367 - val_loss: 0.0432\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0366 - val_loss: 0.0431\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0366 - val_loss: 0.0431\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.0431\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0365 - val_loss: 0.0430\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0364 - val_loss: 0.0430\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0364 - val_loss: 0.0430\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0363 - val_loss: 0.0429\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0363 - val_loss: 0.0429\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0362 - val_loss: 0.0429\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0361 - val_loss: 0.0428\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - val_loss: 0.0428\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0360 - val_loss: 0.0427\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0360 - val_loss: 0.0427\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0359 - val_loss: 0.0427\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0359 - val_loss: 0.0426\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0358 - val_loss: 0.0426\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0358 - val_loss: 0.0426\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - val_loss: 0.0425\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0357 - val_loss: 0.0425\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0356 - val_loss: 0.0425\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0356 - val_loss: 0.0424\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0355 - val_loss: 0.0424\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0355 - val_loss: 0.0424\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0354 - val_loss: 0.0423\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0354 - val_loss: 0.0423\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0354 - val_loss: 0.0423\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0353 - val_loss: 0.0422\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0353 - val_loss: 0.0422\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0352 - val_loss: 0.0422\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0352 - val_loss: 0.0421\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0351 - val_loss: 0.0421\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0351 - val_loss: 0.0421\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0350 - val_loss: 0.0420\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0350 - val_loss: 0.0420\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0349 - val_loss: 0.0420\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0349 - val_loss: 0.0419\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0348 - val_loss: 0.0419\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0348 - val_loss: 0.0419\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0348 - val_loss: 0.0418\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0347 - val_loss: 0.0418\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0347 - val_loss: 0.0418\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0346 - val_loss: 0.0418\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0346 - val_loss: 0.0417\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0345 - val_loss: 0.0417\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0345 - val_loss: 0.0417\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0345 - val_loss: 0.0416\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0344 - val_loss: 0.0416\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0344 - val_loss: 0.0416\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0343 - val_loss: 0.0415\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0343 - val_loss: 0.0415\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0342 - val_loss: 0.0415\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0342 - val_loss: 0.0414\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0342 - val_loss: 0.0414\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0341 - val_loss: 0.0414\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0341 - val_loss: 0.0414\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0340 - val_loss: 0.0413\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0340 - val_loss: 0.0413\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0340 - val_loss: 0.0413\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0339 - val_loss: 0.0412\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0339 - val_loss: 0.0412\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0338 - val_loss: 0.0412\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0338 - val_loss: 0.0411\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0338 - val_loss: 0.0411\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0411\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0337 - val_loss: 0.0411\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0410\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0336 - val_loss: 0.0410\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0336 - val_loss: 0.0410\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0335 - val_loss: 0.0409\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0335 - val_loss: 0.0409\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0335 - val_loss: 0.0409\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0334 - val_loss: 0.0409\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0334 - val_loss: 0.0408\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0334 - val_loss: 0.0408\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0333 - val_loss: 0.0408\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0333 - val_loss: 0.0407\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0333 - val_loss: 0.0407\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0332 - val_loss: 0.0407\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0332 - val_loss: 0.0407\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0331 - val_loss: 0.0406\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0331 - val_loss: 0.0406\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0331 - val_loss: 0.0406\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0330 - val_loss: 0.0405\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0330 - val_loss: 0.0405\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0330 - val_loss: 0.0405\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0329 - val_loss: 0.0405\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0329 - val_loss: 0.0404\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0329 - val_loss: 0.0404\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0328 - val_loss: 0.0404\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0328 - val_loss: 0.0403\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0328 - val_loss: 0.0403\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0327 - val_loss: 0.0403\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0327 - val_loss: 0.0403\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0327 - val_loss: 0.0402\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0326 - val_loss: 0.0402\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0326 - val_loss: 0.0402\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0326 - val_loss: 0.0402\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0325 - val_loss: 0.0401\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0325 - val_loss: 0.0401\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0325 - val_loss: 0.0401\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0324 - val_loss: 0.0401\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0324 - val_loss: 0.0400\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0324 - val_loss: 0.0400\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0324 - val_loss: 0.0400\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0323 - val_loss: 0.0400\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0323 - val_loss: 0.0399\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0323 - val_loss: 0.0399\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0322 - val_loss: 0.0399\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.0398\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0322 - val_loss: 0.0398\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0321 - val_loss: 0.0398\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0321 - val_loss: 0.0398\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0321 - val_loss: 0.0397\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0321 - val_loss: 0.0397\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0320 - val_loss: 0.0397\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.0397\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0320 - val_loss: 0.0396\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0319 - val_loss: 0.0396\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0319 - val_loss: 0.0396\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0319 - val_loss: 0.0396\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0318 - val_loss: 0.0395\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0318 - val_loss: 0.0395\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0318 - val_loss: 0.0395\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0318 - val_loss: 0.0395\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0317 - val_loss: 0.0394\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0317 - val_loss: 0.0394\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0317 - val_loss: 0.0394\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0317 - val_loss: 0.0394\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0316 - val_loss: 0.0393\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0316 - val_loss: 0.0393\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0316 - val_loss: 0.0393\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0315 - val_loss: 0.0393\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0315 - val_loss: 0.0393\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0315 - val_loss: 0.0392\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0315 - val_loss: 0.0392\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0314 - val_loss: 0.0392\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0314 - val_loss: 0.0392\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0314 - val_loss: 0.0391\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.8272 - val_loss: 0.8279\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8015 - val_loss: 0.8037\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7764 - val_loss: 0.7801\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7519 - val_loss: 0.7570\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7279 - val_loss: 0.7345\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7045 - val_loss: 0.7126\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6817 - val_loss: 0.6912\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6594 - val_loss: 0.6704\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6378 - val_loss: 0.6502\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6167 - val_loss: 0.6305\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5962 - val_loss: 0.6115\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5763 - val_loss: 0.5930\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5570 - val_loss: 0.5751\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5382 - val_loss: 0.5578\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5200 - val_loss: 0.5410\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5024 - val_loss: 0.5248\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4854 - val_loss: 0.5091\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4689 - val_loss: 0.4940\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4530 - val_loss: 0.4794\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4376 - val_loss: 0.4653\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4227 - val_loss: 0.4517\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4084 - val_loss: 0.4386\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3946 - val_loss: 0.4260\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3812 - val_loss: 0.4138\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3684 - val_loss: 0.4021\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3560 - val_loss: 0.3908\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3441 - val_loss: 0.3800\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3327 - val_loss: 0.3695\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3217 - val_loss: 0.3595\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3111 - val_loss: 0.3498\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3010 - val_loss: 0.3405\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2912 - val_loss: 0.3316\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2818 - val_loss: 0.3230\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2728 - val_loss: 0.3147\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2641 - val_loss: 0.3068\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2559 - val_loss: 0.2991\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2479 - val_loss: 0.2917\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2403 - val_loss: 0.2847\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2329 - val_loss: 0.2778\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2259 - val_loss: 0.2713\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2192 - val_loss: 0.2650\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2127 - val_loss: 0.2589\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2065 - val_loss: 0.2531\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2006 - val_loss: 0.2475\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1949 - val_loss: 0.2420\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1895 - val_loss: 0.2368\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1843 - val_loss: 0.2318\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1793 - val_loss: 0.2270\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1745 - val_loss: 0.2224\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1700 - val_loss: 0.2179\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1656 - val_loss: 0.2136\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1614 - val_loss: 0.2095\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1574 - val_loss: 0.2055\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1536 - val_loss: 0.2017\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1499 - val_loss: 0.1980\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1464 - val_loss: 0.1945\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1431 - val_loss: 0.1911\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1399 - val_loss: 0.1878\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1368 - val_loss: 0.1847\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1339 - val_loss: 0.1816\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1311 - val_loss: 0.1787\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1285 - val_loss: 0.1759\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1259 - val_loss: 0.1733\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1235 - val_loss: 0.1707\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1212 - val_loss: 0.1682\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1190 - val_loss: 0.1658\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1168 - val_loss: 0.1635\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1148 - val_loss: 0.1613\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1129 - val_loss: 0.1592\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1111 - val_loss: 0.1572\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1093 - val_loss: 0.1553\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1076 - val_loss: 0.1534\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1060 - val_loss: 0.1516\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1045 - val_loss: 0.1499\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1030 - val_loss: 0.1482\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1016 - val_loss: 0.1466\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1002 - val_loss: 0.1450\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0990 - val_loss: 0.1436\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0977 - val_loss: 0.1421\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0965 - val_loss: 0.1408\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0954 - val_loss: 0.1394\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0943 - val_loss: 0.1382\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0933 - val_loss: 0.1369\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0923 - val_loss: 0.1357\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0913 - val_loss: 0.1346\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0904 - val_loss: 0.1335\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0895 - val_loss: 0.1324\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0886 - val_loss: 0.1314\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0878 - val_loss: 0.1304\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0870 - val_loss: 0.1294\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0862 - val_loss: 0.1285\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0854 - val_loss: 0.1276\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0847 - val_loss: 0.1267\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0840 - val_loss: 0.1258\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0833 - val_loss: 0.1250\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0827 - val_loss: 0.1242\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0820 - val_loss: 0.1234\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0814 - val_loss: 0.1226\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0808 - val_loss: 0.1219\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0802 - val_loss: 0.1211\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0796 - val_loss: 0.1204\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0790 - val_loss: 0.1197\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0785 - val_loss: 0.1191\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0779 - val_loss: 0.1184\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0774 - val_loss: 0.1177\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0769 - val_loss: 0.1171\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0764 - val_loss: 0.1165\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0759 - val_loss: 0.1159\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0754 - val_loss: 0.1153\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0749 - val_loss: 0.1147\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0745 - val_loss: 0.1141\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0740 - val_loss: 0.1135\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0735 - val_loss: 0.1130\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0731 - val_loss: 0.1124\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0727 - val_loss: 0.1119\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0722 - val_loss: 0.1113\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0718 - val_loss: 0.1108\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0714 - val_loss: 0.1103\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0710 - val_loss: 0.1098\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0706 - val_loss: 0.1093\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0702 - val_loss: 0.1088\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0698 - val_loss: 0.1083\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0694 - val_loss: 0.1078\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0690 - val_loss: 0.1073\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0686 - val_loss: 0.1069\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0682 - val_loss: 0.1064\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0679 - val_loss: 0.1059\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0675 - val_loss: 0.1055\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0671 - val_loss: 0.1050\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0668 - val_loss: 0.1046\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0664 - val_loss: 0.1041\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0661 - val_loss: 0.1037\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0657 - val_loss: 0.1032\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0654 - val_loss: 0.1028\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0650 - val_loss: 0.1024\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0647 - val_loss: 0.1020\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0644 - val_loss: 0.1016\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0640 - val_loss: 0.1012\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0637 - val_loss: 0.1007\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0634 - val_loss: 0.1003\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0631 - val_loss: 0.0999\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0628 - val_loss: 0.0996\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0624 - val_loss: 0.0992\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0621 - val_loss: 0.0988\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0618 - val_loss: 0.0984\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0615 - val_loss: 0.0980\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0612 - val_loss: 0.0976\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0609 - val_loss: 0.0973\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0606 - val_loss: 0.0969\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0603 - val_loss: 0.0965\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0601 - val_loss: 0.0962\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0598 - val_loss: 0.0958\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0595 - val_loss: 0.0955\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0592 - val_loss: 0.0951\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0589 - val_loss: 0.0948\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0586 - val_loss: 0.0944\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0584 - val_loss: 0.0941\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0581 - val_loss: 0.0938\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0578 - val_loss: 0.0934\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0576 - val_loss: 0.0931\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0573 - val_loss: 0.0928\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0571 - val_loss: 0.0925\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0568 - val_loss: 0.0922\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0565 - val_loss: 0.0918\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0563 - val_loss: 0.0915\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0560 - val_loss: 0.0912\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0558 - val_loss: 0.0909\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0555 - val_loss: 0.0906\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0553 - val_loss: 0.0903\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0551 - val_loss: 0.0900\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0548 - val_loss: 0.0897\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0546 - val_loss: 0.0894\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0543 - val_loss: 0.0891\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0541 - val_loss: 0.0889\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0539 - val_loss: 0.0886\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0536 - val_loss: 0.0883\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0534 - val_loss: 0.0880\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0532 - val_loss: 0.0877\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0530 - val_loss: 0.0875\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0527 - val_loss: 0.0872\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0525 - val_loss: 0.0869\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0523 - val_loss: 0.0866\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0521 - val_loss: 0.0864\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0519 - val_loss: 0.0861\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0517 - val_loss: 0.0859\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0515 - val_loss: 0.0856\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0513 - val_loss: 0.0853\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0511 - val_loss: 0.0851\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0508 - val_loss: 0.0848\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0506 - val_loss: 0.0846\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0504 - val_loss: 0.0843\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0502 - val_loss: 0.0841\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0501 - val_loss: 0.0839\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0499 - val_loss: 0.0836\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0497 - val_loss: 0.0834\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0495 - val_loss: 0.0831\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0493 - val_loss: 0.0829\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0491 - val_loss: 0.0827\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0489 - val_loss: 0.0824\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0487 - val_loss: 0.0822\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0485 - val_loss: 0.0820\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0484 - val_loss: 0.0818\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0482 - val_loss: 0.0815\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0480 - val_loss: 0.0813\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0478 - val_loss: 0.0811\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0477 - val_loss: 0.0809\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0475 - val_loss: 0.0807\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0473 - val_loss: 0.0804\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0471 - val_loss: 0.0802\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0470 - val_loss: 0.0800\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0468 - val_loss: 0.0798\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0466 - val_loss: 0.0796\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0465 - val_loss: 0.0794\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0463 - val_loss: 0.0792\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0461 - val_loss: 0.0790\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0460 - val_loss: 0.0788\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0458 - val_loss: 0.0786\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0457 - val_loss: 0.0784\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0455 - val_loss: 0.0782\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0454 - val_loss: 0.0780\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0452 - val_loss: 0.0778\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0451 - val_loss: 0.0776\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0449 - val_loss: 0.0774\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0448 - val_loss: 0.0772\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0446 - val_loss: 0.0770\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0445 - val_loss: 0.0768\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0443 - val_loss: 0.0766\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0442 - val_loss: 0.0764\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0440 - val_loss: 0.0762\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0439 - val_loss: 0.0761\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0438 - val_loss: 0.0759\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0436 - val_loss: 0.0757\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0435 - val_loss: 0.0755\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0434 - val_loss: 0.0753\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0432 - val_loss: 0.0752\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0431 - val_loss: 0.0750\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0430 - val_loss: 0.0748\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0428 - val_loss: 0.0746\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0427 - val_loss: 0.0745\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0426 - val_loss: 0.0743\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0424 - val_loss: 0.0741\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0423 - val_loss: 0.0739\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0422 - val_loss: 0.0738\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0421 - val_loss: 0.0736\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0419 - val_loss: 0.0734\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0418 - val_loss: 0.0733\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0417 - val_loss: 0.0731\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0416 - val_loss: 0.0729\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0415 - val_loss: 0.0728\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0413 - val_loss: 0.0726\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0412 - val_loss: 0.0724\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0411 - val_loss: 0.0723\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0410 - val_loss: 0.0721\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0409 - val_loss: 0.0720\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0408 - val_loss: 0.0718\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0407 - val_loss: 0.0716\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0405 - val_loss: 0.0715\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0404 - val_loss: 0.0713\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0403 - val_loss: 0.0712\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0402 - val_loss: 0.0710\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0401 - val_loss: 0.0709\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0400 - val_loss: 0.0707\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0399 - val_loss: 0.0706\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0398 - val_loss: 0.0704\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0397 - val_loss: 0.0703\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0396 - val_loss: 0.0701\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0395 - val_loss: 0.0700\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0394 - val_loss: 0.0698\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0393 - val_loss: 0.0697\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0392 - val_loss: 0.0695\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0391 - val_loss: 0.0694\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0390 - val_loss: 0.0693\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0389 - val_loss: 0.0691\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0388 - val_loss: 0.0690\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0387 - val_loss: 0.0688\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0386 - val_loss: 0.0687\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0385 - val_loss: 0.0685\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0385 - val_loss: 0.0684\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0384 - val_loss: 0.0683\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0383 - val_loss: 0.0681\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0382 - val_loss: 0.0680\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0381 - val_loss: 0.0679\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0380 - val_loss: 0.0677\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0379 - val_loss: 0.0676\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0378 - val_loss: 0.0675\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0378 - val_loss: 0.0673\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0377 - val_loss: 0.0672\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0376 - val_loss: 0.0671\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0375 - val_loss: 0.0669\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0374 - val_loss: 0.0668\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0373 - val_loss: 0.0667\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0373 - val_loss: 0.0665\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0372 - val_loss: 0.0664\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0371 - val_loss: 0.0663\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0370 - val_loss: 0.0662\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0370 - val_loss: 0.0660\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0369 - val_loss: 0.0659\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0368 - val_loss: 0.0658\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0367 - val_loss: 0.0657\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0367 - val_loss: 0.0655\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0366 - val_loss: 0.0654\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.0653\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0364 - val_loss: 0.0652\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0364 - val_loss: 0.0650\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0363 - val_loss: 0.0649\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0362 - val_loss: 0.0648\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - val_loss: 0.0647\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0361 - val_loss: 0.0646\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0360 - val_loss: 0.0644\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0359 - val_loss: 0.0643\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0359 - val_loss: 0.0642\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0358 - val_loss: 0.0641\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0357 - val_loss: 0.0640\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0357 - val_loss: 0.0639\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0356 - val_loss: 0.0637\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0355 - val_loss: 0.0636\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0355 - val_loss: 0.0635\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0354 - val_loss: 0.0634\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0354 - val_loss: 0.0633\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0353 - val_loss: 0.0632\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0352 - val_loss: 0.0631\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0352 - val_loss: 0.0630\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0351 - val_loss: 0.0628\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0350 - val_loss: 0.0627\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0350 - val_loss: 0.0626\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0349 - val_loss: 0.0625\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0349 - val_loss: 0.0624\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0348 - val_loss: 0.0623\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0348 - val_loss: 0.0622\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0347 - val_loss: 0.0621\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0346 - val_loss: 0.0620\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0346 - val_loss: 0.0619\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0345 - val_loss: 0.0618\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0345 - val_loss: 0.0617\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0344 - val_loss: 0.0616\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0344 - val_loss: 0.0614\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0343 - val_loss: 0.0613\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0343 - val_loss: 0.0612\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0342 - val_loss: 0.0611\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0341 - val_loss: 0.0610\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0341 - val_loss: 0.0609\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0340 - val_loss: 0.0608\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0340 - val_loss: 0.0607\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0339 - val_loss: 0.0606\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0339 - val_loss: 0.0605\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0338 - val_loss: 0.0604\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0338 - val_loss: 0.0603\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0602\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0601\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0600\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0336 - val_loss: 0.0599\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0335 - val_loss: 0.0598\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0335 - val_loss: 0.0598\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0335 - val_loss: 0.0597\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0334 - val_loss: 0.0596\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0334 - val_loss: 0.0595\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0333 - val_loss: 0.0594\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0333 - val_loss: 0.0593\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0332 - val_loss: 0.0592\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0332 - val_loss: 0.0591\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0331 - val_loss: 0.0590\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0331 - val_loss: 0.0589\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0330 - val_loss: 0.0588\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0330 - val_loss: 0.0587\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0330 - val_loss: 0.0586\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0329 - val_loss: 0.0585\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0329 - val_loss: 0.0585\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0328 - val_loss: 0.0584\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0328 - val_loss: 0.0583\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0327 - val_loss: 0.0582\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0327 - val_loss: 0.0581\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0327 - val_loss: 0.0580\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0326 - val_loss: 0.0579\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0326 - val_loss: 0.0578\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0325 - val_loss: 0.0578\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0325 - val_loss: 0.0577\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0325 - val_loss: 0.0576\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0324 - val_loss: 0.0575\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0324 - val_loss: 0.0574\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0323 - val_loss: 0.0573\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0323 - val_loss: 0.0572\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0323 - val_loss: 0.0572\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0322 - val_loss: 0.0571\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0322 - val_loss: 0.0570\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0322 - val_loss: 0.0569\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0321 - val_loss: 0.0568\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0321 - val_loss: 0.0568\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0320 - val_loss: 0.0567\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0320 - val_loss: 0.0566\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.0565\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0319 - val_loss: 0.0564\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0319 - val_loss: 0.0564\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0319 - val_loss: 0.0563\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0318 - val_loss: 0.0562\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0318 - val_loss: 0.0561\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0318 - val_loss: 0.0560\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0317 - val_loss: 0.0560\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0317 - val_loss: 0.0559\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0317 - val_loss: 0.0558\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0316 - val_loss: 0.0557\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0316 - val_loss: 0.0557\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0316 - val_loss: 0.0556\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0315 - val_loss: 0.0555\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0315 - val_loss: 0.0554\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0315 - val_loss: 0.0554\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0314 - val_loss: 0.0553\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0314 - val_loss: 0.0552\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0314 - val_loss: 0.0551\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0313 - val_loss: 0.0551\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0313 - val_loss: 0.0550\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0313 - val_loss: 0.0549\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0312 - val_loss: 0.0548\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0312 - val_loss: 0.0548\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0312 - val_loss: 0.0547\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0311 - val_loss: 0.0546\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0311 - val_loss: 0.0546\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0311 - val_loss: 0.0545\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0310 - val_loss: 0.0544\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0310 - val_loss: 0.0543\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0310 - val_loss: 0.0543\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0310 - val_loss: 0.0542\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0309 - val_loss: 0.0541\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0309 - val_loss: 0.0541\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0309 - val_loss: 0.0540\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0308 - val_loss: 0.0539\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0308 - val_loss: 0.0539\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0308 - val_loss: 0.0538\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0308 - val_loss: 0.0537\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0307 - val_loss: 0.0537\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0307 - val_loss: 0.0536\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0307 - val_loss: 0.0535\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0306 - val_loss: 0.0535\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0306 - val_loss: 0.0534\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0306 - val_loss: 0.0534\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0306 - val_loss: 0.0533\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0305 - val_loss: 0.0532\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0305 - val_loss: 0.0532\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0305 - val_loss: 0.0531\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0305 - val_loss: 0.0530\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0304 - val_loss: 0.0530\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0304 - val_loss: 0.0529\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0304 - val_loss: 0.0528\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0303 - val_loss: 0.0528\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0303 - val_loss: 0.0527\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0303 - val_loss: 0.0527\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0303 - val_loss: 0.0526\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0302 - val_loss: 0.0525\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0302 - val_loss: 0.0525\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0302 - val_loss: 0.0524\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0302 - val_loss: 0.0524\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0301 - val_loss: 0.0523\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0301 - val_loss: 0.0522\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0301 - val_loss: 0.0522\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0301 - val_loss: 0.0521\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0300 - val_loss: 0.0521\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0300 - val_loss: 0.0520\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0300 - val_loss: 0.0520\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0300 - val_loss: 0.0519\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0299 - val_loss: 0.0518\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0299 - val_loss: 0.0518\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0299 - val_loss: 0.0517\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0299 - val_loss: 0.0517\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0298 - val_loss: 0.0516\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0298 - val_loss: 0.0516\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0298 - val_loss: 0.0515\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0298 - val_loss: 0.0515\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0297 - val_loss: 0.0514\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0297 - val_loss: 0.0514\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0297 - val_loss: 0.0513\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0297 - val_loss: 0.0512\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0297 - val_loss: 0.0512\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0296 - val_loss: 0.0511\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0296 - val_loss: 0.0511\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0296 - val_loss: 0.0510\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0296 - val_loss: 0.0510\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0295 - val_loss: 0.0509\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0295 - val_loss: 0.0509\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0295 - val_loss: 0.0508\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0295 - val_loss: 0.0508\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0294 - val_loss: 0.0507\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0294 - val_loss: 0.0507\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0294 - val_loss: 0.0506\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0294 - val_loss: 0.0506\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0294 - val_loss: 0.0505\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0293 - val_loss: 0.0505\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0293 - val_loss: 0.0504\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0293 - val_loss: 0.0504\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0293 - val_loss: 0.0503\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0292 - val_loss: 0.0503\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0292 - val_loss: 0.0502\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0292 - val_loss: 0.0502\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0292 - val_loss: 0.0501\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0292 - val_loss: 0.0501\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0291 - val_loss: 0.0501\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0291 - val_loss: 0.0500\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - val_loss: 0.0500\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0291 - val_loss: 0.0499\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0291 - val_loss: 0.0499\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0290 - val_loss: 0.0498\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0290 - val_loss: 0.0498\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0290 - val_loss: 0.0497\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0290 - val_loss: 0.0497\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0289 - val_loss: 0.0496\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0289 - val_loss: 0.0496\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0289 - val_loss: 0.0496\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0289 - val_loss: 0.0495\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0289 - val_loss: 0.0495\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0288 - val_loss: 0.0494\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0288 - val_loss: 0.0494\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0288 - val_loss: 0.0493\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0288 - val_loss: 0.0493\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0288 - val_loss: 0.0493\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0287 - val_loss: 0.0492\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0287 - val_loss: 0.0492\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0287 - val_loss: 0.0491\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0287 - val_loss: 0.0491\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0287 - val_loss: 0.0490\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0286 - val_loss: 0.0490\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0286 - val_loss: 0.0490\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0286 - val_loss: 0.0489\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0286 - val_loss: 0.0489\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0286 - val_loss: 0.0488\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0285 - val_loss: 0.0488\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0285 - val_loss: 0.0488\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0285 - val_loss: 0.0487\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0285 - val_loss: 0.0487\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0285 - val_loss: 0.0487\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0284 - val_loss: 0.0486\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0284 - val_loss: 0.0486\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0284 - val_loss: 0.0485\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0284 - val_loss: 0.0485\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0284 - val_loss: 0.0485\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0283 - val_loss: 0.0484\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0283 - val_loss: 0.0484\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0283 - val_loss: 0.0483\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0283 - val_loss: 0.0483\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0283 - val_loss: 0.0483\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0283 - val_loss: 0.0482\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0282 - val_loss: 0.0482\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0282 - val_loss: 0.0482\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0282 - val_loss: 0.0481\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0282 - val_loss: 0.0481\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0282 - val_loss: 0.0481\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0281 - val_loss: 0.0480\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0281 - val_loss: 0.0480\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0281 - val_loss: 0.0480\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0281 - val_loss: 0.0479\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0281 - val_loss: 0.0479\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0280 - val_loss: 0.0478\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0280 - val_loss: 0.0478\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0280 - val_loss: 0.0478\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0280 - val_loss: 0.0477\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0280 - val_loss: 0.0477\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0280 - val_loss: 0.0477\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0279 - val_loss: 0.0476\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0279 - val_loss: 0.0476\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0279 - val_loss: 0.0476\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0279 - val_loss: 0.0475\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0279 - val_loss: 0.0475\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0278 - val_loss: 0.0475\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0278 - val_loss: 0.0474\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0278 - val_loss: 0.0474\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0278 - val_loss: 0.0474\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0278 - val_loss: 0.0474\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0278 - val_loss: 0.0473\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0277 - val_loss: 0.0473\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0277 - val_loss: 0.0473\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0277 - val_loss: 0.0472\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0277 - val_loss: 0.0472\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0277 - val_loss: 0.0472\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0276 - val_loss: 0.0471\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0276 - val_loss: 0.0471\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0276 - val_loss: 0.0471\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0276 - val_loss: 0.0470\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0276 - val_loss: 0.0470\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0276 - val_loss: 0.0470\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0275 - val_loss: 0.0470\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0275 - val_loss: 0.0469\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - val_loss: 0.0469\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - val_loss: 0.0469\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - val_loss: 0.0468\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0275 - val_loss: 0.0468\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0274 - val_loss: 0.0468\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0274 - val_loss: 0.0468\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0274 - val_loss: 0.0467\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0273 - val_loss: 0.0466\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0273 - val_loss: 0.0466\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0273 - val_loss: 0.0466\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0273 - val_loss: 0.0466\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0273 - val_loss: 0.0465\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0273 - val_loss: 0.0465\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0272 - val_loss: 0.0465\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0272 - val_loss: 0.0465\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0272 - val_loss: 0.0464\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0272 - val_loss: 0.0464\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0272 - val_loss: 0.0464\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0272 - val_loss: 0.0463\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0271 - val_loss: 0.0463\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.6887 - val_loss: 0.6400\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6670 - val_loss: 0.6182\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6458 - val_loss: 0.5969\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6251 - val_loss: 0.5762\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6049 - val_loss: 0.5560\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5852 - val_loss: 0.5362\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5660 - val_loss: 0.5171\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5472 - val_loss: 0.4984\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5290 - val_loss: 0.4804\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5113 - val_loss: 0.4628\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4941 - val_loss: 0.4458\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4775 - val_loss: 0.4294\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4613 - val_loss: 0.4134\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4457 - val_loss: 0.3981\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4306 - val_loss: 0.3833\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4160 - val_loss: 0.3690\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4019 - val_loss: 0.3552\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3883 - val_loss: 0.3420\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3752 - val_loss: 0.3293\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3626 - val_loss: 0.3171\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3505 - val_loss: 0.3054\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3388 - val_loss: 0.2942\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3276 - val_loss: 0.2835\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3169 - val_loss: 0.2733\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3066 - val_loss: 0.2635\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2968 - val_loss: 0.2541\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2874 - val_loss: 0.2452\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2784 - val_loss: 0.2368\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2697 - val_loss: 0.2287\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2615 - val_loss: 0.2210\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2537 - val_loss: 0.2137\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2461 - val_loss: 0.2068\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2390 - val_loss: 0.2002\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2322 - val_loss: 0.1939\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2256 - val_loss: 0.1880\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2194 - val_loss: 0.1824\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2135 - val_loss: 0.1771\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2079 - val_loss: 0.1720\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2025 - val_loss: 0.1673\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1973 - val_loss: 0.1627\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1924 - val_loss: 0.1585\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1878 - val_loss: 0.1544\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1833 - val_loss: 0.1506\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1791 - val_loss: 0.1469\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1750 - val_loss: 0.1435\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1711 - val_loss: 0.1403\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1674 - val_loss: 0.1372\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1639 - val_loss: 0.1343\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1605 - val_loss: 0.1315\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1572 - val_loss: 0.1289\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1541 - val_loss: 0.1265\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1511 - val_loss: 0.1241\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1482 - val_loss: 0.1219\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1455 - val_loss: 0.1198\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1428 - val_loss: 0.1178\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1403 - val_loss: 0.1159\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1378 - val_loss: 0.1141\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1355 - val_loss: 0.1124\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1332 - val_loss: 0.1108\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1310 - val_loss: 0.1093\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1289 - val_loss: 0.1078\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1268 - val_loss: 0.1065\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1248 - val_loss: 0.1052\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1229 - val_loss: 0.1039\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1211 - val_loss: 0.1027\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1193 - val_loss: 0.1016\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1175 - val_loss: 0.1006\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1158 - val_loss: 0.0996\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1142 - val_loss: 0.0986\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1126 - val_loss: 0.0977\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1110 - val_loss: 0.0968\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1095 - val_loss: 0.0960\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1081 - val_loss: 0.0953\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1067 - val_loss: 0.0945\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1053 - val_loss: 0.0938\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1039 - val_loss: 0.0932\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1026 - val_loss: 0.0926\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1014 - val_loss: 0.0920\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1001 - val_loss: 0.0915\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0989 - val_loss: 0.0909\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0978 - val_loss: 0.0905\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0966 - val_loss: 0.0900\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0955 - val_loss: 0.0896\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0944 - val_loss: 0.0892\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0934 - val_loss: 0.0888\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0923 - val_loss: 0.0885\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0913 - val_loss: 0.0882\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0903 - val_loss: 0.0879\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0894 - val_loss: 0.0876\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0885 - val_loss: 0.0873\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0875 - val_loss: 0.0871\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0867 - val_loss: 0.0869\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0858 - val_loss: 0.0867\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0849 - val_loss: 0.0865\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0841 - val_loss: 0.0863\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0833 - val_loss: 0.0861\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0825 - val_loss: 0.0860\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0817 - val_loss: 0.0859\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0810 - val_loss: 0.0858\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0802 - val_loss: 0.0857\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0795 - val_loss: 0.0856\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0788 - val_loss: 0.0855\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0781 - val_loss: 0.0854\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0774 - val_loss: 0.0854\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0768 - val_loss: 0.0853\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0761 - val_loss: 0.0853\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0755 - val_loss: 0.0852\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0749 - val_loss: 0.0852\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0742 - val_loss: 0.0852\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0736 - val_loss: 0.0852\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0731 - val_loss: 0.0852\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0725 - val_loss: 0.0851\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0719 - val_loss: 0.0851\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0714 - val_loss: 0.0851\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0708 - val_loss: 0.0851\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0703 - val_loss: 0.0852\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0698 - val_loss: 0.0852\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0693 - val_loss: 0.0852\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0688 - val_loss: 0.0852\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0683 - val_loss: 0.0852\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0678 - val_loss: 0.0852\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0673 - val_loss: 0.0853\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0668 - val_loss: 0.0853\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0664 - val_loss: 0.0853\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0659 - val_loss: 0.0853\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0655 - val_loss: 0.0854\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0650 - val_loss: 0.0854\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0646 - val_loss: 0.0854\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0642 - val_loss: 0.0854\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0638 - val_loss: 0.0855\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0634 - val_loss: 0.0855\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0630 - val_loss: 0.0855\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0626 - val_loss: 0.0855\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0622 - val_loss: 0.0856\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0618 - val_loss: 0.0856\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0614 - val_loss: 0.0856\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0611 - val_loss: 0.0856\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0607 - val_loss: 0.0857\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0603 - val_loss: 0.0857\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0600 - val_loss: 0.0857\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0596 - val_loss: 0.0857\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0593 - val_loss: 0.0857\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0589 - val_loss: 0.0857\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0586 - val_loss: 0.0858\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0583 - val_loss: 0.0858\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0580 - val_loss: 0.0858\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0576 - val_loss: 0.0858\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0573 - val_loss: 0.0858\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0570 - val_loss: 0.0858\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0567 - val_loss: 0.0858\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0564 - val_loss: 0.0858\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0561 - val_loss: 0.0858\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0558 - val_loss: 0.0858\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0555 - val_loss: 0.0858\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0552 - val_loss: 0.0858\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0550 - val_loss: 0.0858\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0547 - val_loss: 0.0858\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0544 - val_loss: 0.0858\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0541 - val_loss: 0.0858\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0539 - val_loss: 0.0858\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0536 - val_loss: 0.0858\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0533 - val_loss: 0.0858\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0531 - val_loss: 0.0857\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0528 - val_loss: 0.0857\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0526 - val_loss: 0.0857\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0523 - val_loss: 0.0857\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0521 - val_loss: 0.0857\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0518 - val_loss: 0.0857\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0516 - val_loss: 0.0856\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0514 - val_loss: 0.0856\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - val_loss: 0.0856\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0509 - val_loss: 0.0856\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0507 - val_loss: 0.0856\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0504 - val_loss: 0.0855\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0502 - val_loss: 0.0855\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0500 - val_loss: 0.0855\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0498 - val_loss: 0.0855\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0496 - val_loss: 0.0854\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0493 - val_loss: 0.0854\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0491 - val_loss: 0.0854\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0489 - val_loss: 0.0854\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0487 - val_loss: 0.0853\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0485 - val_loss: 0.0853\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0483 - val_loss: 0.0853\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0481 - val_loss: 0.0852\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0479 - val_loss: 0.0852\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0477 - val_loss: 0.0852\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0475 - val_loss: 0.0851\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0473 - val_loss: 0.0851\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0471 - val_loss: 0.0851\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0470 - val_loss: 0.0850\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0468 - val_loss: 0.0850\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0466 - val_loss: 0.0850\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0464 - val_loss: 0.0849\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0462 - val_loss: 0.0849\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0460 - val_loss: 0.0849\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0459 - val_loss: 0.0848\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0457 - val_loss: 0.0848\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0455 - val_loss: 0.0848\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0454 - val_loss: 0.0847\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0452 - val_loss: 0.0847\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0450 - val_loss: 0.0846\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0449 - val_loss: 0.0846\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0447 - val_loss: 0.0846\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0445 - val_loss: 0.0845\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0444 - val_loss: 0.0845\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0442 - val_loss: 0.0844\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0441 - val_loss: 0.0844\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0439 - val_loss: 0.0844\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0437 - val_loss: 0.0843\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0436 - val_loss: 0.0843\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0434 - val_loss: 0.0842\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0433 - val_loss: 0.0842\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0432 - val_loss: 0.0841\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0430 - val_loss: 0.0841\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0429 - val_loss: 0.0841\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0427 - val_loss: 0.0840\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0426 - val_loss: 0.0840\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0424 - val_loss: 0.0839\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0423 - val_loss: 0.0839\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0422 - val_loss: 0.0838\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0420 - val_loss: 0.0838\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0419 - val_loss: 0.0838\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0418 - val_loss: 0.0837\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0416 - val_loss: 0.0837\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0415 - val_loss: 0.0836\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0414 - val_loss: 0.0836\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0412 - val_loss: 0.0835\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0411 - val_loss: 0.0835\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0410 - val_loss: 0.0834\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0409 - val_loss: 0.0834\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0407 - val_loss: 0.0834\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0406 - val_loss: 0.0833\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0405 - val_loss: 0.0833\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0404 - val_loss: 0.0832\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0403 - val_loss: 0.0832\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0401 - val_loss: 0.0831\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0400 - val_loss: 0.0831\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0399 - val_loss: 0.0830\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0398 - val_loss: 0.0830\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0397 - val_loss: 0.0830\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0396 - val_loss: 0.0829\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0395 - val_loss: 0.0829\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0394 - val_loss: 0.0828\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0392 - val_loss: 0.0828\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0391 - val_loss: 0.0827\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0390 - val_loss: 0.0827\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0389 - val_loss: 0.0826\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0388 - val_loss: 0.0826\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0387 - val_loss: 0.0826\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0386 - val_loss: 0.0825\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0385 - val_loss: 0.0825\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0384 - val_loss: 0.0824\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0383 - val_loss: 0.0824\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0382 - val_loss: 0.0823\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0381 - val_loss: 0.0823\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0380 - val_loss: 0.0823\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0379 - val_loss: 0.0822\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0378 - val_loss: 0.0822\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0377 - val_loss: 0.0821\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0377 - val_loss: 0.0821\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0376 - val_loss: 0.0820\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0375 - val_loss: 0.0820\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0374 - val_loss: 0.0820\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0373 - val_loss: 0.0819\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0372 - val_loss: 0.0819\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0371 - val_loss: 0.0818\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0370 - val_loss: 0.0818\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0369 - val_loss: 0.0817\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0369 - val_loss: 0.0817\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0368 - val_loss: 0.0817\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0367 - val_loss: 0.0816\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0366 - val_loss: 0.0816\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0365 - val_loss: 0.0815\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0364 - val_loss: 0.0815\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0364 - val_loss: 0.0814\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0363 - val_loss: 0.0814\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0362 - val_loss: 0.0814\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0361 - val_loss: 0.0813\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0360 - val_loss: 0.0813\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0360 - val_loss: 0.0812\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0359 - val_loss: 0.0812\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0358 - val_loss: 0.0812\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0357 - val_loss: 0.0811\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0357 - val_loss: 0.0811\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0356 - val_loss: 0.0810\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0355 - val_loss: 0.0810\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0355 - val_loss: 0.0810\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0354 - val_loss: 0.0809\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0353 - val_loss: 0.0809\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0352 - val_loss: 0.0808\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0352 - val_loss: 0.0808\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0351 - val_loss: 0.0808\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0350 - val_loss: 0.0807\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0350 - val_loss: 0.0807\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0349 - val_loss: 0.0806\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0348 - val_loss: 0.0806\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0348 - val_loss: 0.0806\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0347 - val_loss: 0.0805\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0346 - val_loss: 0.0805\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0346 - val_loss: 0.0804\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0345 - val_loss: 0.0804\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0344 - val_loss: 0.0804\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0344 - val_loss: 0.0803\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0343 - val_loss: 0.0803\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0343 - val_loss: 0.0802\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0342 - val_loss: 0.0802\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0341 - val_loss: 0.0802\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0341 - val_loss: 0.0801\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0340 - val_loss: 0.0801\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0340 - val_loss: 0.0801\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0339 - val_loss: 0.0800\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0338 - val_loss: 0.0800\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0338 - val_loss: 0.0799\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0337 - val_loss: 0.0799\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0799\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0336 - val_loss: 0.0798\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0336 - val_loss: 0.0798\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0335 - val_loss: 0.0798\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0335 - val_loss: 0.0797\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0334 - val_loss: 0.0797\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0334 - val_loss: 0.0796\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0333 - val_loss: 0.0796\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0332 - val_loss: 0.0796\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0332 - val_loss: 0.0795\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0331 - val_loss: 0.0795\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0331 - val_loss: 0.0795\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0330 - val_loss: 0.0794\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0330 - val_loss: 0.0794\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0329 - val_loss: 0.0794\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0329 - val_loss: 0.0793\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0328 - val_loss: 0.0793\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0328 - val_loss: 0.0793\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0327 - val_loss: 0.0792\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0327 - val_loss: 0.0792\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0326 - val_loss: 0.0791\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0326 - val_loss: 0.0791\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0326 - val_loss: 0.0791\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0325 - val_loss: 0.0790\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0325 - val_loss: 0.0790\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0324 - val_loss: 0.0790\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0324 - val_loss: 0.0789\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0323 - val_loss: 0.0789\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0323 - val_loss: 0.0789\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0322 - val_loss: 0.0788\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0322 - val_loss: 0.0788\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0321 - val_loss: 0.0788\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0321 - val_loss: 0.0787\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0321 - val_loss: 0.0787\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.0787\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0320 - val_loss: 0.0786\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0319 - val_loss: 0.0786\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0319 - val_loss: 0.0786\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0318 - val_loss: 0.0785\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0318 - val_loss: 0.0785\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0318 - val_loss: 0.0785\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0317 - val_loss: 0.0784\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0317 - val_loss: 0.0784\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0316 - val_loss: 0.0784\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0316 - val_loss: 0.0783\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0316 - val_loss: 0.0783\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0315 - val_loss: 0.0783\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0315 - val_loss: 0.0782\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0314 - val_loss: 0.0782\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0314 - val_loss: 0.0782\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0314 - val_loss: 0.0781\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0313 - val_loss: 0.0781\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0313 - val_loss: 0.0781\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0313 - val_loss: 0.0781\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0312 - val_loss: 0.0780\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0312 - val_loss: 0.0780\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0311 - val_loss: 0.0780\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0311 - val_loss: 0.0779\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0311 - val_loss: 0.0779\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0310 - val_loss: 0.0779\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0310 - val_loss: 0.0778\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0310 - val_loss: 0.0778\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0309 - val_loss: 0.0778\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0309 - val_loss: 0.0777\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0309 - val_loss: 0.0777\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0308 - val_loss: 0.0777\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0308 - val_loss: 0.0777\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0308 - val_loss: 0.0776\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0307 - val_loss: 0.0776\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0307 - val_loss: 0.0776\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0307 - val_loss: 0.0775\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0306 - val_loss: 0.0775\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0306 - val_loss: 0.0775\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0306 - val_loss: 0.0774\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0305 - val_loss: 0.0774\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0305 - val_loss: 0.0774\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0305 - val_loss: 0.0774\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0304 - val_loss: 0.0773\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0304 - val_loss: 0.0773\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0304 - val_loss: 0.0773\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.0772\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - val_loss: 0.0772\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0303 - val_loss: 0.0772\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0302 - val_loss: 0.0772\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0302 - val_loss: 0.0771\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0302 - val_loss: 0.0771\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0301 - val_loss: 0.0771\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0301 - val_loss: 0.0770\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0301 - val_loss: 0.0770\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0301 - val_loss: 0.0770\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0300 - val_loss: 0.0770\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0300 - val_loss: 0.0769\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0300 - val_loss: 0.0769\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0299 - val_loss: 0.0769\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0299 - val_loss: 0.0768\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0299 - val_loss: 0.0768\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0298 - val_loss: 0.0768\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0298 - val_loss: 0.0768\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0298 - val_loss: 0.0767\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0298 - val_loss: 0.0767\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0297 - val_loss: 0.0767\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0297 - val_loss: 0.0767\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0297 - val_loss: 0.0766\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0296 - val_loss: 0.0766\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0296 - val_loss: 0.0766\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0296 - val_loss: 0.0765\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0296 - val_loss: 0.0765\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0295 - val_loss: 0.0765\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0295 - val_loss: 0.0765\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0295 - val_loss: 0.0764\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0295 - val_loss: 0.0764\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0294 - val_loss: 0.0764\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0294 - val_loss: 0.0764\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0294 - val_loss: 0.0763\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0293 - val_loss: 0.0763\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0293 - val_loss: 0.0763\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0293 - val_loss: 0.0763\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0293 - val_loss: 0.0762\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0292 - val_loss: 0.0762\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0292 - val_loss: 0.0762\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0292 - val_loss: 0.0762\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0292 - val_loss: 0.0761\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0291 - val_loss: 0.0761\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - val_loss: 0.0761\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0291 - val_loss: 0.0761\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0291 - val_loss: 0.0760\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0290 - val_loss: 0.0760\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0290 - val_loss: 0.0760\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0290 - val_loss: 0.0760\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0290 - val_loss: 0.0759\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0289 - val_loss: 0.0759\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0289 - val_loss: 0.0759\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0289 - val_loss: 0.0759\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0289 - val_loss: 0.0758\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0288 - val_loss: 0.0758\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0288 - val_loss: 0.0758\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0288 - val_loss: 0.0758\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0288 - val_loss: 0.0758\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0287 - val_loss: 0.0757\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0287 - val_loss: 0.0757\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0287 - val_loss: 0.0757\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0287 - val_loss: 0.0757\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0286 - val_loss: 0.0756\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0286 - val_loss: 0.0756\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0286 - val_loss: 0.0756\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0286 - val_loss: 0.0756\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0285 - val_loss: 0.0755\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0285 - val_loss: 0.0755\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0285 - val_loss: 0.0755\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0285 - val_loss: 0.0755\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0285 - val_loss: 0.0755\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0284 - val_loss: 0.0754\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0284 - val_loss: 0.0754\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0284 - val_loss: 0.0754\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0284 - val_loss: 0.0754\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0283 - val_loss: 0.0753\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0283 - val_loss: 0.0753\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0283 - val_loss: 0.0753\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0283 - val_loss: 0.0753\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0282 - val_loss: 0.0753\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0282 - val_loss: 0.0752\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0282 - val_loss: 0.0752\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0282 - val_loss: 0.0752\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0282 - val_loss: 0.0752\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0281 - val_loss: 0.0752\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0281 - val_loss: 0.0751\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0281 - val_loss: 0.0751\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0281 - val_loss: 0.0751\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0280 - val_loss: 0.0751\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0280 - val_loss: 0.0751\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0280 - val_loss: 0.0750\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0280 - val_loss: 0.0750\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0280 - val_loss: 0.0750\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0279 - val_loss: 0.0750\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0279 - val_loss: 0.0750\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0279 - val_loss: 0.0749\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0279 - val_loss: 0.0749\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0278 - val_loss: 0.0749\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0278 - val_loss: 0.0749\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0278 - val_loss: 0.0749\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0278 - val_loss: 0.0748\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0278 - val_loss: 0.0748\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0277 - val_loss: 0.0748\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0277 - val_loss: 0.0748\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0277 - val_loss: 0.0748\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - val_loss: 0.0747\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0277 - val_loss: 0.0747\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0276 - val_loss: 0.0747\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0276 - val_loss: 0.0747\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0276 - val_loss: 0.0747\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0276 - val_loss: 0.0746\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0276 - val_loss: 0.0746\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - val_loss: 0.0746\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0275 - val_loss: 0.0746\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0275 - val_loss: 0.0746\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0275 - val_loss: 0.0746\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0274 - val_loss: 0.0745\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0274 - val_loss: 0.0745\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0274 - val_loss: 0.0745\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0274 - val_loss: 0.0745\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0274 - val_loss: 0.0745\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0273 - val_loss: 0.0744\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0273 - val_loss: 0.0744\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0273 - val_loss: 0.0744\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0273 - val_loss: 0.0744\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0273 - val_loss: 0.0744\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0272 - val_loss: 0.0744\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0272 - val_loss: 0.0743\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0272 - val_loss: 0.0743\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0272 - val_loss: 0.0743\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0272 - val_loss: 0.0743\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0271 - val_loss: 0.0743\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0271 - val_loss: 0.0743\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0271 - val_loss: 0.0742\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0271 - val_loss: 0.0742\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0271 - val_loss: 0.0742\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0270 - val_loss: 0.0742\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0270 - val_loss: 0.0742\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0270 - val_loss: 0.0742\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0270 - val_loss: 0.0741\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0270 - val_loss: 0.0741\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0269 - val_loss: 0.0741\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0269 - val_loss: 0.0741\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0269 - val_loss: 0.0741\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0269 - val_loss: 0.0741\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0269 - val_loss: 0.0741\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0268 - val_loss: 0.0740\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0267 - val_loss: 0.0740\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0267 - val_loss: 0.0739\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0267 - val_loss: 0.0739\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0267 - val_loss: 0.0739\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0267 - val_loss: 0.0739\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0266 - val_loss: 0.0739\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0266 - val_loss: 0.0739\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0266 - val_loss: 0.0739\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0266 - val_loss: 0.0738\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0266 - val_loss: 0.0738\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0265 - val_loss: 0.0738\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0265 - val_loss: 0.0738\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0265 - val_loss: 0.0738\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0265 - val_loss: 0.0738\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0265 - val_loss: 0.0738\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0264 - val_loss: 0.0737\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0263 - val_loss: 0.0737\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0263 - val_loss: 0.0737\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0263 - val_loss: 0.0736\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0263 - val_loss: 0.0736\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0263 - val_loss: 0.0736\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0262 - val_loss: 0.0736\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0262 - val_loss: 0.0736\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0262 - val_loss: 0.0736\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0262 - val_loss: 0.0736\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0262 - val_loss: 0.0736\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0261 - val_loss: 0.0735\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0260 - val_loss: 0.0735\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0260 - val_loss: 0.0735\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0260 - val_loss: 0.0734\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0260 - val_loss: 0.0734\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0260 - val_loss: 0.0734\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0259 - val_loss: 0.0734\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0259 - val_loss: 0.0734\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0259 - val_loss: 0.0734\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0259 - val_loss: 0.0734\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0259 - val_loss: 0.0734\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0258 - val_loss: 0.0734\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0258 - val_loss: 0.0734\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0258 - val_loss: 0.0733\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0258 - val_loss: 0.0733\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0258 - val_loss: 0.0733\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0258 - val_loss: 0.0733\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 1.2724 - val_loss: 1.4846\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2440 - val_loss: 1.4529\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2159 - val_loss: 1.4216\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.1883 - val_loss: 1.3906\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1610 - val_loss: 1.3601\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1341 - val_loss: 1.3299\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1077 - val_loss: 1.3002\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0816 - val_loss: 1.2709\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0559 - val_loss: 1.2420\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0306 - val_loss: 1.2135\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0058 - val_loss: 1.1855\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9814 - val_loss: 1.1579\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9574 - val_loss: 1.1308\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9338 - val_loss: 1.1041\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9106 - val_loss: 1.0778\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8879 - val_loss: 1.0521\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8656 - val_loss: 1.0267\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8437 - val_loss: 1.0018\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8223 - val_loss: 0.9774\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8013 - val_loss: 0.9535\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7807 - val_loss: 0.9300\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7605 - val_loss: 0.9069\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7408 - val_loss: 0.8843\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7215 - val_loss: 0.8622\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7026 - val_loss: 0.8405\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6841 - val_loss: 0.8193\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6660 - val_loss: 0.7985\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6484 - val_loss: 0.7782\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6311 - val_loss: 0.7583\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6143 - val_loss: 0.7389\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5979 - val_loss: 0.7199\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5818 - val_loss: 0.7013\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5662 - val_loss: 0.6832\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5510 - val_loss: 0.6654\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5361 - val_loss: 0.6481\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5216 - val_loss: 0.6313\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5075 - val_loss: 0.6148\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4938 - val_loss: 0.5987\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4804 - val_loss: 0.5831\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4674 - val_loss: 0.5678\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4547 - val_loss: 0.5529\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4424 - val_loss: 0.5385\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4304 - val_loss: 0.5243\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4187 - val_loss: 0.5106\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4074 - val_loss: 0.4972\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3964 - val_loss: 0.4842\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3858 - val_loss: 0.4715\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3754 - val_loss: 0.4592\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3653 - val_loss: 0.4472\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3556 - val_loss: 0.4356\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3461 - val_loss: 0.4243\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3369 - val_loss: 0.4133\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3280 - val_loss: 0.4026\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3193 - val_loss: 0.3922\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3110 - val_loss: 0.3822\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3029 - val_loss: 0.3724\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2950 - val_loss: 0.3629\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2874 - val_loss: 0.3537\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2800 - val_loss: 0.3448\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2729 - val_loss: 0.3361\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2660 - val_loss: 0.3277\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2593 - val_loss: 0.3196\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2529 - val_loss: 0.3117\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2466 - val_loss: 0.3040\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2406 - val_loss: 0.2966\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2348 - val_loss: 0.2895\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2291 - val_loss: 0.2825\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2237 - val_loss: 0.2758\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2184 - val_loss: 0.2693\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2133 - val_loss: 0.2630\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2084 - val_loss: 0.2569\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2037 - val_loss: 0.2510\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1991 - val_loss: 0.2453\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1947 - val_loss: 0.2398\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1904 - val_loss: 0.2344\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1863 - val_loss: 0.2292\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1823 - val_loss: 0.2243\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1785 - val_loss: 0.2194\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1748 - val_loss: 0.2148\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1712 - val_loss: 0.2103\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1677 - val_loss: 0.2059\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1644 - val_loss: 0.2017\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1612 - val_loss: 0.1976\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1581 - val_loss: 0.1937\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1551 - val_loss: 0.1899\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1522 - val_loss: 0.1862\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1495 - val_loss: 0.1827\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1468 - val_loss: 0.1793\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1442 - val_loss: 0.1760\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1417 - val_loss: 0.1728\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1393 - val_loss: 0.1697\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1370 - val_loss: 0.1667\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1347 - val_loss: 0.1639\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1326 - val_loss: 0.1611\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1305 - val_loss: 0.1584\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1285 - val_loss: 0.1558\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1265 - val_loss: 0.1533\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1246 - val_loss: 0.1509\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1228 - val_loss: 0.1486\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1211 - val_loss: 0.1464\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1194 - val_loss: 0.1442\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1178 - val_loss: 0.1421\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1162 - val_loss: 0.1401\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1147 - val_loss: 0.1381\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1132 - val_loss: 0.1363\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1117 - val_loss: 0.1344\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1104 - val_loss: 0.1327\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1090 - val_loss: 0.1310\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1077 - val_loss: 0.1294\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1065 - val_loss: 0.1278\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1053 - val_loss: 0.1262\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1041 - val_loss: 0.1248\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1030 - val_loss: 0.1233\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1019 - val_loss: 0.1219\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1008 - val_loss: 0.1206\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0998 - val_loss: 0.1193\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0987 - val_loss: 0.1181\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0978 - val_loss: 0.1169\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0968 - val_loss: 0.1157\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0959 - val_loss: 0.1146\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0950 - val_loss: 0.1135\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0941 - val_loss: 0.1124\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0933 - val_loss: 0.1114\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0925 - val_loss: 0.1104\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0916 - val_loss: 0.1094\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0909 - val_loss: 0.1085\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0901 - val_loss: 0.1076\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0894 - val_loss: 0.1067\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0886 - val_loss: 0.1058\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0879 - val_loss: 0.1050\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0872 - val_loss: 0.1042\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0866 - val_loss: 0.1034\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0859 - val_loss: 0.1027\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0853 - val_loss: 0.1020\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0846 - val_loss: 0.1012\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0840 - val_loss: 0.1005\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0834 - val_loss: 0.0999\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0829 - val_loss: 0.0992\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0823 - val_loss: 0.0986\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0817 - val_loss: 0.0980\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0812 - val_loss: 0.0974\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0806 - val_loss: 0.0968\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0801 - val_loss: 0.0962\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0796 - val_loss: 0.0957\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0791 - val_loss: 0.0951\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0786 - val_loss: 0.0946\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0781 - val_loss: 0.0941\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0776 - val_loss: 0.0936\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0772 - val_loss: 0.0931\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0767 - val_loss: 0.0926\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0762 - val_loss: 0.0922\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0758 - val_loss: 0.0917\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0754 - val_loss: 0.0913\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0749 - val_loss: 0.0908\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0745 - val_loss: 0.0904\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0741 - val_loss: 0.0900\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0737 - val_loss: 0.0896\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0733 - val_loss: 0.0892\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0729 - val_loss: 0.0888\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0725 - val_loss: 0.0884\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0721 - val_loss: 0.0881\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0718 - val_loss: 0.0877\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0714 - val_loss: 0.0873\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0710 - val_loss: 0.0870\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0707 - val_loss: 0.0867\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0703 - val_loss: 0.0863\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0700 - val_loss: 0.0860\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0696 - val_loss: 0.0857\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0693 - val_loss: 0.0854\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0690 - val_loss: 0.0850\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0686 - val_loss: 0.0847\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0683 - val_loss: 0.0844\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0680 - val_loss: 0.0842\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0677 - val_loss: 0.0839\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0674 - val_loss: 0.0836\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0671 - val_loss: 0.0833\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0668 - val_loss: 0.0830\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0665 - val_loss: 0.0828\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0662 - val_loss: 0.0825\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0659 - val_loss: 0.0822\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0656 - val_loss: 0.0820\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0653 - val_loss: 0.0817\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0650 - val_loss: 0.0815\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0648 - val_loss: 0.0812\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0645 - val_loss: 0.0810\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0642 - val_loss: 0.0807\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0640 - val_loss: 0.0805\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0637 - val_loss: 0.0803\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0634 - val_loss: 0.0801\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0632 - val_loss: 0.0798\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0629 - val_loss: 0.0796\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0627 - val_loss: 0.0794\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0624 - val_loss: 0.0792\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0622 - val_loss: 0.0789\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0620 - val_loss: 0.0787\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0617 - val_loss: 0.0785\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0615 - val_loss: 0.0783\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0612 - val_loss: 0.0781\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0610 - val_loss: 0.0779\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0608 - val_loss: 0.0777\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0606 - val_loss: 0.0775\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0603 - val_loss: 0.0773\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0601 - val_loss: 0.0771\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0599 - val_loss: 0.0769\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0597 - val_loss: 0.0767\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - val_loss: 0.0765\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0593 - val_loss: 0.0764\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0590 - val_loss: 0.0762\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0588 - val_loss: 0.0760\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0586 - val_loss: 0.0758\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0584 - val_loss: 0.0756\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0582 - val_loss: 0.0754\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0580 - val_loss: 0.0753\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0578 - val_loss: 0.0751\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0576 - val_loss: 0.0749\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0574 - val_loss: 0.0747\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0573 - val_loss: 0.0746\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0571 - val_loss: 0.0744\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0569 - val_loss: 0.0742\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0567 - val_loss: 0.0740\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0565 - val_loss: 0.0739\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0563 - val_loss: 0.0737\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0561 - val_loss: 0.0735\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0560 - val_loss: 0.0734\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0558 - val_loss: 0.0732\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0556 - val_loss: 0.0731\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0554 - val_loss: 0.0729\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0553 - val_loss: 0.0727\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0551 - val_loss: 0.0726\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0549 - val_loss: 0.0724\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0548 - val_loss: 0.0723\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0546 - val_loss: 0.0721\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0544 - val_loss: 0.0719\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0543 - val_loss: 0.0718\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0541 - val_loss: 0.0716\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0539 - val_loss: 0.0715\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0538 - val_loss: 0.0713\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0536 - val_loss: 0.0712\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0535 - val_loss: 0.0710\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0533 - val_loss: 0.0709\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0531 - val_loss: 0.0707\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0530 - val_loss: 0.0706\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0528 - val_loss: 0.0704\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0527 - val_loss: 0.0703\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0525 - val_loss: 0.0701\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0524 - val_loss: 0.0700\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0522 - val_loss: 0.0698\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0521 - val_loss: 0.0697\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0520 - val_loss: 0.0696\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0518 - val_loss: 0.0694\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0517 - val_loss: 0.0693\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0515 - val_loss: 0.0691\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0514 - val_loss: 0.0690\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0512 - val_loss: 0.0688\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0511 - val_loss: 0.0687\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0510 - val_loss: 0.0686\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0508 - val_loss: 0.0684\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0507 - val_loss: 0.0683\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0506 - val_loss: 0.0682\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0504 - val_loss: 0.0680\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0503 - val_loss: 0.0679\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0502 - val_loss: 0.0677\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0500 - val_loss: 0.0676\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0499 - val_loss: 0.0675\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0498 - val_loss: 0.0673\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0496 - val_loss: 0.0672\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0495 - val_loss: 0.0671\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0494 - val_loss: 0.0669\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0493 - val_loss: 0.0668\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0491 - val_loss: 0.0667\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0490 - val_loss: 0.0666\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0489 - val_loss: 0.0664\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0488 - val_loss: 0.0663\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0487 - val_loss: 0.0662\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0485 - val_loss: 0.0660\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0484 - val_loss: 0.0659\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0483 - val_loss: 0.0658\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0482 - val_loss: 0.0657\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0481 - val_loss: 0.0655\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0480 - val_loss: 0.0654\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0478 - val_loss: 0.0653\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0477 - val_loss: 0.0652\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0476 - val_loss: 0.0650\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0475 - val_loss: 0.0649\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0474 - val_loss: 0.0648\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0473 - val_loss: 0.0647\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0472 - val_loss: 0.0646\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0471 - val_loss: 0.0644\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0470 - val_loss: 0.0643\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0469 - val_loss: 0.0642\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0467 - val_loss: 0.0641\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0466 - val_loss: 0.0640\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0465 - val_loss: 0.0638\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0464 - val_loss: 0.0637\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0463 - val_loss: 0.0636\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0462 - val_loss: 0.0635\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0461 - val_loss: 0.0634\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0460 - val_loss: 0.0633\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0459 - val_loss: 0.0632\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0458 - val_loss: 0.0630\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0457 - val_loss: 0.0629\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0456 - val_loss: 0.0628\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0455 - val_loss: 0.0627\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0454 - val_loss: 0.0626\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0453 - val_loss: 0.0625\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0452 - val_loss: 0.0624\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0451 - val_loss: 0.0623\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0450 - val_loss: 0.0621\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0450 - val_loss: 0.0620\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0449 - val_loss: 0.0619\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0448 - val_loss: 0.0618\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0447 - val_loss: 0.0617\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0446 - val_loss: 0.0616\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0445 - val_loss: 0.0615\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0444 - val_loss: 0.0614\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0443 - val_loss: 0.0613\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0442 - val_loss: 0.0612\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0441 - val_loss: 0.0611\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0440 - val_loss: 0.0610\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0440 - val_loss: 0.0609\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0439 - val_loss: 0.0608\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0438 - val_loss: 0.0607\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0437 - val_loss: 0.0606\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0436 - val_loss: 0.0605\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0435 - val_loss: 0.0604\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0434 - val_loss: 0.0603\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0434 - val_loss: 0.0602\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0433 - val_loss: 0.0601\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0432 - val_loss: 0.0600\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0431 - val_loss: 0.0599\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0430 - val_loss: 0.0598\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0429 - val_loss: 0.0597\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0429 - val_loss: 0.0596\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0428 - val_loss: 0.0595\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0427 - val_loss: 0.0594\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0426 - val_loss: 0.0593\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0426 - val_loss: 0.0592\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0425 - val_loss: 0.0591\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0424 - val_loss: 0.0590\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0423 - val_loss: 0.0589\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0422 - val_loss: 0.0588\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0422 - val_loss: 0.0587\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0421 - val_loss: 0.0586\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0420 - val_loss: 0.0585\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0419 - val_loss: 0.0584\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0419 - val_loss: 0.0583\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0418 - val_loss: 0.0582\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0417 - val_loss: 0.0582\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0416 - val_loss: 0.0581\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0416 - val_loss: 0.0580\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0415 - val_loss: 0.0579\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0414 - val_loss: 0.0578\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0414 - val_loss: 0.0577\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0413 - val_loss: 0.0576\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0412 - val_loss: 0.0575\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0412 - val_loss: 0.0574\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0411 - val_loss: 0.0574\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0410 - val_loss: 0.0573\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0409 - val_loss: 0.0572\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0409 - val_loss: 0.0571\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0408 - val_loss: 0.0570\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0407 - val_loss: 0.0569\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0407 - val_loss: 0.0568\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0406 - val_loss: 0.0568\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0405 - val_loss: 0.0567\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0405 - val_loss: 0.0566\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0404 - val_loss: 0.0565\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0403 - val_loss: 0.0564\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0403 - val_loss: 0.0563\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0402 - val_loss: 0.0563\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0402 - val_loss: 0.0562\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0401 - val_loss: 0.0561\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0400 - val_loss: 0.0560\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0400 - val_loss: 0.0559\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0399 - val_loss: 0.0558\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0398 - val_loss: 0.0558\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0398 - val_loss: 0.0557\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0397 - val_loss: 0.0556\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0397 - val_loss: 0.0555\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0396 - val_loss: 0.0554\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0395 - val_loss: 0.0554\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0395 - val_loss: 0.0553\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0394 - val_loss: 0.0552\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0394 - val_loss: 0.0551\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0393 - val_loss: 0.0551\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0393 - val_loss: 0.0550\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0392 - val_loss: 0.0549\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0391 - val_loss: 0.0548\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0391 - val_loss: 0.0548\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0390 - val_loss: 0.0547\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0390 - val_loss: 0.0546\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0389 - val_loss: 0.0545\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0389 - val_loss: 0.0545\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0388 - val_loss: 0.0544\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0387 - val_loss: 0.0543\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0387 - val_loss: 0.0542\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0386 - val_loss: 0.0542\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0386 - val_loss: 0.0541\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0385 - val_loss: 0.0540\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0385 - val_loss: 0.0539\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0384 - val_loss: 0.0539\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0384 - val_loss: 0.0538\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0383 - val_loss: 0.0537\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0383 - val_loss: 0.0537\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0382 - val_loss: 0.0536\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0382 - val_loss: 0.0535\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0381 - val_loss: 0.0534\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0381 - val_loss: 0.0534\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0380 - val_loss: 0.0533\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0380 - val_loss: 0.0532\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0379 - val_loss: 0.0532\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0379 - val_loss: 0.0531\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0378 - val_loss: 0.0530\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0378 - val_loss: 0.0530\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0377 - val_loss: 0.0529\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0377 - val_loss: 0.0528\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0376 - val_loss: 0.0528\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0376 - val_loss: 0.0527\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0375 - val_loss: 0.0526\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0375 - val_loss: 0.0526\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0374 - val_loss: 0.0525\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0374 - val_loss: 0.0524\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0373 - val_loss: 0.0524\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0373 - val_loss: 0.0523\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0372 - val_loss: 0.0522\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0372 - val_loss: 0.0522\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0371 - val_loss: 0.0521\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0371 - val_loss: 0.0520\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0371 - val_loss: 0.0520\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0370 - val_loss: 0.0519\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0370 - val_loss: 0.0519\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0369 - val_loss: 0.0518\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0369 - val_loss: 0.0517\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0368 - val_loss: 0.0517\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0368 - val_loss: 0.0516\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0367 - val_loss: 0.0515\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0367 - val_loss: 0.0515\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0367 - val_loss: 0.0514\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0366 - val_loss: 0.0514\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0366 - val_loss: 0.0513\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0365 - val_loss: 0.0512\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0365 - val_loss: 0.0512\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0364 - val_loss: 0.0511\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0364 - val_loss: 0.0511\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0364 - val_loss: 0.0510\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0363 - val_loss: 0.0509\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0363 - val_loss: 0.0509\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0362 - val_loss: 0.0508\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0362 - val_loss: 0.0508\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0362 - val_loss: 0.0507\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - val_loss: 0.0506\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0361 - val_loss: 0.0506\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0360 - val_loss: 0.0505\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0360 - val_loss: 0.0505\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0360 - val_loss: 0.0504\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0359 - val_loss: 0.0504\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0359 - val_loss: 0.0503\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0358 - val_loss: 0.0502\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0358 - val_loss: 0.0502\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0358 - val_loss: 0.0501\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0357 - val_loss: 0.0501\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - val_loss: 0.0500\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - val_loss: 0.0500\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0356 - val_loss: 0.0499\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0356 - val_loss: 0.0498\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0355 - val_loss: 0.0498\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0355 - val_loss: 0.0497\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0355 - val_loss: 0.0497\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0354 - val_loss: 0.0496\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0354 - val_loss: 0.0496\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0354 - val_loss: 0.0495\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0353 - val_loss: 0.0495\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0353 - val_loss: 0.0494\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0353 - val_loss: 0.0494\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0352 - val_loss: 0.0493\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0352 - val_loss: 0.0493\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0351 - val_loss: 0.0492\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0351 - val_loss: 0.0492\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0351 - val_loss: 0.0491\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0350 - val_loss: 0.0490\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0350 - val_loss: 0.0490\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0350 - val_loss: 0.0489\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0349 - val_loss: 0.0489\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0349 - val_loss: 0.0488\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0349 - val_loss: 0.0488\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0348 - val_loss: 0.0487\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0348 - val_loss: 0.0487\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0348 - val_loss: 0.0486\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0347 - val_loss: 0.0486\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0347 - val_loss: 0.0485\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0347 - val_loss: 0.0485\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0346 - val_loss: 0.0484\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0346 - val_loss: 0.0484\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0346 - val_loss: 0.0483\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0345 - val_loss: 0.0483\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0345 - val_loss: 0.0482\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0345 - val_loss: 0.0482\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0344 - val_loss: 0.0481\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0344 - val_loss: 0.0481\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0344 - val_loss: 0.0481\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0344 - val_loss: 0.0480\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0343 - val_loss: 0.0480\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0343 - val_loss: 0.0479\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0343 - val_loss: 0.0479\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0342 - val_loss: 0.0478\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0342 - val_loss: 0.0478\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0342 - val_loss: 0.0477\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0341 - val_loss: 0.0477\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0341 - val_loss: 0.0476\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0341 - val_loss: 0.0476\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0341 - val_loss: 0.0475\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0340 - val_loss: 0.0475\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0340 - val_loss: 0.0474\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0340 - val_loss: 0.0474\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0339 - val_loss: 0.0474\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0339 - val_loss: 0.0473\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0339 - val_loss: 0.0473\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0338 - val_loss: 0.0472\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0338 - val_loss: 0.0472\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0338 - val_loss: 0.0471\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0338 - val_loss: 0.0471\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0337 - val_loss: 0.0470\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0470\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0469\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0336 - val_loss: 0.0469\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0336 - val_loss: 0.0469\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0336 - val_loss: 0.0468\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0468\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0335 - val_loss: 0.0467\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0335 - val_loss: 0.0467\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0335 - val_loss: 0.0466\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0335 - val_loss: 0.0466\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0334 - val_loss: 0.0466\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0334 - val_loss: 0.0465\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0334 - val_loss: 0.0465\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0334 - val_loss: 0.0464\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0333 - val_loss: 0.0464\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0333 - val_loss: 0.0463\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0333 - val_loss: 0.0463\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0332 - val_loss: 0.0463\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0462\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0462\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0332 - val_loss: 0.0461\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0331 - val_loss: 0.0461\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0331 - val_loss: 0.0461\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0331 - val_loss: 0.0460\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0331 - val_loss: 0.0460\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0330 - val_loss: 0.0459\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0330 - val_loss: 0.0459\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0330 - val_loss: 0.0459\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0330 - val_loss: 0.0458\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0329 - val_loss: 0.0458\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0329 - val_loss: 0.0457\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0329 - val_loss: 0.0457\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0329 - val_loss: 0.0457\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0328 - val_loss: 0.0456\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0328 - val_loss: 0.0456\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0328 - val_loss: 0.0455\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0328 - val_loss: 0.0455\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0327 - val_loss: 0.0455\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0327 - val_loss: 0.0454\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0327 - val_loss: 0.0454\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0327 - val_loss: 0.0454\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0327 - val_loss: 0.0453\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0326 - val_loss: 0.0453\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0326 - val_loss: 0.0452\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0326 - val_loss: 0.0452\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0326 - val_loss: 0.0452\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0325 - val_loss: 0.0451\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0325 - val_loss: 0.0451\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0325 - val_loss: 0.0451\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0325 - val_loss: 0.0450\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0324 - val_loss: 0.0450\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0324 - val_loss: 0.0449\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0324 - val_loss: 0.0449\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0324 - val_loss: 0.0449\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0324 - val_loss: 0.0448\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0323 - val_loss: 0.0448\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0323 - val_loss: 0.0448\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0323 - val_loss: 0.0447\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0323 - val_loss: 0.0447\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0322 - val_loss: 0.0447\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0322 - val_loss: 0.0446\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0322 - val_loss: 0.0446\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0322 - val_loss: 0.0445\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0322 - val_loss: 0.0445\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0321 - val_loss: 0.0445\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0321 - val_loss: 0.0444\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0321 - val_loss: 0.0444\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0321 - val_loss: 0.0444\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0320 - val_loss: 0.0443\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0320 - val_loss: 0.0443\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0320 - val_loss: 0.0443\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0320 - val_loss: 0.0442\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0320 - val_loss: 0.0442\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0319 - val_loss: 0.0442\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0319 - val_loss: 0.0441\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0319 - val_loss: 0.0441\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0319 - val_loss: 0.0441\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0319 - val_loss: 0.0440\n",
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.8471 - val_loss: 0.8841\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8003 - val_loss: 0.8621\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7541 - val_loss: 0.8406\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7086 - val_loss: 0.8194\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6638 - val_loss: 0.7985\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6197 - val_loss: 0.7781\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.5764 - val_loss: 0.7581\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5338 - val_loss: 0.7384\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4919 - val_loss: 0.7192\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4509 - val_loss: 0.7003\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4105 - val_loss: 0.6819\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3710 - val_loss: 0.6639\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3322 - val_loss: 0.6462\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2942 - val_loss: 0.6290\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.2570 - val_loss: 0.6121\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2205 - val_loss: 0.5957\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1849 - val_loss: 0.5796\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1500 - val_loss: 0.5639\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1159 - val_loss: 0.5487\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0826 - val_loss: 0.5338\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0501 - val_loss: 0.5193\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0183 - val_loss: 0.5052\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9873 - val_loss: 0.4915\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.9571 - val_loss: 0.4781\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9276 - val_loss: 0.4651\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8989 - val_loss: 0.4525\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8710 - val_loss: 0.4402\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8438 - val_loss: 0.4283\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8173 - val_loss: 0.4168\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.7916 - val_loss: 0.4056\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7666 - val_loss: 0.3947\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7423 - val_loss: 0.3842\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7186 - val_loss: 0.3740\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6957 - val_loss: 0.3641\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6735 - val_loss: 0.3545\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6519 - val_loss: 0.3453\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6310 - val_loss: 0.3363\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6107 - val_loss: 0.3277\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5911 - val_loss: 0.3193\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5721 - val_loss: 0.3113\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5537 - val_loss: 0.3035\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5359 - val_loss: 0.2959\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5187 - val_loss: 0.2887\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5020 - val_loss: 0.2817\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4859 - val_loss: 0.2749\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4704 - val_loss: 0.2684\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4554 - val_loss: 0.2621\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4409 - val_loss: 0.2561\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4269 - val_loss: 0.2503\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4134 - val_loss: 0.2446\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4004 - val_loss: 0.2393\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3879 - val_loss: 0.2341\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3758 - val_loss: 0.2291\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3641 - val_loss: 0.2243\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3529 - val_loss: 0.2196\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3422 - val_loss: 0.2152\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3318 - val_loss: 0.2109\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3218 - val_loss: 0.2068\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3122 - val_loss: 0.2028\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3029 - val_loss: 0.1990\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2941 - val_loss: 0.1954\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2855 - val_loss: 0.1919\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2773 - val_loss: 0.1885\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2695 - val_loss: 0.1853\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2619 - val_loss: 0.1822\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2546 - val_loss: 0.1792\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2477 - val_loss: 0.1763\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2410 - val_loss: 0.1736\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2346 - val_loss: 0.1709\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2284 - val_loss: 0.1684\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2225 - val_loss: 0.1659\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2168 - val_loss: 0.1636\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2114 - val_loss: 0.1613\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2062 - val_loss: 0.1591\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2012 - val_loss: 0.1570\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1964 - val_loss: 0.1550\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1918 - val_loss: 0.1531\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1874 - val_loss: 0.1512\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1832 - val_loss: 0.1494\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1792 - val_loss: 0.1477\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1753 - val_loss: 0.1461\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1716 - val_loss: 0.1445\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1680 - val_loss: 0.1429\n",
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1646 - val_loss: 0.1414\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1613 - val_loss: 0.1400\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1582 - val_loss: 0.1386\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1552 - val_loss: 0.1373\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1523 - val_loss: 0.1360\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1495 - val_loss: 0.1348\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1469 - val_loss: 0.1336\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1443 - val_loss: 0.1324\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1419 - val_loss: 0.1313\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1395 - val_loss: 0.1302\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1372 - val_loss: 0.1292\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1351 - val_loss: 0.1282\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1330 - val_loss: 0.1272\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1310 - val_loss: 0.1263\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1290 - val_loss: 0.1254\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1272 - val_loss: 0.1245\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1254 - val_loss: 0.1236\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1237 - val_loss: 0.1228\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1220 - val_loss: 0.1220\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1204 - val_loss: 0.1212\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1189 - val_loss: 0.1204\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1174 - val_loss: 0.1197\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1160 - val_loss: 0.1190\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1146 - val_loss: 0.1183\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1132 - val_loss: 0.1176\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1120 - val_loss: 0.1170\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1107 - val_loss: 0.1163\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1095 - val_loss: 0.1157\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1083 - val_loss: 0.1151\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1072 - val_loss: 0.1146\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1061 - val_loss: 0.1140\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1050 - val_loss: 0.1134\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1040 - val_loss: 0.1129\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1030 - val_loss: 0.1124\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1020 - val_loss: 0.1119\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1011 - val_loss: 0.1114\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1001 - val_loss: 0.1109\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0993 - val_loss: 0.1104\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0984 - val_loss: 0.1100\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0975 - val_loss: 0.1095\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0967 - val_loss: 0.1091\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0959 - val_loss: 0.1087\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0951 - val_loss: 0.1083\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0943 - val_loss: 0.1079\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0936 - val_loss: 0.1075\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0929 - val_loss: 0.1071\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0922 - val_loss: 0.1067\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0915 - val_loss: 0.1063\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0908 - val_loss: 0.1060\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0901 - val_loss: 0.1056\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0895 - val_loss: 0.1053\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0888 - val_loss: 0.1050\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0882 - val_loss: 0.1047\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0876 - val_loss: 0.1043\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0870 - val_loss: 0.1040\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0864 - val_loss: 0.1037\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0858 - val_loss: 0.1034\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0852 - val_loss: 0.1031\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0847 - val_loss: 0.1029\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0841 - val_loss: 0.1026\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0836 - val_loss: 0.1023\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0831 - val_loss: 0.1021\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0825 - val_loss: 0.1018\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0820 - val_loss: 0.1016\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0815 - val_loss: 0.1013\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0810 - val_loss: 0.1011\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0805 - val_loss: 0.1008\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0801 - val_loss: 0.1006\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0796 - val_loss: 0.1004\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0791 - val_loss: 0.1002\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0787 - val_loss: 0.1000\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0782 - val_loss: 0.0998\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0778 - val_loss: 0.0996\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0773 - val_loss: 0.0994\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0769 - val_loss: 0.0992\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0765 - val_loss: 0.0990\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0761 - val_loss: 0.0988\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0756 - val_loss: 0.0986\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0752 - val_loss: 0.0984\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0748 - val_loss: 0.0982\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0744 - val_loss: 0.0981\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0740 - val_loss: 0.0979\n",
      "Epoch 166/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0737 - val_loss: 0.0977\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0733 - val_loss: 0.0976\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0729 - val_loss: 0.0974\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0725 - val_loss: 0.0973\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0722 - val_loss: 0.0971\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0718 - val_loss: 0.0970\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0714 - val_loss: 0.0968\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0711 - val_loss: 0.0967\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0707 - val_loss: 0.0965\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0704 - val_loss: 0.0964\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0700 - val_loss: 0.0963\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0697 - val_loss: 0.0961\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0694 - val_loss: 0.0960\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0690 - val_loss: 0.0959\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0687 - val_loss: 0.0957\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0684 - val_loss: 0.0956\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0681 - val_loss: 0.0955\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0678 - val_loss: 0.0954\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0674 - val_loss: 0.0953\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0671 - val_loss: 0.0951\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0668 - val_loss: 0.0950\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0665 - val_loss: 0.0949\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0662 - val_loss: 0.0948\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0659 - val_loss: 0.0947\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0656 - val_loss: 0.0946\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0654 - val_loss: 0.0945\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0651 - val_loss: 0.0944\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0648 - val_loss: 0.0943\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0645 - val_loss: 0.0942\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0642 - val_loss: 0.0941\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0640 - val_loss: 0.0940\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0637 - val_loss: 0.0939\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0634 - val_loss: 0.0938\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0631 - val_loss: 0.0937\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0629 - val_loss: 0.0936\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0626 - val_loss: 0.0935\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0624 - val_loss: 0.0934\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0621 - val_loss: 0.0934\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0619 - val_loss: 0.0933\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0616 - val_loss: 0.0932\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0614 - val_loss: 0.0931\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0611 - val_loss: 0.0930\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0609 - val_loss: 0.0929\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0606 - val_loss: 0.0928\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0604 - val_loss: 0.0928\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0601 - val_loss: 0.0927\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0599 - val_loss: 0.0926\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0597 - val_loss: 0.0925\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0594 - val_loss: 0.0924\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0592 - val_loss: 0.0924\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0590 - val_loss: 0.0923\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0588 - val_loss: 0.0922\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0585 - val_loss: 0.0921\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0583 - val_loss: 0.0921\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0581 - val_loss: 0.0920\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0579 - val_loss: 0.0919\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0577 - val_loss: 0.0918\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0575 - val_loss: 0.0918\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0573 - val_loss: 0.0917\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0570 - val_loss: 0.0916\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0568 - val_loss: 0.0915\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0566 - val_loss: 0.0915\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0564 - val_loss: 0.0914\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0562 - val_loss: 0.0913\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0560 - val_loss: 0.0913\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0558 - val_loss: 0.0912\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0556 - val_loss: 0.0911\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0554 - val_loss: 0.0910\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0552 - val_loss: 0.0910\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0550 - val_loss: 0.0909\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0549 - val_loss: 0.0908\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0547 - val_loss: 0.0908\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0545 - val_loss: 0.0907\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0543 - val_loss: 0.0906\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0541 - val_loss: 0.0905\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0539 - val_loss: 0.0905\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0538 - val_loss: 0.0904\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0536 - val_loss: 0.0903\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0534 - val_loss: 0.0903\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0532 - val_loss: 0.0902\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0530 - val_loss: 0.0901\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0529 - val_loss: 0.0901\n",
      "Epoch 248/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0527 - val_loss: 0.0900\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0525 - val_loss: 0.0899\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0524 - val_loss: 0.0899\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0522 - val_loss: 0.0898\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0520 - val_loss: 0.0897\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0519 - val_loss: 0.0896\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0517 - val_loss: 0.0896\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0515 - val_loss: 0.0895\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0514 - val_loss: 0.0894\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0512 - val_loss: 0.0894\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0510 - val_loss: 0.0893\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0509 - val_loss: 0.0892\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0507 - val_loss: 0.0892\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0506 - val_loss: 0.0891\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0504 - val_loss: 0.0890\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0503 - val_loss: 0.0889\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0501 - val_loss: 0.0889\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0500 - val_loss: 0.0888\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0498 - val_loss: 0.0887\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0497 - val_loss: 0.0887\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0495 - val_loss: 0.0886\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0494 - val_loss: 0.0885\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0492 - val_loss: 0.0884\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0491 - val_loss: 0.0884\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0489 - val_loss: 0.0883\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0488 - val_loss: 0.0882\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0487 - val_loss: 0.0882\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0485 - val_loss: 0.0881\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0484 - val_loss: 0.0880\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0482 - val_loss: 0.0879\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0481 - val_loss: 0.0879\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0480 - val_loss: 0.0878\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0478 - val_loss: 0.0877\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0477 - val_loss: 0.0876\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0476 - val_loss: 0.0876\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0474 - val_loss: 0.0875\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0473 - val_loss: 0.0874\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0472 - val_loss: 0.0874\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0470 - val_loss: 0.0873\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0469 - val_loss: 0.0872\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0468 - val_loss: 0.0871\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0467 - val_loss: 0.0871\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0465 - val_loss: 0.0870\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0464 - val_loss: 0.0869\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0463 - val_loss: 0.0868\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0462 - val_loss: 0.0868\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0460 - val_loss: 0.0867\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0459 - val_loss: 0.0866\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0458 - val_loss: 0.0865\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0457 - val_loss: 0.0865\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0456 - val_loss: 0.0864\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0454 - val_loss: 0.0863\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0453 - val_loss: 0.0862\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0452 - val_loss: 0.0862\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0451 - val_loss: 0.0861\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0450 - val_loss: 0.0860\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0449 - val_loss: 0.0859\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0447 - val_loss: 0.0858\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0446 - val_loss: 0.0858\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0445 - val_loss: 0.0857\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0444 - val_loss: 0.0856\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0443 - val_loss: 0.0855\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0442 - val_loss: 0.0855\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0441 - val_loss: 0.0854\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0440 - val_loss: 0.0853\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0439 - val_loss: 0.0852\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0438 - val_loss: 0.0852\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0436 - val_loss: 0.0851\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0435 - val_loss: 0.0850\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0434 - val_loss: 0.0849\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0433 - val_loss: 0.0848\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0432 - val_loss: 0.0848\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0431 - val_loss: 0.0847\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0430 - val_loss: 0.0846\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0429 - val_loss: 0.0845\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0428 - val_loss: 0.0844\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0427 - val_loss: 0.0844\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0426 - val_loss: 0.0843\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0425 - val_loss: 0.0842\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0424 - val_loss: 0.0841\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0423 - val_loss: 0.0841\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0422 - val_loss: 0.0840\n",
      "Epoch 330/600\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0421 - val_loss: 0.0839\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0420 - val_loss: 0.0838\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0419 - val_loss: 0.0837\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0419 - val_loss: 0.0837\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0418 - val_loss: 0.0836\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0417 - val_loss: 0.0835\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0416 - val_loss: 0.0834\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0415 - val_loss: 0.0833\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0414 - val_loss: 0.0833\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0413 - val_loss: 0.0832\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0412 - val_loss: 0.0831\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0411 - val_loss: 0.0830\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0410 - val_loss: 0.0830\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0409 - val_loss: 0.0829\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0409 - val_loss: 0.0828\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0408 - val_loss: 0.0827\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0407 - val_loss: 0.0826\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0406 - val_loss: 0.0826\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0405 - val_loss: 0.0825\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0404 - val_loss: 0.0824\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0403 - val_loss: 0.0823\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0403 - val_loss: 0.0822\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0402 - val_loss: 0.0822\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0401 - val_loss: 0.0821\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0400 - val_loss: 0.0820\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0399 - val_loss: 0.0819\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - val_loss: 0.0819\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - val_loss: 0.0818\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0397 - val_loss: 0.0817\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0396 - val_loss: 0.0816\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0395 - val_loss: 0.0815\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0394 - val_loss: 0.0815\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0394 - val_loss: 0.0814\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0393 - val_loss: 0.0813\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0392 - val_loss: 0.0812\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0391 - val_loss: 0.0812\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0391 - val_loss: 0.0811\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0390 - val_loss: 0.0810\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0389 - val_loss: 0.0809\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0388 - val_loss: 0.0808\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0388 - val_loss: 0.0808\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0387 - val_loss: 0.0807\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0386 - val_loss: 0.0806\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0385 - val_loss: 0.0805\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0385 - val_loss: 0.0805\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0384 - val_loss: 0.0804\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0383 - val_loss: 0.0803\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0383 - val_loss: 0.0802\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0382 - val_loss: 0.0802\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0381 - val_loss: 0.0801\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0380 - val_loss: 0.0800\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0380 - val_loss: 0.0799\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0379 - val_loss: 0.0798\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0378 - val_loss: 0.0798\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0378 - val_loss: 0.0797\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0377 - val_loss: 0.0796\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0376 - val_loss: 0.0795\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0376 - val_loss: 0.0795\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0375 - val_loss: 0.0794\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0374 - val_loss: 0.0793\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0374 - val_loss: 0.0792\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0373 - val_loss: 0.0792\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0372 - val_loss: 0.0791\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0372 - val_loss: 0.0790\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0371 - val_loss: 0.0790\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0370 - val_loss: 0.0789\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0370 - val_loss: 0.0788\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0369 - val_loss: 0.0787\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0368 - val_loss: 0.0787\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0368 - val_loss: 0.0786\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - val_loss: 0.0785\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0367 - val_loss: 0.0784\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0366 - val_loss: 0.0784\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0365 - val_loss: 0.0783\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - val_loss: 0.0782\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0364 - val_loss: 0.0781\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0364 - val_loss: 0.0781\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0363 - val_loss: 0.0780\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0362 - val_loss: 0.0779\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0362 - val_loss: 0.0779\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - val_loss: 0.0778\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0361 - val_loss: 0.0777\n",
      "Epoch 412/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0360 - val_loss: 0.0776\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0360 - val_loss: 0.0776\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0359 - val_loss: 0.0775\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0358 - val_loss: 0.0774\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0358 - val_loss: 0.0774\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0357 - val_loss: 0.0773\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0357 - val_loss: 0.0772\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0356 - val_loss: 0.0772\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0356 - val_loss: 0.0771\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0355 - val_loss: 0.0770\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0354 - val_loss: 0.0769\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0354 - val_loss: 0.0769\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0353 - val_loss: 0.0768\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0353 - val_loss: 0.0767\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0352 - val_loss: 0.0767\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0352 - val_loss: 0.0766\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0351 - val_loss: 0.0765\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0351 - val_loss: 0.0765\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0350 - val_loss: 0.0764\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0350 - val_loss: 0.0763\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0349 - val_loss: 0.0763\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0349 - val_loss: 0.0762\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0348 - val_loss: 0.0761\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0348 - val_loss: 0.0761\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0347 - val_loss: 0.0760\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0347 - val_loss: 0.0759\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0346 - val_loss: 0.0759\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0346 - val_loss: 0.0758\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0345 - val_loss: 0.0757\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0345 - val_loss: 0.0757\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0344 - val_loss: 0.0756\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0344 - val_loss: 0.0756\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0343 - val_loss: 0.0755\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0343 - val_loss: 0.0754\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0342 - val_loss: 0.0754\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0342 - val_loss: 0.0753\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0341 - val_loss: 0.0752\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0341 - val_loss: 0.0752\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0340 - val_loss: 0.0751\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0340 - val_loss: 0.0750\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0340 - val_loss: 0.0750\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0339 - val_loss: 0.0749\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0339 - val_loss: 0.0749\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0338 - val_loss: 0.0748\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0338 - val_loss: 0.0747\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0747\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0746\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0746\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0336 - val_loss: 0.0745\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0336 - val_loss: 0.0744\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0335 - val_loss: 0.0744\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0335 - val_loss: 0.0743\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0334 - val_loss: 0.0743\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0334 - val_loss: 0.0742\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0333 - val_loss: 0.0741\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0333 - val_loss: 0.0741\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0333 - val_loss: 0.0740\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0332 - val_loss: 0.0740\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0332 - val_loss: 0.0739\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0331 - val_loss: 0.0738\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0331 - val_loss: 0.0738\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0330 - val_loss: 0.0737\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0330 - val_loss: 0.0737\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0330 - val_loss: 0.0736\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0329 - val_loss: 0.0736\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0329 - val_loss: 0.0735\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0328 - val_loss: 0.0734\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0328 - val_loss: 0.0734\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0328 - val_loss: 0.0733\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0327 - val_loss: 0.0733\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0327 - val_loss: 0.0732\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0326 - val_loss: 0.0732\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0326 - val_loss: 0.0731\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0326 - val_loss: 0.0731\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0325 - val_loss: 0.0730\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0325 - val_loss: 0.0730\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0325 - val_loss: 0.0729\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0324 - val_loss: 0.0728\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0324 - val_loss: 0.0728\n",
      "Epoch 491/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0323 - val_loss: 0.0727\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0323 - val_loss: 0.0727\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0323 - val_loss: 0.0726\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.0726\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0322 - val_loss: 0.0725\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0322 - val_loss: 0.0725\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0321 - val_loss: 0.0724\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0321 - val_loss: 0.0724\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0321 - val_loss: 0.0723\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0320 - val_loss: 0.0723\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0320 - val_loss: 0.0722\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0320 - val_loss: 0.0722\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0319 - val_loss: 0.0721\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0319 - val_loss: 0.0721\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0318 - val_loss: 0.0720\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0318 - val_loss: 0.0720\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0318 - val_loss: 0.0719\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0317 - val_loss: 0.0719\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0317 - val_loss: 0.0718\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0317 - val_loss: 0.0718\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0316 - val_loss: 0.0717\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0316 - val_loss: 0.0717\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0316 - val_loss: 0.0716\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0315 - val_loss: 0.0716\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0315 - val_loss: 0.0715\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0315 - val_loss: 0.0715\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0314 - val_loss: 0.0715\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0314 - val_loss: 0.0714\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0314 - val_loss: 0.0714\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0314 - val_loss: 0.0713\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0313 - val_loss: 0.0713\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0313 - val_loss: 0.0712\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0313 - val_loss: 0.0712\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0312 - val_loss: 0.0711\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0312 - val_loss: 0.0711\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0312 - val_loss: 0.0710\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0311 - val_loss: 0.0710\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0311 - val_loss: 0.0710\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0311 - val_loss: 0.0709\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0310 - val_loss: 0.0709\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0310 - val_loss: 0.0708\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0310 - val_loss: 0.0708\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0309 - val_loss: 0.0707\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0309 - val_loss: 0.0707\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0309 - val_loss: 0.0707\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0309 - val_loss: 0.0706\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0308 - val_loss: 0.0706\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0308 - val_loss: 0.0705\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0308 - val_loss: 0.0705\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0307 - val_loss: 0.0704\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0307 - val_loss: 0.0704\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0307 - val_loss: 0.0704\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0307 - val_loss: 0.0703\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0306 - val_loss: 0.0703\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0306 - val_loss: 0.0702\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0306 - val_loss: 0.0702\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0305 - val_loss: 0.0702\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0305 - val_loss: 0.0701\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0305 - val_loss: 0.0701\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0305 - val_loss: 0.0701\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0304 - val_loss: 0.0700\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0304 - val_loss: 0.0700\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0304 - val_loss: 0.0699\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0304 - val_loss: 0.0699\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0303 - val_loss: 0.0699\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0303 - val_loss: 0.0698\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0303 - val_loss: 0.0698\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0302 - val_loss: 0.0697\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0302 - val_loss: 0.0697\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0302 - val_loss: 0.0697\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0302 - val_loss: 0.0696\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0301 - val_loss: 0.0696\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0301 - val_loss: 0.0696\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0301 - val_loss: 0.0695\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0301 - val_loss: 0.0695\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0300 - val_loss: 0.0695\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0300 - val_loss: 0.0694\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0300 - val_loss: 0.0694\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0300 - val_loss: 0.0694\n",
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0299 - val_loss: 0.0693\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0299 - val_loss: 0.0693\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0299 - val_loss: 0.0693\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0299 - val_loss: 0.0692\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0298 - val_loss: 0.0692\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0298 - val_loss: 0.0692\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0298 - val_loss: 0.0691\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0298 - val_loss: 0.0691\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0297 - val_loss: 0.0691\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0297 - val_loss: 0.0690\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0297 - val_loss: 0.0690\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0297 - val_loss: 0.0690\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0296 - val_loss: 0.0689\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0296 - val_loss: 0.0689\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0296 - val_loss: 0.0689\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0296 - val_loss: 0.0688\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0295 - val_loss: 0.0688\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0295 - val_loss: 0.0688\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0295 - val_loss: 0.0687\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0295 - val_loss: 0.0687\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0294 - val_loss: 0.0687\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0294 - val_loss: 0.0687\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0294 - val_loss: 0.0686\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0294 - val_loss: 0.0686\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0294 - val_loss: 0.0686\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0293 - val_loss: 0.0685\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0293 - val_loss: 0.0685\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0293 - val_loss: 0.0685\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0293 - val_loss: 0.0685\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0292 - val_loss: 0.0684\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0292 - val_loss: 0.0684\n"
     ]
    }
   ],
   "source": [
    "save_loss = list()\n",
    "save_val_loss = list()\n",
    "save_history = list()\n",
    "\n",
    "#KFoldの設定\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "\n",
    "#交差検証\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train = x[train_index]\n",
    "    y_train = y[train_index]\n",
    "    x_test = x[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model = build_model(x)\n",
    "    \n",
    "    model.compile(loss=losses.MeanSquaredError(), \n",
    "              optimizer=optimizers.Adam(learning_rate = 0.00001))\n",
    "\n",
    "    mc = callbacks.ModelCheckpoint(\n",
    "        filepath = \"model.h5\",\n",
    "        monitor = \"val_loss\",\n",
    "        save_best_only = True,\n",
    "        mode = \"min\"\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size = len(x_train), epochs = 600, verbose = 1, \n",
    "                        validation_data=(x_test, y_test), callbacks =[mc])\n",
    "\n",
    "    save_history.append(history.history)\n",
    "    model = models.load_model(\"model.h5\")\n",
    "    \n",
    "    best_val_loss = model.evaluate(x_test, y_test, verbose = False)\n",
    "\n",
    "    best_loss = model.evaluate(x_train, y_train, verbose = False)\n",
    "\n",
    "    save_val_loss.append(best_val_loss)\n",
    "    save_loss.append(best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "\n",
    "# 学習曲線\n",
    "# ax.plot(history.history[\"loss\"], label = \"train\")\n",
    "for i, H  in enumerate(save_history):\n",
    "    H[\"loss\"]\n",
    "    # 活性化関数tanhで学習した後のtanh_test\n",
    "    ax.plot(H[\"loss\"], label = f\"{i}\")\n",
    "    # ax.plot(H[\"val_loss\"], label = \"val_loss\")\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"loss(log)\")\n",
    "ax.set_xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04463426396250725,\n",
       " 0.02336467243731022,\n",
       " 0.112494558095932,\n",
       " 0.02376248687505722,\n",
       " 0.03058838061988354,\n",
       " 0.05570859685540199)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_save_loss = list()\n",
    "min_save_loss = list()\n",
    "max_save_val_loss = list()\n",
    "min_save_val_loss = list()\n",
    "\n",
    "max(save_loss), min(save_loss), max(save_val_loss), min(save_val_loss), np.average(save_loss), np.average(save_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06839665025472641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(30,)' with type '<class 'tuple'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mSequential()\n\u001b[1;32m      2\u001b[0m \u001b[39m# model.add(layers.Input(shape=x_train.shape[1:]))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49madd(layers\u001b[39m.\u001b[39;49mLSTM(units\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(x_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m:], \u001b[39m1\u001b[39;49m)))\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mDropout(\u001b[39m0.2\u001b[39m))\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mLSTM(units\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf291/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf291/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(30,)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "# model.add(layers.Input(shape=x_train.shape[1:]))\n",
    "model.add(layers.LSTM(units=50,return_sequences=True, input_shape=(x_train.shape[1:], 1)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(units=50,return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(units=50,return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(units=50))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_history = model.fit(x_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
